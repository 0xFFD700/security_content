<h2>web</h2>


<h4>monitor_web_traffic_for_brand_abuse.yml</h4>

<table><tr><td>name</td><td>Monitor Web Traffic For Brand Abuse</td></tr><tr><td>id</td><td>134da869-e264-4a8f-8d7e-fcd0ec88f301</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-09-23</td></tr><tr><td>description</td><td>This search looks for Web requests to faux domains similar to the one that you want to have monitored for abuse.</td></tr><tr><td>how_to_implement</td><td>You need to ingest data from your web traffic. This can be accomplished by indexing data from a web proxy, or using a network traffic analysis tool, such as Bro or Splunk Stream. You also need to have run the search "ESCU - DNSTwist Domain Names", which creates the permutations of the domain that will be checked for.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` values(Web.url) as urls min(_time) as firstTime from datamodel=Web by Web.src | `drop_dm_object_name("Web")` | `security_content_ctime(firstTime)` | `brand_abuse_web` | `monitor_web_traffic_for_brand_abuse_filter`</td></tr><tr><td>known_false_positives</td><td>None at this time</td></tr><tr><td>tags</td><td>{'analytics_story': ['Brand Monitoring'], 'kill_chain_phases': ['Delivery'], 'cis20': ['CIS 7'], 'nist': ['PR.IP'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>sql_injection_with_long_urls.yml</h4>

<table><tr><td>name</td><td>SQL Injection with Long URLs</td></tr><tr><td>id</td><td>e0aad4cf-0790-423b-8328-7564d0d938f9</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for long URLs that have several SQL commands visible within them.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you need to be monitoring network communications to your web servers or ingesting your HTTP logs and populating the Web data model. You must also identify your web servers in the Enterprise Security assets table.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count from datamodel=Web where Web.dest_category=web_server AND (Web.url_length > 1024 OR Web.http_user_agent_length > 200) by Web.src Web.dest Web.url Web.url_length Web.http_user_agent | `drop_dm_object_name("Web")` | eval num_sql_cmds=mvcount(split(url, "alter%20table")) + mvcount(split(url, "between")) + mvcount(split(url, "create%20table")) + mvcount(split(url, "create%20database")) + mvcount(split(url, "create%20index")) + mvcount(split(url, "create%20view")) + mvcount(split(url, "delete")) + mvcount(split(url, "drop%20database")) + mvcount(split(url, "drop%20index")) + mvcount(split(url, "drop%20table")) + mvcount(split(url, "exists")) + mvcount(split(url, "exec")) + mvcount(split(url, "group%20by")) + mvcount(split(url, "having")) + mvcount(split(url, "insert%20into")) + mvcount(split(url, "inner%20join")) + mvcount(split(url, "left%20join")) + mvcount(split(url, "right%20join")) + mvcount(split(url, "full%20join")) + mvcount(split(url, "select")) + mvcount(split(url, "distinct")) + mvcount(split(url, "select%20top")) + mvcount(split(url, "union")) + mvcount(split(url, "xp_cmdshell")) - 24 | where num_sql_cmds > 3 | `sql_injection_with_long_urls_filter`</td></tr><tr><td>known_false_positives</td><td>It's possible that legitimate traffic will have long URLs or long user agent strings and that common SQL commands may be found within the URL. Please investigate as appropriate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['SQL Injection'], 'mitre_attack_id': ['T1190'], 'kill_chain_phases': ['Delivery'], 'cis20': ['CIS 4', 'CIS 13', 'CIS 18'], 'nist': ['PR.DS', 'ID.RA', 'PR.PT', 'PR.IP', 'DE.CM'], 'security_domain': 'network', 'asset_type': 'Database Server'}</td></tr></table>
<h4>detect_f5_tmui_rct_cve_2020_5902.yml</h4>

<table><tr><td>name</td><td>Detect F5 TMUI RCE CVE-2020-5902</td></tr><tr><td>id</td><td>810e4dbc-d46e-11ea-87d0-0242ac130003</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-08-02</td></tr><tr><td>description</td><td>This search detects remote code exploit attempts on F5 BIG-IP, BIG-IQ, and Traffix SDC devices</td></tr><tr><td>how_to_implement</td><td>To consistently detect exploit attempts on F5 devices using the vulnerabilities contained within CVE-2020-5902 it is recommended to ingest logs via syslog.  As many BIG-IP devices will have SSL enabled on their management interfaces, detections via wire data may not pick anything up unless you are decrypting SSL traffic in order to inspect it.  I am using a regex string from a Cloudflare mitigation technique to try and always catch the offending string (..;), along with the other exploit of using (hsqldb;).</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://www.ptsecurity.com/ww-en/about/news/f5-fixes-critical-vulnerability-discovered-by-positive-technologies-in-big-ip-application-delivery-controller/', 'https://support.f5.com/csp/article/K52145254', 'https://blog.cloudflare.com/cve-2020-5902-helping-to-protect-against-the-f5-tmui-rce-vulnerability/']</td></tr><tr><td>author</td><td>Shannon Davis, Splunk</td></tr><tr><td>search</td><td>`f5_bigip_rogue` | regex _raw="(hsqldb;|.*\\.\\.;.*)" | search `detect_f5_tmui_rce_cve_2020_5902_filter`</td></tr><tr><td>known_false_positives</td><td>unknown</td></tr><tr><td>tags</td><td>{'analytics_story': ['F5 TMUI RCE CVE-2020-5902'], 'mitre_attack_id': ['T1190'], 'kill_chain_phases': ['Exploitation'], 'cis20': ['CIS 8', 'CIS 11'], 'nist': ['DE.CM'], 'security_domain': 'network', 'asset_type': 'Network'}</td></tr></table>
<h4>web_fraud___account_harvesting.yml</h4>

<table><tr><td>name</td><td>Web Fraud - Account Harvesting</td></tr><tr><td>id</td><td>31337aaa-941d-4ada-81ac-q2a17be5bf0d</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-10-08</td></tr><tr><td>description</td><td>This search is used to identify the creation of multiple user accounts using the same email domain name.</td></tr><tr><td>how_to_implement</td><td>We start with a dataset that provides visibility into the email address used for the account creation. In this example, we are narrowing our search down to the single web page that hosts the Magento2 e-commerce platform (via URI) used for account creation, the single http content-type to grab only the user's clicks, and the http field that provides the username (form_data), for performance reasons.  After we have the username and email domain, we look for numerous account creations per email domain.  Common data sources used for this detection are customized Apache logs or Splunk Stream.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://splunkbase.splunk.com/app/2734/', 'https://splunkbase.splunk.com/app/1809/']</td></tr><tr><td>author</td><td>Jim Apger, Splunk</td></tr><tr><td>search</td><td>`stream_http` http_content_type=text* uri="/magento2/customer/account/loginPost/" | rex field=cookie "form_key=(?<SessionID>\w+)" | rex field=form_data "login\[username\]=(?<Username>[^&|^$]+)" | search Username=* | rex field=Username "@(?<email_domain>.*)" | stats dc(Username) as UniqueUsernames list(Username) as src_user by email_domain | where UniqueUsernames> 25 | `web_fraud___account_harvesting_filter`</td></tr><tr><td>known_false_positives</td><td>As is common with many fraud-related searches, we are usually looking to attribute risk or synthesize relevant context with loosely written detections that simply detect anamolous behavior. This search will need to be customized to fit your environment&#151;improving its fidelity by counting based on something much more specific, such as a device ID that may be present in your dataset. Consideration for whether the large number of registrations are occuring from a first-time seen domain may also be important.  Extending the search window to look further back in time, or even calculating the average per hour/day for each email domain to look for an anomalous spikes, will improve this search.  You can also use Shannon entropy or Levenshtein Distance (both courtesy of URL Toolbox) to consider the randomness or similarity of the email name or email domain, as the names are often machine-generated.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Web Fraud Detection'], 'mitre_attack_id': ['T1136'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 16'], 'nist': ['DE.CM', 'DE.DP'], 'security_domain': 'threat', 'asset_type': 'Account'}</td></tr></table>
<h4>detect_web_traffic_to_dynamic_domain_providers.yml</h4>

<table><tr><td>name</td><td>Detect web traffic to dynamic domain providers</td></tr><tr><td>id</td><td>134da869-e264-4a8f-8d7e-fcd01c18f301</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for web connections to dynamic DNS providers.</td></tr><tr><td>how_to_implement</td><td>This search requires you to be ingesting web-traffic logs. You can obtain these logs from indexing data from a web proxy or by using a network-traffic-analysis tool, such as Bro or Splunk Stream. The web data model must contain the URL being requested, the IP address of the host initiating the request, and the destination IP. This search also leverages a lookup file, `dynamic_dns_providers_default.csv`, which contains a non-exhaustive list of dynamic DNS providers. Consider periodically updating this local lookup file with new domains.\
This search produces fields (`isDynDNS`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** IsDynamicDNS, **Field:** isDynDNS\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Web.url) as url min(_time) as firstTime from datamodel=Web where Web.status=200 by Web.src Web.dest Web.status | `drop_dm_object_name("Web")` | `security_content_ctime(firstTime)` | `dynamic_dns_web_traffic` | `detect_web_traffic_to_dynamic_domain_providers_filter`</td></tr><tr><td>known_false_positives</td><td>It is possible that list of dynamic DNS providers is outdated and/or that the URL being requested is legitimate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Dynamic DNS'], 'mitre_attack_id': ['T1071.001'], 'kill_chain_phases': ['Command and Control', 'Actions on Objectives'], 'cis20': ['CIS 7', 'CIS 8'], 'nist': ['PR.IP', 'DE.DP'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>web_fraud___password_sharing_across_accounts.yml</h4>

<table><tr><td>name</td><td>Web Fraud - Password Sharing Across Accounts</td></tr><tr><td>id</td><td>31337a1a-53b9-4e05-96e9-55c934cb71d3</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-10-08</td></tr><tr><td>description</td><td>This search is used to identify user accounts that share a common password.</td></tr><tr><td>how_to_implement</td><td>We need to start with a dataset that allows us to see the values of usernames and passwords that users are submitting to the website hosting the Magento2 e-commerce platform (commonly found in the HTTP form_data field). A tokenized or hashed value of a password is acceptable and certainly preferable to a clear-text password. Common data sources used for this detection are customized Apache logs, customized IIS, and Splunk Stream.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://en.wikipedia.org/wiki/Session_ID', 'https://en.wikipedia.org/wiki/Session_(computer_science)', 'https://en.wikipedia.org/wiki/HTTP_cookie', 'https://splunkbase.splunk.com/app/1809/']</td></tr><tr><td>author</td><td>Jim Apger, Splunk</td></tr><tr><td>search</td><td>`stream_http` http_content_type=text* uri=/magento2/customer/account/loginPost*  | rex field=form_data "login\[username\]=(?<Username>[^&|^$]+)" | rex field=form_data "login\[password\]=(?<Password>[^&|^$]+)" | stats dc(Username) as UniqueUsernames values(Username) as user list(src_ip) as src_ip by Password|where UniqueUsernames>5 | `web_fraud___password_sharing_across_accounts_filter`</td></tr><tr><td>known_false_positives</td><td>As is common with many fraud-related searches, we are usually looking to attribute risk or synthesize relevant context with loosely written detections that simply detect anamoluous behavior.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Web Fraud Detection'], 'cis20': ['CIS 16'], 'nist': ['DE.DP'], 'security_domain': 'threat', 'asset_type': 'account'}</td></tr></table>
<h4>test.yml</h4>

<table><tr><td>name</td><td>Test</td></tr><tr><td>id</td><td>104658f4-afdc-499e-9719-17243f982681</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-09-23</td></tr><tr><td>description</td><td>This search looks for specific GET or HEAD requests to web servers that are indicative of reconnaissance attempts to identify vulnerable JBoss servers. JexBoss is described as the exploit tool of choice for this malicious activity.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data from the web server or network traffic that contains web specific information, and populating the Web data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Web where (Web.http_method="GET" OR Web.http_method="HEAD") AND (Web.url="*/web-console/ServerInfo.jsp*" OR Web.url="*web-console*" OR Web.url="*jmx-console*" OR Web.url = "*invoker*") by Web.http_method, Web.url, Web.src, Web.dest | `drop_dm_object_name("Web")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `detect_attackers_scanning_for_vulnerable_jboss_servers_filter`</td></tr><tr><td>known_false_positives</td><td>It's possible for legitimate HTTP requests to be made to URLs containing the suspicious paths.</td></tr><tr><td>tags</td><td>{'analytics_story': ['JBoss Vulnerability', 'SamSam Ransomware'], 'mitre_attack_id': ['T1082'], 'kill_chain_phases': ['Reconnaissance'], 'security_domain': 'network', 'asset_type': 'Web Server'}</td></tr></table>
<h4>web_fraud___anomalous_user_clickspeed.yml</h4>

<table><tr><td>name</td><td>Web Fraud - Anomalous User Clickspeed</td></tr><tr><td>id</td><td>31337bbb-bc22-4752-b599-ef192df2dc7a</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-10-08</td></tr><tr><td>description</td><td>This search is used to examine web sessions to identify those where the clicks are occurring too quickly for a human or are occurring with a near-perfect cadence (high periodicity or low standard deviation), resembling a script driven session.</td></tr><tr><td>how_to_implement</td><td>Start with a dataset that allows you to see clickstream data for each user click on the website. That data must have a time stamp and must contain a reference to the session identifier being used by the website. This ties the clicks together into clickstreams. This value is usually found in the http cookie. With a bit of tuning, a version of this search could be used in high-volume scenarios, such as scraping, crawling, application DDOS, credit-card testing, account takeover, etc. Common data sources used for this detection are customized Apache logs, customized IIS, and Splunk Stream.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://en.wikipedia.org/wiki/Session_ID', 'https://en.wikipedia.org/wiki/Session_(computer_science)', 'https://en.wikipedia.org/wiki/HTTP_cookie', 'https://splunkbase.splunk.com/app/1809/']</td></tr><tr><td>author</td><td>Jim Apger, Splunk</td></tr><tr><td>search</td><td>`stream_http` http_content_type=text* | rex field=cookie "form_key=(?<session_id>\w+)" | streamstats window=2 current=1 range(_time) as TimeDelta by session_id | where TimeDelta>0 |stats count stdev(TimeDelta) as ClickSpeedStdDev avg(TimeDelta) as ClickSpeedAvg by session_id | where count>5 AND (ClickSpeedStdDev<.5 OR ClickSpeedAvg<.5) | `web_fraud___anomalous_user_clickspeed_filter`</td></tr><tr><td>known_false_positives</td><td>As is common with many fraud-related searches, we are usually looking to attribute risk or synthesize relevant context with loosly written detections that simply detect anamoluous behavior.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Web Fraud Detection'], 'mitre_attack_id': ['T1078'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 6'], 'nist': ['DE.AE', 'DE.CM'], 'security_domain': 'threat', 'asset_type': 'account'}</td></tr></table>
<h4>detect_malicious_requests_to_exploit_jboss_servers.yml</h4>

<table><tr><td>name</td><td>Detect malicious requests to exploit JBoss servers</td></tr><tr><td>id</td><td>c8bff7a4-11ea-4416-a27d-c5bca472913d</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-09-23</td></tr><tr><td>description</td><td>This search is used to detect malicious HTTP requests crafted to exploit jmx-console in JBoss servers. The malicious requests have a long URL length, as the payload is embedded in the URL.</td></tr><tr><td>how_to_implement</td><td>You must ingest data from the web server or capture network data that contains web specific information with solutions such as Bro or Splunk Stream, and populating the Web data model</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Web where (Web.http_method="GET" OR Web.http_method="HEAD") by Web.http_method, Web.url,Web.url_length Web.src, Web.dest | search Web.url="*jmx-console/HtmlAdaptor?action=invokeOpByName&name=jboss.admin*import*" AND Web.url_length > 200 | `drop_dm_object_name("Web")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | table src, dest_ip, http_method, url, firstTime, lastTime | `detect_malicious_requests_to_exploit_jboss_servers_filter`</td></tr><tr><td>known_false_positives</td><td>No known false positives for this detection.</td></tr><tr><td>tags</td><td>{'analytics_story': ['JBoss Vulnerability', 'SamSam Ransomware'], 'kill_chain_phases': ['Delivery'], 'cis20': ['CIS 12', 'CIS 4', 'CIS 18'], 'nist': ['ID.RA', 'PR.PT', 'PR.IP', 'DE.AE', 'PR.MA', 'DE.CM'], 'security_domain': 'network', 'asset_type': 'Web Server'}</td></tr></table>

<h2>network</h2>


<h4>dns_query_length_outliers___mltk.yml</h4>

<table><tr><td>name</td><td>DNS Query Length Outliers - MLTK</td></tr><tr><td>id</td><td>85fbcfe8-9718-4911-adf6-7000d077a3a9</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-01-22</td></tr><tr><td>description</td><td>This search allows you to identify DNS requests that are unusually large for the record type being requested in your environment.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you will need to ensure that DNS data is populating the Network_Resolution data model. In addition, the Machine Learning Toolkit (MLTK) version 4.2 or greater must be installed on your search heads, along with any required dependencies. Finally, the support search "Baseline of DNS Query Length - MLTK" must be executed before this detection search, because it builds a machine-learning (ML) model over the historical data used by this search. It is important that this search is run in the same app context as the associated support search, so that the model created by the support search is available for use. You should periodically re-run the support search to rebuild the model with the latest data available in your environment.\
This search produces fields (`query`,`query_length`,`count`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** DNS Query, **Field:** query\
1. \
1. **Label:** DNS Query Length, **Field:** query_length\
1. \
1. **Label:** Number of events, **Field:** count\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as start_time max(_time) as end_time values(DNS.src) as src values(DNS.dest) as dest from datamodel=Network_Resolution by DNS.query DNS.record_type | search DNS.record_type=* |  `drop_dm_object_name(DNS)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | eval query_length = len(query) | apply dns_query_pdfmodel threshold=0.01 | rename "IsOutlier(query_length)" as isOutlier | search isOutlier > 0 | sort -query_length | table start_time end_time query record_type count src dest query_length | `dns_query_length_outliers___mltk_filter` </td></tr><tr><td>known_false_positives</td><td>If you are seeing more results than desired, you may consider reducing the value for threshold in the search. You should also periodically re-run the support search to re-build the ML model on the latest data.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Hidden Cobra Malware', 'Suspicious DNS Traffic', 'Command and Control'], 'mitre_attack_id': ['T1071.004'], 'kill_chain_phases': ['Command and Control'], 'cis20': ['CIS 8', 'CIS 12'], 'nist': ['PR.PT', 'DE.AE', 'DE.CM'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_unauthorized_assets_by_mac_address.yml</h4>

<table><tr><td>name</td><td>Detect Unauthorized Assets by MAC address</td></tr><tr><td>id</td><td>dcfd6b40-42f9-469d-a433-2e53f7489ff4</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-09-13</td></tr><tr><td>description</td><td>By populating the organization's assets within the assets_by_str.csv, we will be able to detect unauthorized devices that are trying to connect with the organization's network by inspecting DHCP request packets, which are issued by devices when they attempt to obtain an IP address from the DHCP server. The MAC address associated with the source of the DHCP request is checked against the list of known devices, and reports on those that are not found.</td></tr><tr><td>how_to_implement</td><td>This search uses the Network_Sessions data model shipped with Enterprise Security. It leverages the Assets and Identity framework to populate the assets_by_str.csv file located in SA-IdentityManagement, which will contain a list of known authorized organizational assets including their MAC addresses. Ensure that all inventoried systems have their MAC address populated.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count from datamodel=Network_Sessions where nodename=All_Sessions.DHCP All_Sessions.signature=DHCPREQUEST by All_Sessions.src_ip All_Sessions.src_mac | dedup All_Sessions.src_mac| `drop_dm_object_name("Network_Sessions")`|`drop_dm_object_name("All_Sessions")` | search NOT [| inputlookup asset_lookup_by_str |rename mac as src_mac | fields + src_mac] | `detect_unauthorized_assets_by_mac_address_filter`</td></tr><tr><td>known_false_positives</td><td>This search might be prone to high false positives. Please consider this when conducting analysis or investigations. Authorized devices may be detected as unauthorized. If this is the case, verify the MAC address of the system responsible for the false positive and add it to the Assets and Identity framework with the proper information.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Asset Tracking'], 'kill_chain_phases': ['Reconnaissance', 'Delivery', 'Actions on Objectives'], 'cis20': ['CIS 1'], 'nist': ['ID.AM', 'PR.DS'], 'security_domain': 'network', 'asset_type': 'Infrastructure'}</td></tr></table>
<h4>detect_outbound_smb_traffic.yml</h4>

<table><tr><td>name</td><td>Detect Outbound SMB Traffic</td></tr><tr><td>id</td><td>7f5fb3e1-4209-414-90db-0ec21b936378</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for outbound SMB connections made by hosts within your network to the Internet. SMB traffic is used for Windows file-sharing activity. One of the techniques often used by attackers involves retrieving the credential hash using an SMB request made to a compromised server controlled by the threat actor.</td></tr><tr><td>how_to_implement</td><td>In order to run this search effectively, we highly recommend that you leverage the Assets and Identity framework. It is important that you have good understanding of how your network segments are designed, and be able to distinguish internal from external address space. Add a category named `internal` to the CIDRs that host the company's assets in `assets_by_cidr.csv` lookup file, which is located in `$SPLUNK_HOME/etc/apps/SA-IdentityManagement/lookups/`. More information on updating this lookup can be found here: https://docs.splunk.com/Documentation/ES/5.0.0/Admin/Addassetandidentitydata. This search also requires you to be ingesting your network traffic and populating the Network_Traffic data model</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count earliest(_time) as earliest latest(_time) as latest values(All_Traffic.action) from datamodel=Network_Traffic where All_Traffic.action !=blocked All_Traffic.dest_category !=internal (All_Traffic.dest_port=139 OR All_Traffic.dest_port=445 OR All_Traffic.app=smb) by All_Traffic.src_ip All_Traffic.dest_ip | `drop_dm_object_name("All_Traffic")` | search ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16) | `security_content_ctime(earliest)`| `security_content_ctime(latest)` | `detect_outbound_smb_traffic_filter` </td></tr><tr><td>known_false_positives</td><td>It is likely that the outbound Server Message Block (SMB) traffic is legitimate, if the company's internal networks are not well-defined in the Assets and Identity Framework. Categorize the internal CIDR blocks as `internal` in the lookup file to avoid creating notable events for traffic destined to those CIDR blocks. Any other network connection that is going out to the Internet should be investigated and blocked. Best practices suggest preventing external communications of all SMB versions and related protocols at the network boundary.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Hidden Cobra Malware', 'DHS Report TA18-074A'], 'mitre_attack_id': ['T1071.002'], 'kill_chain_phases': ['Actions on Objectives', 'Command and Control'], 'cis20': ['CIS 12'], 'nist': ['DE.CM'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>large_volume_of_dns_any_queries.yml</h4>

<table><tr><td>name</td><td>Large Volume of DNS ANY Queries</td></tr><tr><td>id</td><td>8fa891f7-a533-4b3c-af85-5aa2e7c1f1eb</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-09-20</td></tr><tr><td>description</td><td>The search is used to identify attempts to use your DNS Infrastructure for DDoS purposes via a DNS amplification attack leveraging ANY queries.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search you must ensure that DNS data is populating the Network_Resolution data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count from datamodel=Network_Resolution where nodename=DNS "DNS.message_type"="QUERY" "DNS.record_type"="ANY" by "DNS.dest" | `drop_dm_object_name("DNS")` | where count>200 | `large_volume_of_dns_any_queries_filter`</td></tr><tr><td>known_false_positives</td><td>Legitimate ANY requests may trigger this search, however it is unusual to see a large volume of them under typical circumstances. You may modify the threshold in the search to better suit your environment.</td></tr><tr><td>tags</td><td>{'analytics_story': ['DNS Amplification Attacks'], 'mitre_attack_id': ['T1498.002'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 11', 'CIS 12'], 'nist': ['PR.PT', 'DE.AE', 'PR.IP'], 'security_domain': 'network', 'asset_type': 'DNS Servers'}</td></tr></table>
<h4>detect_rogue_dhcp_server.yml</h4>

<table><tr><td>name</td><td>Detect Rogue DHCP Server</td></tr><tr><td>id</td><td>6e1ada88-7a0d-4ac1-92c6-03d354686079</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-08-11</td></tr><tr><td>description</td><td>By enabling DHCP Snooping as a Layer 2 Security measure on the organization's network devices, we will be able to detect unauthorized DHCP servers handing out DHCP leases to devices on the network (Man in the Middle attack).</td></tr><tr><td>how_to_implement</td><td>This search uses a standard SPL query on logs from Cisco Network devices. The network devices must be configured with DHCP Snooping enabled (see https://www.cisco.com/c/en/us/td/docs/switches/lan/catalyst2960x/software/15-0_2_EX/security/configuration_guide/b_sec_152ex_2960-x_cg/b_sec_152ex_2960-x_cg_chapter_01101.html) and log with a severity level of minimum "5 - notification". The search also requires that the Cisco Networks Add-on for Splunk (https://splunkbase.splunk.com/app/1467) is used to parse the logs from the Cisco network devices.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Mikael Bjerkeland, Splunk</td></tr><tr><td>search</td><td>`cisco_networks` facility="DHCP_SNOOPING" mnemonic="DHCP_SNOOPING_UNTRUSTED_PORT" | stats min(_time) AS firstTime max(_time) AS lastTime count values(message_type) AS message_type values(src_mac) AS src_mac BY host | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`| `detect_rogue_dhcp_server_filter`</td></tr><tr><td>known_false_positives</td><td>This search might be prone to high false positives if DHCP Snooping has been incorrectly configured or in the unlikely event that the DHCP server has been moved to another network interface.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Router and Infrastructure Security'], 'kill_chain_phases': ['Reconnaissance', 'Delivery', 'Actions on Objectives'], 'mitre_attack_id': ['T1200', 'T1498', 'T1557'], 'cis20': ['CIS 1', 'CIS 11'], 'nist': ['ID.AM', 'PR.DS'], 'detection_name': 'Detect Rogue DHCP Server', 'security_domain': 'network', 'asset_type': 'Infrastructure'}</td></tr></table>
<h4>detect_zerologon_via_zeek.yml</h4>

<table><tr><td>name</td><td>Detect Zerologon via Zeek</td></tr><tr><td>id</td><td>bf7a06ec-f703-11ea-adc1-0242ac120002</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-09-15</td></tr><tr><td>description</td><td>This search detects attempts to run exploits for the Zerologon CVE-2020-1472 vulnerability via Zeek RPC</td></tr><tr><td>how_to_implement</td><td>You must be ingesting Zeek DCE-RPC data into Splunk. Zeek data should also be getting ingested in JSON format.  We are detecting when all three RPC operations (NetrServerReqChallenge, NetrServerAuthenticate3, NetrServerPasswordSet2) are splunk_security_essentials_app via bro:rpc:json.  These three operations are then correlated on the Zeek UID field.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://www.secura.com/blog/zero-logon', 'https://github.com/SecuraBV/CVE-2020-1472', 'https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2020-1472']</td></tr><tr><td>author</td><td>Shannon Davis, Splunk</td></tr><tr><td>search</td><td>`zeek_rpc` operation IN (NetrServerPasswordSet2,NetrServerReqChallenge,NetrServerAuthenticate3) | bin span=5m _time | stats values(operation) dc(operation) as opscount count(eval(operation=="NetrServerReqChallenge")) as challenge count(eval(operation=="NetrServerAuthenticate3")) as authcount count(eval(operation=="NetrServerPasswordSet2")) as passcount count as totalcount by _time,src_ip,dest_ip | search opscount=3 authcount>4 passcount>0 | search `detect_zerologon_via_zeek_filter`</td></tr><tr><td>known_false_positives</td><td>unknown</td></tr><tr><td>tags</td><td>{'analytics_story': ['Detect Zerologon Attack'], 'mitre_attack_id': ['T1190'], 'kill_chain_phases': ['Exploitation'], 'cis20': ['CIS 8', 'CIS 11'], 'nist': ['DE.CM'], 'security_domain': 'network', 'asset_type': 'Network'}</td></tr></table>
<h4>hosts_receiving_high_volume_of_network_traffic_from_email_server.yml</h4>

<table><tr><td>name</td><td>Hosts receiving high volume of network traffic from email server</td></tr><tr><td>id</td><td>7f5fb3e1-4209-4914-90db-0ec21b556368</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for an increase of data transfers from your email server to your clients. This could be indicative of a malicious actor collecting data using your email server.</td></tr><tr><td>how_to_implement</td><td>This search requires you to be ingesting your network traffic and populating the Network_Traffic data model.  Your email servers must be categorized as "email_server" for the search to work, as well. You may need to adjust the deviation_threshold and minimum_data_samples values based on the network traffic in your environment. The "deviation_threshold" field is a multiplying factor to control how much variation you're willing to tolerate. The "minimum_data_samples" field is the minimum number of connections of data samples required for the statistic to be valid.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` sum(All_Traffic.bytes_in) as bytes_in from datamodel=Network_Traffic where All_Traffic.dest_category=email_server by All_Traffic.src_ip _time span=1d | `drop_dm_object_name("All_Traffic")` | eventstats avg(bytes_in) as avg_bytes_in stdev(bytes_in) as stdev_bytes_in | eventstats count as num_data_samples avg(eval(if(_time < relative_time(now(), "@d"), bytes_in, null))) as per_source_avg_bytes_in stdev(eval(if(_time < relative_time(now(), "@d"), bytes_in, null))) as per_source_stdev_bytes_in by src_ip | eval minimum_data_samples = 4, deviation_threshold = 3 | where num_data_samples >= minimum_data_samples AND bytes_in > (avg_bytes_in + (deviation_threshold * stdev_bytes_in)) AND bytes_in > (per_source_avg_bytes_in + (deviation_threshold * per_source_stdev_bytes_in)) AND _time >= relative_time(now(), "@d") | eval num_standard_deviations_away_from_server_average = round(abs(bytes_in - avg_bytes_in) / stdev_bytes_in, 2), num_standard_deviations_away_from_client_average = round(abs(bytes_in - per_source_avg_bytes_in) / per_source_stdev_bytes_in, 2) | table src_ip, _time, bytes_in, avg_bytes_in, per_source_avg_bytes_in, num_standard_deviations_away_from_server_average, num_standard_deviations_away_from_client_average | `hosts_receiving_high_volume_of_network_traffic_from_email_server_filter`</td></tr><tr><td>known_false_positives</td><td>The false-positive rate will vary based on how you set the deviation_threshold and data_samples values. Our recommendation is to adjust these values based on your network traffic to and from your email servers.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Collection and Staging'], 'mitre_attack_id': ['T1114.002'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 7'], 'nist': ['PR.PT', 'DE.CM', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_hosts_connecting_to_dynamic_domain_providers.yml</h4>

<table><tr><td>name</td><td>Detect hosts connecting to dynamic domain providers</td></tr><tr><td>id</td><td>c77162d3-f93c-45cc-80c8-22f6v5464g9f</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-01-16</td></tr><tr><td>description</td><td>Malicious actors often abuse legitimate Dynamic DNS services to host malicious payloads or interactive command and control nodes. Attackers will automate domain resolution changes by routing dynamic domains to countless IP addresses to circumvent firewall blocks, blacklists as well as frustrate a network defenders analytic and investigative processes. This search will look for DNS queries made from within your infrastructure to suspicious dynamic domains.</td></tr><tr><td>how_to_implement</td><td>First, you'll need to ingest data from your DNS operations. This can be done by ingesting logs from your server or data, collected passively by Splunk Stream or a similar solution. Specifically, data that contains the domain that is being queried and the IP of the host originating the request must be populating the `Network_Resolution` data model. This search also leverages a lookup file, `dynamic_dns_providers_default.csv`, which contains a non-exhaustive list of Dynamic DNS providers. Please consider updating the local lookup periodically by adding new domains to the list of `dynamic_dns_providers_local.csv`.\
This search produces fields (query, answer, isDynDNS) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable event. To see the additional metadata, add the following fields, if not already present, to Incident Review. Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** DNS Query, **Field:** query\
1. \
1. **Label:** DNS Answer, **Field:** answer\
1. \
1. **Label:** IsDynamicDNS, **Field:** isDynDNS\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(DNS.answer) as answer min(_time) as firstTime from datamodel=Network_Resolution by DNS.src, DNS.query | `drop_dm_object_name("DNS")` | `security_content_ctime(firstTime)` | `dynamic_dns_providers` | `detect_hosts_connecting_to_dynamic_domain_providers_filter`</td></tr><tr><td>known_false_positives</td><td>Some users and applications may leverage Dynamic DNS to reach out to some domains on the Internet since dynamic DNS by itself is not malicious, however this activity must be verified.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Data Protection', 'Prohibited Traffic Allowed or Protocol Mismatch', 'DNS Hijacking', 'Suspicious DNS Traffic', 'Dynamic DNS', 'Command and Control'], 'kill_chain_phases': ['Command and Control', 'Actions on Objectives'], 'cis20': ['CIS 8', 'CIS 12', 'CIS 13'], 'nist': ['PR.DS', 'PR.PT', 'DE.AE', 'DE.CM'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>dns_query_requests_resolved_by_unauthorized_dns_servers.yml</h4>

<table><tr><td>name</td><td>DNS Query Requests Resolved by Unauthorized DNS Servers</td></tr><tr><td>id</td><td>1a67f15a-f4ff-4170-84e9-08cf6f75d6f6</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search will detect DNS requests resolved by unauthorized DNS servers. Legitimate DNS servers should be identified in the Enterprise Security Assets and Identity Framework.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search you will need to ensure that DNS data is populating the Network_Resolution data model. It also requires that your DNS servers are identified correctly in the Assets and Identity table of Enterprise Security.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count from datamodel=Network_Resolution where DNS.dest_category != dns_server AND DNS.src_category != dns_server by DNS.src DNS.dest | `drop_dm_object_name("DNS")` | `dns_query_requests_resolved_by_unauthorized_dns_servers_filter` </td></tr><tr><td>known_false_positives</td><td>Legitimate DNS activity can be detected in this search. Investigate, verify and update the list of authorized DNS servers as appropriate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['DNS Hijacking', 'Command and Control', 'Suspicious DNS Traffic', 'Host Redirection'], 'mitre_attack_id': ['T1071.004'], 'kill_chain_phases': ['Command and Control'], 'cis20': ['CIS 1', 'CIS 3', 'CIS 8', 'CIS 12'], 'nist': ['ID.AM', 'PR.DS', 'PR.IP', 'DE.AE', 'DE.CM'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>smb_traffic_spike___mltk.yml</h4>

<table><tr><td>name</td><td>SMB Traffic Spike - MLTK</td></tr><tr><td>id</td><td>d25773ba-9ad8-48d1-858e-07ad0bbeb828</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-22</td></tr><tr><td>description</td><td>This search uses the Machine Learning Toolkit (MLTK) to identify spikes in the number of Server Message Block (SMB) connections.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you will need to ensure that DNS data is populating the Network_Resolution data model. In addition, the Machine Learning Toolkit (MLTK) version 4.2 or greater must be installed on your search heads, along with any required dependencies. Finally, the support search "Baseline of SMB Traffic - MLTK" must be executed before this detection search, because it builds a machine-learning (ML) model over the historical data used by this search. It is important that this search is run in the same app context as the associated support search, so that the model created by the support search is available for use. You should periodically re-run the support search to rebuild the model with the latest data available in your environment.\
This search produces a field (Number of events,count) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. This field contributes additional context to the notable. To see the additional metadata, add the following field, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry): \
1. **Label:** Number of events, **Field:** count\
Detailed documentation on how to create a new field within Incident Review is found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(All_Traffic.dest_ip) as dest values(All_Traffic.dest_port) as port from datamodel=Network_Traffic where All_Traffic.dest_port=139 OR All_Traffic.dest_port=445 OR All_Traffic.app=smb by _time span=1h, All_Traffic.src | eval HourOfDay=strftime(_time, "%H") | eval DayOfWeek=strftime(_time, "%A") | `drop_dm_object_name(All_Traffic)` | apply smb_pdfmodel threshold=0.001 | rename "IsOutlier(count)" as isOutlier | search isOutlier > 0 | sort -count | table _time src dest port count | `smb_traffic_spike___mltk_filter` </td></tr><tr><td>known_false_positives</td><td>If you are seeing more results than desired, you may consider reducing the value of the threshold in the search. You should also periodically re-run the support search to re-build the ML model on the latest data. Please update the `smb_traffic_spike_mltk_filter` macro to filter out false positive results</td></tr><tr><td>tags</td><td>{'analytics_story': ['Emotet Malware  DHS Report TA18-201A ', 'Hidden Cobra Malware', 'Ransomware', 'DHS Report TA18-074A'], 'mitre_attack_id': ['T1021.002'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['DE.CM'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>smb_traffic_spike.yml</h4>

<table><tr><td>name</td><td>SMB Traffic Spike</td></tr><tr><td>id</td><td>7f5fb3e1-4209-4914-90db-0ec21b936378</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-22</td></tr><tr><td>description</td><td>This search looks for spikes in the number of Server Message Block (SMB) traffic connections.</td></tr><tr><td>how_to_implement</td><td>This search requires you to be ingesting your network traffic logs and populating the `Network_Traffic` data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=139 OR All_Traffic.dest_port=445 OR All_Traffic.app=smb by _time span=1h, All_Traffic.src | `drop_dm_object_name("All_Traffic")` | eventstats max(_time) as maxtime | stats count as num_data_samples max(eval(if(_time >= relative_time(maxtime, "-70m@m"), count, null))) as count avg(eval(if(_time<relative_time(maxtime, "-70m@m"), count, null))) as avg stdev(eval(if(_time<relative_time(maxtime, "-70m@m"), count, null))) as stdev by src | eval upperBound=(avg+stdev*2), isOutlier=if(count > upperBound AND num_data_samples >=50, 1, 0) | where isOutlier=1 | table src count | `smb_traffic_spike_filter` </td></tr><tr><td>known_false_positives</td><td>A file server may experience high-demand loads that could cause this analytic to trigger.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Emotet Malware  DHS Report TA18-201A ', 'Hidden Cobra Malware', 'Ransomware', 'DHS Report TA18-074A'], 'mitre_attack_id': ['T1021.002'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['DE.CM'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_long_dns_txt_record_response.yml</h4>

<table><tr><td>name</td><td>Detect Long DNS TXT Record Response</td></tr><tr><td>id</td><td>05437c07-62f5-452e-afdc-04dd44815bb9</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search is used to detect attempts to use DNS tunneling, by calculating the length of responses to DNS TXT queries. Endpoints using DNS as a method of transmission for data exfiltration, command and control, or evasion of security controls can often be detected by noting unusually large volumes of DNS traffic.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search you need to ingest data from your DNS logs, or monitor DNS traffic using Stream, Bro or something similar. Specifically, this query requires that the DNS data model is populated with information regarding the DNS record type that is being returned as well as the data in the answer section of the protocol.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Resolution where DNS.message_type=response AND DNS.record_type=TXT by DNS.src DNS.dest DNS.answer DNS.record_type |  `drop_dm_object_name("DNS")` | eval anslen=len(answer) | search anslen>100 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename src as "Source IP", dest as "Destination IP", answer as "DNS Answer" anslen as "Answer Length" record_type as "DNS Record Type" firstTime as "First Time" lastTime as "Last Time" count as Count | table "Source IP" "Destination IP" "DNS Answer" "DNS Record Type"  "Answer Length" Count "First Time" "Last Time" | `detect_long_dns_txt_record_response_filter`</td></tr><tr><td>known_false_positives</td><td>It's possible that legitimate TXT record responses can be long enough to trigger this search. You can modify the packet threshold for this search to help mitigate false positives.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious DNS Traffic', 'Command and Control'], 'mitre_attack_id': ['T1071.004'], 'kill_chain_phases': ['Command and Control'], 'cis20': ['CIS 8', 'CIS 12', 'CIS 13'], 'nist': ['PR.DS', 'PR.PT', 'DE.AE', 'DE.CM'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>remote_desktop_network_bruteforce.yml</h4>

<table><tr><td>name</td><td>Remote Desktop Network Bruteforce</td></tr><tr><td>id</td><td>a98727cc-286b-4ff2-b898-41df64695923</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for RDP application network traffic and filters any source/destination pair generating more than twice the standard deviation of the average traffic.</td></tr><tr><td>how_to_implement</td><td>You must ensure that your network traffic data is populating the Network_Traffic data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Jose Hernandez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.app=rdp by All_Traffic.src All_Traffic.dest All_Traffic.dest_port | eventstats stdev(count) AS stdev avg(count) AS avg p50(count) AS p50 | where count>(avg + stdev*2) | rename All_Traffic.src AS src All_Traffic.dest AS dest | table firstTime lastTime src dest count avg p50 stdev | `remote_desktop_network_bruteforce_filter`</td></tr><tr><td>known_false_positives</td><td>RDP gateways may have unusually high amounts of traffic from all other hosts' RDP applications in the network.</td></tr><tr><td>tags</td><td>{'analytics_story': ['SamSam Ransomware'], 'mitre_attack_id': ['T1021.001'], 'kill_chain_phases': ['Reconnaissance', 'Delivery'], 'cis20': ['CIS 12', 'CIS 9', 'CIS 16'], 'nist': ['DE.AE', 'PR.AC', 'PR.IP'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_large_outbound_icmp_packets.yml</h4>

<table><tr><td>name</td><td>Detect Large Outbound ICMP Packets</td></tr><tr><td>id</td><td>e9c102de-4d43-42a7-b1c8-8062ea297419</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2018-06-01</td></tr><tr><td>description</td><td>This search looks for outbound ICMP packets with a packet size larger than 1,000 bytes. Various threat actors have been known to use ICMP as a command and control channel for their attack infrastructure. Large ICMP packets from an endpoint to a remote host may be indicative of this activity.</td></tr><tr><td>how_to_implement</td><td>In order to run this search effectively, we highly recommend that you leverage the Assets and Identity framework. It is important that you have a good understanding of how your network segments are designed and that you are able to distinguish internal from external address space. Add a category named `internal` to the CIDRs that host the company's assets in the `assets_by_cidr.csv` lookup file, which is located in `$SPLUNK_HOME/etc/apps/SA-IdentityManagement/lookups/`. More information on updating this lookup can be found here: https://docs.splunk.com/Documentation/ES/5.0.0/Admin/Addassetandidentitydata. This search also requires you to be ingesting your network traffic and populating the Network_Traffic data model</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count earliest(_time) as firstTime latest(_time) as lastTime values(All_Traffic.action) values(All_Traffic.bytes) from datamodel=Network_Traffic where All_Traffic.action !=blocked All_Traffic.dest_category !=internal (All_Traffic.protocol=icmp OR All_Traffic.transport=icmp) All_Traffic.bytes > 1000 by All_Traffic.src_ip All_Traffic.dest_ip | `drop_dm_object_name("All_Traffic")` | search ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16) | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` | `detect_large_outbound_icmp_packets_filter`</td></tr><tr><td>known_false_positives</td><td>ICMP packets are used in a variety of ways to help troubleshoot networking issues and ensure the proper flow of traffic. As such, it is possible that a large ICMP packet could be perfectly legitimate. If large ICMP packets are associated with command and control traffic, there will typically be a large number of these packets observed over time. If the search is providing a large number of false positives, you can modify the search to adjust the byte threshold or whitelist specific IP addresses, as necessary.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Command and Control'], 'mitre_attack_id': ['T1095'], 'kill_chain_phases': ['Command and Control'], 'cis20': ['CIS 9', 'CIS 12'], 'nist': ['DE.AE'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>protocol_or_port_mismatch.yml</h4>

<table><tr><td>name</td><td>Protocol or Port Mismatch</td></tr><tr><td>id</td><td>54dc1265-2f74-4b6d-b30d-49eb506a31b3</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for network traffic on common ports where a higher layer protocol does not match the port that is being used. For example, this search should identify cases where protocols other than HTTP are running on TCP port 80. This can be used by attackers to circumvent firewall restrictions, or as an attempt to hide malicious communications over ports and protocols that are typically allowed and not well inspected.</td></tr><tr><td>how_to_implement</td><td>Running this search properly requires a technology that can inspect network traffic and identify common protocols. Technologies such as Bro and Palo Alto Networks firewalls are two examples that will identify protocols via inspection, and not just assume a specific protocol based on the transport protocol and ports.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where (All_Traffic.app=dns NOT All_Traffic.dest_port=53) OR ((All_Traffic.app=web-browsing OR All_Traffic.app=http) NOT (All_Traffic.dest_port=80 OR All_Traffic.dest_port=8080 OR All_Traffic.dest_port=8000)) OR (All_Traffic.app=ssl NOT (All_Traffic.dest_port=443 OR All_Traffic.dest_port=8443)) OR (All_Traffic.app=smtp NOT All_Traffic.dest_port=25) by All_Traffic.src_ip, All_Traffic.dest_ip, All_Traffic.app, All_Traffic.dest_port |`security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Traffic")` | `protocol_or_port_mismatch_filter`</td></tr><tr><td>known_false_positives</td><td>None identified</td></tr><tr><td>tags</td><td>{'analytics_story': ['Prohibited Traffic Allowed or Protocol Mismatch', 'Command and Control'], 'mitre_attack_id': ['T1048.003'], 'kill_chain_phases': ['Command and Control'], 'cis20': ['CIS 9', 'CIS 12'], 'nist': ['DE.AE', 'PR.AC'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>dns_record_changed.yml</h4>

<table><tr><td>name</td><td>DNS record changed</td></tr><tr><td>id</td><td>44d3a43e-dcd5-49f7-8356-5209bb369065</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>The search takes the DNS records and their answers results of the discovered_dns_records lookup and finds if any records have changed by searching DNS response from the Network_Resolution datamodel across the last day.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search you will need to ensure that DNS data is populating the `Network_Resolution` data model. It also requires that the `discover_dns_record` lookup table be populated by the included support search "Discover DNS record". \
 **Splunk>Phantom Playbook Integration**\
If Splunk>Phantom is also configured in your environment, a Playbook called "DNS Hijack Enrichment" can be configured to run when any results are found by this detection search. The playbook takes in the DNS record changed and uses Geoip, whois, Censys and PassiveTotal to detect if DNS issuers changed. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/`, add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search, and set the corresponding Playbook to active. \
(Playbook Link:`https://my.phantom.us/4.2/playbook/dns-hijack-enrichment/`).\
</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>Jose Hernandez, Splunk</td></tr><tr><td>search</td><td>| inputlookup discovered_dns_records.csv | rename answer as discovered_answer | join domain[|tstats `security_content_summariesonly` count values(DNS.record_type) as type, values(DNS.answer) as current_answer values(DNS.src) as src from datamodel=Network_Resolution where DNS.message_type=RESPONSE DNS.answer!="unknown" DNS.answer!="" by DNS.query | rename DNS.query as query | where query!="unknown" | rex field=query "(?<domain>\w+\.\w+?)(?:$|/)"] | makemv delim=" " answer |  makemv delim=" " type | sort -count | table count,src,domain,type,query,current_answer,discovered_answer | makemv current_answer  | mvexpand current_answer | makemv discovered_answer | eval n=mvfind(discovered_answer, current_answer) | where isnull(n) | `dns_record_changed_filter`</td></tr><tr><td>known_false_positives</td><td>Legitimate DNS changes can be detected in this search. Investigate, verify and update the list of provided current answers for the domains in question as appropriate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['DNS Hijacking'], 'mitre_attack_id': ['T1071.004'], 'kill_chain_phases': ['Command and Control'], 'cis20': ['CIS 1', 'CIS 3', 'CIS 8', 'CIS 12'], 'nist': ['ID.AM', 'PR.DS', 'PR.IP', 'DE.AE', 'DE.CM'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>prohibited_network_traffic_allowed.yml</h4>

<table><tr><td>name</td><td>Prohibited Network Traffic Allowed</td></tr><tr><td>id</td><td>ce5a0962-849f-4720-a678-753fe6674479</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for network traffic defined by port and transport layer protocol in the Enterprise Security lookup table "lookup_interesting_ports", that is marked as prohibited, and has an associated 'allow' action in the Network_Traffic data model. This could be indicative of a misconfigured network device.</td></tr><tr><td>how_to_implement</td><td>In order to properly run this search, Splunk needs to ingest data from firewalls or other network control devices that mediate the traffic allowed into an environment. This is necessary so that the search can identify an 'action' taken on the traffic of interest. The search requires the Network_Traffic data model be populated.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.action = allowed by All_Traffic.src_ip All_Traffic.dest_ip All_Traffic.dest_port All_Traffic.action | lookup update=true interesting_ports_lookup dest_port as All_Traffic.dest_port OUTPUT app is_prohibited note transport | search is_prohibited=true | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Traffic")` | `prohibited_network_traffic_allowed_filter`</td></tr><tr><td>known_false_positives</td><td>None identified</td></tr><tr><td>tags</td><td>{'analytics_story': ['Prohibited Traffic Allowed or Protocol Mismatch', 'Ransomware', 'Command and Control'], 'mitre_attack_id': ['T1048'], 'kill_chain_phases': ['Delivery', 'Command and Control'], 'cis20': ['CIS 9', 'CIS 12'], 'nist': ['DE.AE', 'PR.AC'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>protocols_passing_authentication_in_cleartext.yml</h4>

<table><tr><td>name</td><td>Protocols passing authentication in cleartext</td></tr><tr><td>id</td><td>6923cd64-17a0-453c-b945-81ac2d8c6db9</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-09-15</td></tr><tr><td>description</td><td>This search looks for cleartext protocols at risk of leaking credentials. Currently, this consists of legacy protocols such as telnet, POP3, IMAP, and non-anonymous FTP sessions. While some of these protocols can be used over SSL, they typically run on different assigned ports in those cases.</td></tr><tr><td>how_to_implement</td><td>This search requires you to be ingesting your network traffic, and populating the Network_Traffic data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.protocol="tcp" AND (All_Traffic.dest_port="23" OR All_Traffic.dest_port="143" OR All_Traffic.dest_port="110" OR (All_Traffic.dest_port="21" AND All_Traffic.user != "anonymous")) groupby All_Traffic.user All_Traffic.src All_Traffic.dest All_Traffic.dest_port | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Traffic")` | `protocols_passing_authentication_in_cleartext_filter`</td></tr><tr><td>known_false_positives</td><td>Some networks may use kerberized FTP or telnet servers, however, this is rare.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Use of Cleartext Protocols'], 'kill_chain_phases': ['Reconnaissance', 'Actions on Objectives'], 'cis20': ['CIS 9', 'CIS 14'], 'nist': ['PR.PT', 'DE.AE', 'PR.AC', 'PR.DS'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detection_of_dns_tunnels.yml</h4>

<table><tr><td>name</td><td>Detection of DNS Tunnels</td></tr><tr><td>id</td><td>104658f4-afdc-499f-9719-17a43f9826f4</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2017-09-18</td></tr><tr><td>description</td><td>This search is used to detect DNS tunneling, by calculating the sum of the length of DNS queries and DNS answers. The search also filters out potential false positives by filtering out queries made to internal systems and the queries originating from internal DNS, Web, and Email servers. Endpoints using DNS as a method of transmission for data exfiltration, command and control, or evasion of security controls can often be detected by noting an unusually large volume of DNS traffic.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, we must ensure that DNS data is being ingested and mapped to the appropriate fields in the Network_Resolution data model. Fields like src_category are automatically provided by the Assets and Identity Framework shipped with Splunk Enterprise Security. You will need to ensure you are using the Assets and Identity Framework and populating the src_category field. You will also need to enable the `cim_corporate_web_domain_search()` macro which will essentially filter out the DNS queries made to the corporate web domains to reduce alert fatigue.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` dc("DNS.query") as count  from datamodel=Network_Resolution  where nodename=DNS "DNS.message_type"="QUERY" NOT (`cim_corporate_web_domain_search("DNS.query")`) NOT "DNS.query"="*.in-addr.arpa" NOT ("DNS.src_category"="svc_infra_dns" OR "DNS.src_category"="svc_infra_webproxy" OR "DNS.src_category"="svc_infra_email*"   ) by "DNS.src","DNS.query" | rename "DNS.src" as src  "DNS.query" as message | eval length=len(message) | stats sum(length) as length by src | append [ tstats `security_content_summariesonly` dc("DNS.answer") as count  from datamodel=Network_Resolution  where nodename=DNS "DNS.message_type"="QUERY" NOT (`cim_corporate_web_domain_search("DNS.query")`) NOT "DNS.query"="*.in-addr.arpa" NOT ("DNS.src_category"="svc_infra_dns" OR "DNS.src_category"="svc_infra_webproxy" OR "DNS.src_category"="svc_infra_email*"   ) by "DNS.src","DNS.answer" | rename "DNS.src" as src  "DNS.answer" as message | eval message=if(message=="unknown","", message) | eval length=len(message) | stats sum(length) as length by src ] | stats sum(length) as length by src | where length > 10000 | `detection_of_dns_tunnels_filter`</td></tr><tr><td>known_false_positives</td><td>It's possible that normal DNS traffic will exhibit this behavior. If an alert is generated, please investigate and validate as appropriate. The threshold can also be modified to better suit your environment.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Data Protection', 'Suspicious DNS Traffic', 'Command and Control'], 'mitre_attack_id': ['T1071.004'], 'kill_chain_phases': ['Command and Control', 'Actions on Objectives'], 'cis20': ['CIS 13'], 'nist': ['PR.PT', 'PR.DS'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>monitor_dns_for_brand_abuse.yml</h4>

<table><tr><td>name</td><td>Monitor DNS For Brand Abuse</td></tr><tr><td>id</td><td>24dd17b1-e2fb-4c31-878c-d4f746595bfa</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-09-23</td></tr><tr><td>description</td><td>This search looks for DNS requests for faux domains similar to the domains that you want to have monitored for abuse.</td></tr><tr><td>how_to_implement</td><td>You need to ingest data from your DNS logs. Specifically you must ingest the domain that is being queried and the IP of the host originating the request. Ideally, you should also be ingesting the answer to the query and the query type. This approach allows you to also create your own localized passive DNS capability which can aid you in future investigations. You also need to have run the search "ESCU - DNSTwist Domain Names", which creates the permutations of the domain that will be checked for.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` values(DNS.answer) as IPs min(_time) as firstTime from datamodel=Network_Resolution by DNS.src, DNS.query | `drop_dm_object_name("DNS")` | `security_content_ctime(firstTime)`| `brand_abuse_dns` | `monitor_dns_for_brand_abuse_filter`</td></tr><tr><td>known_false_positives</td><td>None at this time</td></tr><tr><td>tags</td><td>{'analytics_story': ['Brand Monitoring'], 'kill_chain_phases': ['Delivery', 'Actions on Objectives'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_arp_poisoning.yml</h4>

<table><tr><td>name</td><td>Detect ARP Poisoning</td></tr><tr><td>id</td><td>b44bebd6-bd39-467b-9321-73971bcd7aac</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-08-11</td></tr><tr><td>description</td><td>By enabling Dynamic ARP Inspection as a Layer 2 Security measure on the organization's network devices, we will be able to detect ARP Poisoning attacks in the Infrastructure.</td></tr><tr><td>how_to_implement</td><td>This search uses a standard SPL query on logs from Cisco Network devices. The network devices must be configured with DHCP Snooping (see https://www.cisco.com/c/en/us/td/docs/switches/lan/catalyst2960x/software/15-0_2_EX/security/configuration_guide/b_sec_152ex_2960-x_cg/b_sec_152ex_2960-x_cg_chapter_01101.html) and Dynamic ARP Inspection (see https://www.cisco.com/c/en/us/td/docs/switches/lan/catalyst2960x/software/15-2_2_e/security/configuration_guide/b_sec_1522e_2960x_cg/b_sec_1522e_2960x_cg_chapter_01111.html) and log with a severity level of minimum "5 - notification". The search also requires that the Cisco Networks Add-on for Splunk (https://splunkbase.splunk.com/app/1467) is used to parse the logs from the Cisco network devices.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Mikael Bjerkeland, Splunk</td></tr><tr><td>search</td><td>`cisco_networks` facility="PM" mnemonic="ERR_DISABLE" disable_cause="arp-inspection" | eval src_interface=src_int_prefix_long+src_int_suffix | stats min(_time) AS firstTime max(_time) AS lastTime count BY host src_interface | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`| `detect_arp_poisoning_filter`</td></tr><tr><td>known_false_positives</td><td>This search might be prone to high false positives if DHCP Snooping or ARP inspection has been incorrectly configured, or if a device normally sends many ARP packets (unlikely).</td></tr><tr><td>tags</td><td>{'analytics_story': ['Router and Infrastructure Security'], 'kill_chain_phases': ['Reconnaissance', 'Delivery', 'Actions on Objectives'], 'mitre_attack_id': ['T1200', 'T1498', 'T1557'], 'cis20': ['CIS 1', 'CIS 11'], 'nist': ['ID.AM', 'PR.DS'], 'detection_name': 'Detect ARP Poisoning', 'security_domain': 'network', 'asset_type': 'Infrastructure'}</td></tr></table>
<h4>clients_connecting_to_multiple_dns_servers.yml</h4>

<table><tr><td>name</td><td>Clients Connecting to Multiple DNS Servers</td></tr><tr><td>id</td><td>74ec6f18-604b-4202-a567-86b2066be3ce</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search allows you to identify the endpoints that have connected to more than five DNS servers and made DNS Queries over the time frame of the search.</td></tr><tr><td>how_to_implement</td><td>This search requires that DNS data is being ingested and populating the `Network_Resolution` data model. This data can come from DNS logs or from solutions that parse network traffic for this data, such as Splunk Stream or Bro.\
This search produces fields (`dest_count`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** Distinct DNS Connections, **Field:** dest_count\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count, values(DNS.dest) AS dest dc(DNS.dest) as dest_count from datamodel=Network_Resolution where DNS.message_type=QUERY by DNS.src | `drop_dm_object_name("Network_Resolution")` |where dest_count > 5 | `clients_connecting_to_multiple_dns_servers_filter` </td></tr><tr><td>known_false_positives</td><td>It's possible that an enterprise has more than five DNS servers that are configured in a round-robin rotation. Please customize the search, as appropriate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['DNS Hijacking', 'Command and Control', 'Suspicious DNS Traffic', 'Host Redirection'], 'mitre_attack_id': ['T1048.003'], 'kill_chain_phases': ['Command and Control'], 'cis20': ['CIS 9', 'CIS 12', 'CIS 13'], 'nist': ['PR.PT', 'DE.AE', 'PR.DS'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>tor_traffic.yml</h4>

<table><tr><td>name</td><td>TOR Traffic</td></tr><tr><td>id</td><td>ea688274-9c06-4473-b951-e4cb7a5d7a45</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-22</td></tr><tr><td>description</td><td>This search looks for network traffic identified as The Onion Router (TOR), a benign anonymity network which can be abused for a variety of nefarious purposes.</td></tr><tr><td>how_to_implement</td><td>In order to properly run this search, Splunk needs to ingest data from firewalls or other network control devices that mediate the traffic allowed into an environment. This is necessary so that the search can identify an 'action' taken on the traffic of interest. The search requires the Network_Traffic data model be populated.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.app=tor AND All_Traffic.action=allowed by All_Traffic.src_ip All_Traffic.dest_ip All_Traffic.dest_port All_Traffic.action | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Traffic")` | `tor_traffic_filter`</td></tr><tr><td>known_false_positives</td><td>None at this time</td></tr><tr><td>tags</td><td>{'analytics_story': ['Prohibited Traffic Allowed or Protocol Mismatch', 'Ransomware', 'Command and Control'], 'mitre_attack_id': ['T1071.001'], 'kill_chain_phases': ['Command and Control'], 'cis20': ['CIS 9', 'CIS 12'], 'nist': ['DE.AE'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>excessive_dns_failures.yml</h4>

<table><tr><td>name</td><td>Excessive DNS Failures</td></tr><tr><td>id</td><td>104658f4-afdc-499e-9719-17243f9826f1</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search identifies DNS query failures by counting the number of DNS responses that do not indicate success, and trigger on more than 50 occurrences.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search you must ensure that DNS data is populating the Network_Resolution data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values("DNS.query") as queries from datamodel=Network_Resolution where nodename=DNS "DNS.reply_code"!="No Error" "DNS.reply_code"!="NoError" DNS.reply_code!="unknown" NOT "DNS.query"="*.arpa" "DNS.query"="*.*" by "DNS.src","DNS.query"| `drop_dm_object_name("DNS")`| lookup cim_corporate_web_domain_lookup domain as query OUTPUT domain| where isnull(domain)| lookup update=true alexa_lookup_by_str domain as query OUTPUT rank| where isnull(rank)| stats sum(count) as count mode(queries) as queries by src| `get_asset(src)`| where count>50 | `excessive_dns_failures_filter`</td></tr><tr><td>known_false_positives</td><td>It is possible legitimate traffic can trigger this rule. Please investigate as appropriate. The threshold for generating an event can also be customized to better suit your environment.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious DNS Traffic', 'Command and Control'], 'mitre_attack_id': ['T1071.004'], 'kill_chain_phases': ['Command and Control'], 'cis20': ['CIS 8', 'CIS 9', 'CIS 12'], 'nist': ['PR.PT', 'DE.AE', 'DE.CM'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_dns_requests_to_phishing_sites_leveraging_evilginx2.yml</h4>

<table><tr><td>name</td><td>Detect DNS requests to Phishing Sites leveraging EvilGinx2</td></tr><tr><td>id</td><td>24dd17b1-e2fb-4c31-878c-d4f226595bfa</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for DNS requests for phishing domains that are leveraging EvilGinx tools to mimic websites.</td></tr><tr><td>how_to_implement</td><td>You need to ingest data from your DNS logs in the Network_Resolution datamodel. Specifically you must ingest the domain that is being queried and the IP of the host originating the request. Ideally, you should also be ingesting the answer to the query and the query type. This approach allows you to also create your own localized passive DNS capability which can aid you in future investigations. You will have to add legitimate domain names to the `legit_domains.csv` file shipped with the app. \
 **Splunk>Phantom Playbook Integration**\
If Splunk>Phantom is also configured in your environment, a Playbook called `Lets Encrypt Domain Investigate` can be configured to run when any results are found by this detection search. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/`, add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search, and set the corresponding Playbook to active. \
(Playbook link:`https://my.phantom.us/4.2/playbook/lets-encrypt-domain-investigate/`).\
</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(DNS.answer) as answer from datamodel=Network_Resolution.DNS by DNS.dest DNS.src DNS.query host | `drop_dm_object_name(DNS)`| rex field=query ".*?(?<domain>[^./:]+\.(\S{2,3}|\S{2,3}.\S{2,3}))$" | stats count values(query) as query by domain dest src answer| search `evilginx_phishlets_amazon` OR `evilginx_phishlets_facebook` OR `evilginx_phishlets_github` OR `evilginx_phishlets_0365` OR `evilginx_phishlets_outlook` OR `evilginx_phishlets_aws` OR `evilginx_phishlets_google` | search NOT [ inputlookup legit_domains.csv | fields domain]| join domain type=outer [| tstats count `security_content_summariesonly` values(Web.url) as url from datamodel=Web.Web by Web.dest Web.site | rename "Web.*" as * | rex field=site ".*?(?<domain>[^./:]+\.(\S{2,3}|\S{2,3}.\S{2,3}))$" | table dest domain url] | table count src dest query answer domain url | `detect_dns_requests_to_phishing_sites_leveraging_evilginx2_filter`</td></tr><tr><td>known_false_positives</td><td>If a known good domain is not listed in the legit_domains.csv file, then the search could give you false postives. Please update that lookup file to filter out DNS requests to legitimate domains.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Common Phishing Frameworks'], 'mitre_attack_id': ['T1566.003'], 'kill_chain_phases': ['Delivery', 'Command and Control'], 'cis20': ['CIS 8', 'CIS 7'], 'nist': ['ID.AM', 'PR.DS', 'PR.IP', 'DE.AE', 'DE.CM'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>dns_query_length_with_high_standard_deviation.yml</h4>

<table><tr><td>name</td><td>DNS Query Length With High Standard Deviation</td></tr><tr><td>id</td><td>1a67f15a-f4ff-4170-84e9-08cf6f75d6f5</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search allows you to identify DNS requests and compute the standard deviation on the length of the names being resolved, then filter on two times the standard deviation to show you those queries that are unusually large for your environment.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you will need to ensure that DNS data is populating the Network_Resolution data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count from datamodel=Network_Resolution by DNS.query DNS.record_type |  `drop_dm_object_name("DNS")` | eval query_length = len(query) | table query query_length record_type count | eventstats stdev(query_length) AS stdev avg(query_length) AS avg p50(query_length) AS p50| where query_length>(avg+stdev*2) | eval z_score=(query_length-avg)/stdev | `dns_query_length_with_high_standard_deviation_filter` </td></tr><tr><td>known_false_positives</td><td>It's possible there can be long domain names that are legitimate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Hidden Cobra Malware', 'Suspicious DNS Traffic', 'Command and Control'], 'mitre_attack_id': ['T1071.004'], 'kill_chain_phases': ['Command and Control'], 'cis20': ['CIS 8', 'CIS 12'], 'nist': ['PR.PT', 'DE.AE', 'DE.CM'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>remote_desktop_network_traffic.yml</h4>

<table><tr><td>name</td><td>Remote Desktop Network Traffic</td></tr><tr><td>id</td><td>272b8407-842d-4b3d-bead-a704584003d3</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-07</td></tr><tr><td>description</td><td>This search looks for network traffic on TCP/3389, the default port used by remote desktop. While remote desktop traffic is not uncommon on a network, it is usually associated with known hosts. This search allows for whitelisting both source and destination hosts to remove them from the output of the search so you can focus on the uncommon uses of remote desktop on your network.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search you need to identify systems that commonly originate remote desktop traffic and that commonly receive remote desktop traffic. You can use the included support search "Identify Systems Creating Remote Desktop Traffic" to identify systems that originate the traffic and the search "Identify Systems Receiving Remote Desktop Traffic" to identify systems that receive a lot of remote desktop traffic. After identifying these systems, you will need to add the "common_rdp_source" or "common_rdp_destination" category to that system depending on the usage, using the Enterprise Security Assets and Identities framework.  This can be done by adding an entry in the assets.csv file located in SA-IdentityManagement/lookups.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.dest_port=3389 AND All_Traffic.dest_category!=common_rdp_destination AND All_Traffic.src_category!=common_rdp_source by All_Traffic.src All_Traffic.dest All_Traffic.dest_port | `drop_dm_object_name("All_Traffic")` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `remote_desktop_network_traffic_filter` </td></tr><tr><td>known_false_positives</td><td>Remote Desktop may be used legitimately by users on the network.</td></tr><tr><td>tags</td><td>{'analytics_story': ['SamSam Ransomware', 'Hidden Cobra Malware', 'Lateral Movement'], 'mitre_attack_id': ['T1021.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 9', 'CIS 16'], 'nist': ['DE.AE', 'PR.AC', 'PR.IP'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>

<h2>endpoint</h2>


<h4>detect_computer_changed_with_anonymous_account.yml</h4>

<table><tr><td>name</td><td>Detect Computer Changed with Anonymous Account</td></tr><tr><td>id</td><td>1400624a-d42d-484d-8843-e6753e6e3645</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-09-18</td></tr><tr><td>description</td><td>This search looks for Event Code 4742 (Computer Change) or EventCode 4624 (An account was successfully logged on) with an anonymous account.</td></tr><tr><td>how_to_implement</td><td>This search requires audit computer account management to be enabled on the system in order to generate Event ID 4742. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Event Logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://www.lares.com/blog/from-lares-labs-defensive-guidance-for-zerologon-cve-2020-1472/']</td></tr><tr><td>author</td><td>Rod Soto, Jose Hernandez, Splunk</td></tr><tr><td>search</td><td>`wineventlog_security` EventCode=4624 OR EventCode=4742 TargetUserName="ANONYMOUS LOGON" LogonType=3 | stats count values(host) as host, values(TargetDomainName) as Domain, values(user) as user | `detect_computer_changed_with_anonymous_account_filter`</td></tr><tr><td>known_false_positives</td><td>None thus far found</td></tr><tr><td>tags</td><td>{'analytics_story': ['Detect Zerologon Attack'], 'mitre_attack_id': ['T1210'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 6', 'CIS 8'], 'nist': ['DE.AE', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Windows'}</td></tr></table>
<h4>malicious_powershell_process___multiple_suspicious_command_line_arguments.yml</h4>

<table><tr><td>name</td><td>Malicious PowerShell Process - Multiple Suspicious Command-Line Arguments</td></tr><tr><td>id</td><td>2cdb91d2-542c-497f-b252-be495e71f38c</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for PowerShell processes started with a base64 encoded command-line passed to it, with parameters to modify the execution policy for the process, and those that prevent the display of an interactive prompt to the user. This combination of command-line options is suspicious because it overrides the default PowerShell execution policy, attempts to hide itself from the user, and passes an encoded script to be run on the command-line.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| search (process=*-EncodedCommand* OR process=*-enc*) process=*-Exec* AND process=*-NonI* | `malicious_powershell_process___multiple_suspicious_command_line_arguments_filter`</td></tr><tr><td>known_false_positives</td><td>Legitimate process can have this combination of command-line options, but it's not common.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Malicious PowerShell'], 'mitre_attack_id': ['T1059.001'], 'kill_chain_phases': ['Command and Control', 'Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 7', 'CIS 8'], 'nist': ['PR.PT', 'DE.CM', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>remote_wmi_command_attempt.yml</h4>

<table><tr><td>name</td><td>Remote WMI Command Attempt</td></tr><tr><td>id</td><td>272df6de-61f1-4784-877c-1fbc3e2d0838</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2018-12-03</td></tr><tr><td>description</td><td>This search looks for wmic.exe being launched with parameters to operate on remote systems.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=wmic.exe  AND Processes.process= */node* by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `remote_wmi_command_attempt_filter`</td></tr><tr><td>known_false_positives</td><td>Administrators may use this legitimately to gather info from remote systems.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious WMI Use'], 'mitre_attack_id': ['T1047'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 5'], 'nist': ['PR.PT', 'PR.AT', 'PR.AC', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>reg_exe_manipulating_windows_services_registry_keys.yml</h4>

<table><tr><td>name</td><td>Reg exe Manipulating Windows Services Registry Keys</td></tr><tr><td>id</td><td>8470d755-0c13-45b3-bd63-387a373c10cf</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>The search looks for reg.exe modifying registry keys that define Windows services and their configurations.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Processes.process_name) as process_name values(Processes.parent_process_name) as parent_process_name values(Processes.user) as user FROM datamodel=Endpoint.Processes where Processes.process_name=reg.exe Processes.process=*reg* Processes.process=*add* Processes.process=*Services* by Processes.process_id Processes.dest Processes.process | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `reg_exe_manipulating_windows_services_registry_keys_filter`</td></tr><tr><td>known_false_positives</td><td>It is unusual for a service to be created or modified by directly manipulating the registry. However, there may be legitimate instances of this behavior. It is important to validate and investigate, as appropriate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Service Abuse', 'Windows Persistence Techniques'], 'mitre_attack_id': ['T1547.001'], 'kill_chain_phases': ['Installation'], 'cis20': ['CIS 3', 'CIS 5', 'CIS 8'], 'nist': ['PR.IP', 'PR.PT', 'PR.AC', 'PR.AT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>registry_keys_for_creating_shim_databases.yml</h4>

<table><tr><td>name</td><td>Registry Keys for Creating SHIM Databases</td></tr><tr><td>id</td><td>f5f6af30-7aa7-4295-bfe9-07fe87c01bbb</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for registry activity associated with application compatibility shims, which can be leveraged by attackers for various nefarious purposes.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must populate the Change_Analysis data model. This is typically populated via endpoint detection and response products, such as Carbon Black or other endpoint data sources such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis.All_Changes where All_Changes.object_category=registry AND (All_Changes.object_path="*CurrentVersion\\AppCompatFlags\\Custom*" OR All_Changes.object_path="*CurrentVersion\\AppCompatFlags\\InstalledSDB*") by All_Changes.dest, All_Changes.command, All_Changes.user, All_Changes.object, All_Changes.object_path | `drop_dm_object_name("All_Changes")` | `registry_keys_for_creating_shim_databases_filter`</td></tr><tr><td>known_false_positives</td><td>There are many legitimate applications that leverage shim databases for compatibility purposes for legacy applications</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious Windows Registry Activities', 'Windows Persistence Techniques'], 'mitre_attack_id': ['T1546.011'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>create_local_admin_accounts_using_net_exe.yml</h4>

<table><tr><td>name</td><td>Create local admin accounts using net exe</td></tr><tr><td>id</td><td>b89919ed-fe5f-492c-b139-151bb162040e</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for the creation of local administrator accounts using net.exe.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.user) as user values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process_name=net.exe OR Processes.process_name=net1.exe) AND (Processes.process=*localgroup* OR Processes.process=*/add* OR Processes.process=*user*) by Processes.process Processes.process_name Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` |`create_local_admin_accounts_using_net_exe_filter` </td></tr><tr><td>known_false_positives</td><td>Administrators often leverage net.exe to create admin accounts.</td></tr><tr><td>tags</td><td>{'analytics_story': ['DHS Report TA18-074A'], 'mitre_attack_id': ['T1136.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_new_local_admin_account.yml</h4>

<table><tr><td>name</td><td>Detect New Local Admin account</td></tr><tr><td>id</td><td>b25f6f62-0712-43c1-b203-083231ffd97d</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-08</td></tr><tr><td>description</td><td>This search looks for newly created accounts that have been elevated to local administrators.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>`wineventlog_security` EventID=4720 OR (EventID=4732 Group_Name=Administrators) | transaction MemberSid connected=false maxspan=180m | rename MemberSid as user | stats count min(_time) as firstTime max(_time) as lastTime by user dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_new_local_admin_account_filter`</td></tr><tr><td>known_false_positives</td><td>The activity may be legitimate. For this reason, it's best to verify the account with an administrator and ask whether there was a valid service request for the account creation. If your local administrator group name is not "Administrators", this search may generate an excessive number of false positives</td></tr><tr><td>tags</td><td>{'analytics_story': ['DHS Report TA18-074A'], 'mitre_attack_id': ['T1136.001'], 'kill_chain_phases': ['Actions on Objectives', 'Command and Control'], 'cis20': ['CIS 16'], 'nist': ['PR.AC', 'DE.CM'], 'security_domain': 'access', 'asset_type': 'Windows'}</td></tr></table>
<h4>process_execution_via_wmi.yml</h4>

<table><tr><td>name</td><td>Process Execution via WMI</td></tr><tr><td>id</td><td>24869767-8579-485d-9a4f-d9ddfd8f0cac</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-03-16</td></tr><tr><td>description</td><td>This search looks for processes launched via WMI.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.parent_process_name = *WmiPrvSE.exe by Processes.user Processes.dest Processes.process_name  | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| `process_execution_via_wmi_filter` </td></tr><tr><td>known_false_positives</td><td>Although unlikely, administrators may use wmi to execute commands for legitimate purposes.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious WMI Use'], 'mitre_attack_id': ['T1047'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 5'], 'nist': ['PR.PT', 'PR.AT', 'PR.AC', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>disabling_remote_user_account_control.yml</h4>

<table><tr><td>name</td><td>Disabling Remote User Account Control</td></tr><tr><td>id</td><td>bbc644bc-37df-4e1a-9c88-ec9a53e2038c</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-03-02</td></tr><tr><td>description</td><td>The search looks for modifications to registry keys that control the enforcement of Windows User Account Control (UAC).</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must be ingesting data that records registry activity from your hosts to populate the endpoint data model in the registry node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or via other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report registry modifications.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where Registry.registry_path="*Windows\\CurrentVersion\\Policies\\System\\LocalAccountTokenFilterPolicy" by Registry.dest, Registry.registry_key_name Registry.user Registry.registry_path Registry.action | `drop_dm_object_name(Registry)` | `disabling_remote_user_account_control_filter`</td></tr><tr><td>known_false_positives</td><td>This registry key may be modified via administrators to implement a change in system policy. This type of change should be a very rare occurrence.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Defense Evasion Tactics', 'Suspicious Windows Registry Activities'], 'mitre_attack_id': ['T1112'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>malicious_powershell_process_with_obfuscation_techniques.yml</h4>

<table><tr><td>name</td><td>Malicious PowerShell Process With Obfuscation Techniques</td></tr><tr><td>id</td><td>cde75cf6-3c7a-4dd6-af01-27cdb4511fd4</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for PowerShell processes launched with arguments that have characters indicative of obfuscation on the command-line.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest Processes.process | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| eval num_obfuscation = (mvcount(split(process, "`"))-1) + (mvcount(split(process, "^"))-1) | `malicious_powershell_process_with_obfuscation_techniques_filter` | search num_obfuscation > 0</td></tr><tr><td>known_false_positives</td><td>These characters might be legitimately on the command-line, but it is not common.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Malicious PowerShell'], 'mitre_attack_id': ['T1059.001'], 'kill_chain_phases': ['Command and Control', 'Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 7', 'CIS 8'], 'nist': ['PR.PT', 'DE.CM', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>system_process_running_unexpected_location___ssa.yml</h4>

<table><tr><td>name</td><td>System Process Running from Unexpected Location - SSA</td></tr><tr><td>id</td><td>28179107-099a-464a-94d3-08301e6c055f</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-08-25</td></tr><tr><td>description</td><td>An attacker tries might try to use different version of a system command without overriding original, or they might try to avoid some detection running the process from a different folder. This detection checks that a list of system processes run inside C:\\Windows\System32 or C:\\Windows\SysWOW64 The list of system processes has been extracted from https://github.com/splunk/security-content/blob/develop/lookups/is_windows_system_file.csv and the original detection https://github.com/splunk/security-content/blob/develop/detections/system_processes_run_from_unexpected_locations.yml</td></tr><tr><td>how_to_implement</td><td>Collect endpoint data such as sysmon or 4688 events.</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>type</td><td>SSA</td></tr><tr><td>author</td><td>Ignacio Bermudez Corrales, Splunk</td></tr><tr><td>search</td><td> | from read_ssa_enriched_events() | eval device=ucast(map_get(input_event, "dest_device_id"), "string", null), timestamp=parse_long(ucast(map_get(input_event, "_time"), "string", null)), process_name=lower(ucast(map_get(input_event, "process_name"), "string", null)), process_path=lower(ucast(map_get(input_event, "process_path"), "string", null)), | where process_name="arp.exe" OR process_name="adaptertroubleshooter.exe" OR process_name="applicationframehost.exe" OR process_name="atbroker.exe" OR process_name="authhost.exe" OR process_name="autoworkplace.exe" OR process_name="axinstui.exe" OR process_name="backgroundtransferhost.exe" OR process_name="bdehdcfg.exe" OR process_name="bdeuisrv.exe" OR process_name="bdeunlockwizard.exe" OR process_name="bitlockerdeviceencryption.exe" OR process_name="bitlockerwizard.exe" OR process_name="bitlockerwizardelev.exe" OR process_name="bytecodegenerator.exe" OR process_name="camerasettingsuihost.exe" OR process_name="castsrv.exe" OR process_name="certenrollctrl.exe" OR process_name="checknetisolation.exe" OR process_name="clipup.exe" OR process_name="cloudexperiencehostbroker.exe" OR process_name="cloudnotifications.exe" OR process_name="cloudstoragewizard.exe" OR process_name="compmgmtlauncher.exe" OR process_name="compattelrunner.exe" OR process_name="computerdefaults.exe" OR process_name="credentialuibroker.exe" OR process_name="dfdwiz.exe" OR process_name="dwwin.exe" OR process_name="dataexchangehost.exe" OR process_name="defrag.exe" OR process_name="devicedisplayobjectprovider.exe" OR process_name="deviceeject.exe" OR process_name="deviceenroller.exe" OR process_name="devicepairingwizard.exe" OR process_name="deviceproperties.exe" OR process_name="disksnapshot.exe" OR process_name="dism.exe" OR process_name="displayswitch.exe" OR process_name="dmnotificationbroker.exe" OR process_name="dmomacpmo.exe" OR process_name="dpiscaling.exe" OR process_name="dsmusertask.exe" OR process_name="dxpserver.exe" OR process_name="edpcleanup.exe" OR process_name="eosnotify.exe" OR process_name="eap3host.exe" OR process_name="easpoliciesbrokerhost.exe" OR process_name="easeofaccessdialog.exe" OR process_name="ehstorauthn.exe" OR process_name="fxscover.exe" OR process_name="fxssvc.exe" OR process_name="fxsunatd.exe" OR process_name="filehistory.exe" OR process_name="fondue.exe" OR process_name="gamepanel.exe" OR process_name="genvalobj.exe" OR process_name="gettingstarted.exe" OR process_name="hostname.exe" OR process_name="icsentitlementhost.exe" OR process_name="infdefaultinstall.exe" OR process_name="installagent.exe" OR process_name="languagecomponentsinstallercomhandler.exe" OR process_name="launchtm.exe" OR process_name="launchwinapp.exe" OR process_name="legacynetuxhost.exe" OR process_name="licensemanagershellext.exe" OR process_name="licensingui.exe" OR process_name="locationnotificationwindows.exe" OR process_name="locationnotifications.exe" OR process_name="locator.exe" OR process_name="lockapphost.exe" OR process_name="lockscreencontentserver.exe" OR process_name="logonui.exe" OR process_name="lsaiso.exe" OR process_name="mdeserver.exe" OR process_name="mdmagent.exe" OR process_name="mdmappinstaller.exe" OR process_name="mrinfo.exe" OR process_name="mrt.exe" OR process_name="mschedexe.exe" OR process_name="magnify.exe" OR process_name="mbaeparsertask.exe" OR process_name="mdres.exe" OR process_name="mdsched.exe" OR process_name="migautoplay.exe" OR process_name="mpsigstub.exe" OR process_name="msspellcheckinghost.exe" OR process_name="muiunattend.exe" OR process_name="multidigimon.exe" OR process_name="musnotification.exe" OR process_name="musnotificationux.exe" OR process_name="napstat.exe" OR process_name="netstat.exe" OR process_name="narrator.exe" OR process_name="netcfgnotifyobjecthost.exe" OR process_name="netevtfwdr.exe" OR process_name="netproj.exe" OR process_name="netplwiz.exe" OR process_name="networkuxbroker.exe" OR process_name="openwith.exe" OR process_name="optionalfeatures.exe" OR process_name="pathping.exe" OR process_name="ping.exe" OR process_name="passwordonwakesettingflyout.exe" OR process_name="pickerhost.exe" OR process_name="pkgmgr.exe" OR process_name="pnpunattend.exe" OR process_name="pnputil.exe" OR process_name="presentationhost.exe" OR process_name="presentationsettings.exe" OR process_name="printbrmui.exe" OR process_name="printdialoghost.exe" OR process_name="printdialoghost3d.exe" OR process_name="printisolationhost.exe" OR process_name="proximityuxhost.exe" OR process_name="rdspnf.exe" OR process_name="rmactivate.exe" OR process_name="rmactivate_isv.exe" OR process_name="rmactivate_ssp.exe" OR process_name="rmactivate_ssp_isv.exe" OR process_name="route.exe" OR process_name="rdpsa.exe" OR process_name="rdpsaproxy.exe" OR process_name="rdpsauachelper.exe" OR process_name="reagentc.exe" OR process_name="recoverydrive.exe" OR process_name="register-cimprovider.exe" OR process_name="registeriepkeys.exe" OR process_name="relpost.exe" OR process_name="remoteposworker.exe" OR process_name="rmclient.exe" OR process_name="robocopy.exe" OR process_name="rpcping.exe" OR process_name="runlegacycplelevated.exe" OR process_name="runtimebroker.exe" OR process_name="sihclient.exe" OR process_name="searchfilterhost.exe" OR process_name="searchindexer.exe" OR process_name="searchprotocolhost.exe" OR process_name="secedit.exe" OR process_name="sensordataservice.exe" OR process_name="setieinstalleddate.exe" OR process_name="settingsynchost.exe" OR process_name="slidetoshutdown.exe" OR process_name="smartscreensettings.exe" OR process_name="sndvol.exe" OR process_name="snippingtool.exe" OR process_name="soundrecorder.exe" OR process_name="spaceagent.exe" OR process_name="sppextcomobj.exe" OR process_name="srtasks.exe" OR process_name="stikynot.exe" OR process_name="synchost.exe" OR process_name="sysreseterr.exe" OR process_name="systempropertiesadvanced.exe" OR process_name="systempropertiescomputername.exe" OR process_name="systempropertiesdataexecutionprevention.exe" OR process_name="systempropertieshardware.exe" OR process_name="systempropertiesperformance.exe" OR process_name="systempropertiesprotection.exe" OR process_name="systempropertiesremote.exe" OR process_name="systemsettingsadminflows.exe" OR process_name="systemsettingsbroker.exe" OR process_name="systemsettingsremovedevice.exe" OR process_name="tcpsvcs.exe" OR process_name="tracert.exe" OR process_name="tstheme.exe" OR process_name="tswbprxy.exe" OR process_name="tapiunattend.exe" OR process_name="taskmgr.exe" OR process_name="thumbnailextractionhost.exe" OR process_name="tokenbrokercookies.exe" OR process_name="tpminit.exe" OR process_name="tswpfwrp.exe" OR process_name="ui0detect.exe" OR process_name="upgraderesultsui.exe" OR process_name="useraccountbroker.exe" OR process_name="useraccountcontrolsettings.exe" OR process_name="usoclient.exe" OR process_name="utilman.exe" OR process_name="vssvc.exe" OR process_name="vaultcmd.exe" OR process_name="vaultsysui.exe" OR process_name="wfs.exe" OR process_name="wmpdmc.exe" OR process_name="wpdshextautoplay.exe" OR process_name="wscollect.exe" OR process_name="wsmanhttpconfig.exe" OR process_name="wsreset.exe" OR process_name="wudfhost.exe" OR process_name="wwahost.exe" OR process_name="wallpaperhost.exe" OR process_name="webcache.exe" OR process_name="werfault.exe" OR process_name="werfaultsecure.exe" OR process_name="winsat.exe" OR process_name="windows.media.backgroundplayback.exe" OR process_name="windowsactiondialog.exe" OR process_name="windowsanytimeupgrade.exe" OR process_name="windowsanytimeupgraderesults.exe" OR process_name="windowsanytimeupgradeui.exe" OR process_name="windowsupdateelevatedinstaller.exe" OR process_name="workfolders.exe" OR process_name="wpcmon.exe" OR process_name="acu.exe" OR process_name="aitagent.exe" OR process_name="aitstatic.exe" OR process_name="alg.exe" OR process_name="appidcertstorecheck.exe" OR process_name="appidpolicyconverter.exe" OR process_name="at.exe" OR process_name="attrib.exe" OR process_name="audiodg.exe" OR process_name="auditpol.exe" OR process_name="autochk.exe" OR process_name="autoconv.exe" OR process_name="autofmt.exe" OR process_name="baaupdate.exe" OR process_name="backgroundtaskhost.exe" OR process_name="bcastdvr.exe" OR process_name="bcdboot.exe" OR process_name="bcdedit.exe" OR process_name="bdechangepin.exe" OR process_name="bdeunlock.exe" OR process_name="bitsadmin.exe" OR process_name="bootcfg.exe" OR process_name="bootim.exe" OR process_name="bootsect.exe" OR process_name="bridgeunattend.exe" OR process_name="browser_broker.exe" OR process_name="bthudtask.exe" OR process_name="cacls.exe" OR process_name="calc.exe" OR process_name="cdpreference.exe" OR process_name="certreq.exe" OR process_name="certutil.exe" OR process_name="change.exe" OR process_name="changepk.exe" OR process_name="charmap.exe" OR process_name="chglogon.exe" OR process_name="chgport.exe" OR process_name="chgusr.exe" OR process_name="chkdsk.exe" OR process_name="chkntfs.exe" OR process_name="choice.exe" OR process_name="cipher.exe" OR process_name="cleanmgr.exe" OR process_name="cliconfg.exe" OR process_name="clip.exe" OR process_name="cmd.exe" OR process_name="cmdkey.exe" OR process_name="cmdl32.exe" OR process_name="cmmon32.exe" OR process_name="cmstp.exe" OR process_name="cofire.exe" OR process_name="colorcpl.exe" OR process_name="comp.exe" OR process_name="compact.exe" OR process_name="conhost.exe" OR process_name="consent.exe" OR process_name="control.exe" OR process_name="convert.exe" OR process_name="credwiz.exe" OR process_name="cscript.exe" OR process_name="csrss.exe" OR process_name="ctfmon.exe" OR process_name="cttune.exe" OR process_name="cttunesvr.exe" OR process_name="dashost.exe" OR process_name="dccw.exe" OR process_name="dcomcnfg.exe" OR process_name="ddodiag.exe" OR process_name="dfrgui.exe" OR process_name="dialer.exe" OR process_name="diantz.exe" OR process_name="dinotify.exe" OR process_name="diskpart.exe" OR process_name="diskperf.exe" OR process_name="diskraid.exe" OR process_name="dispdiag.exe" OR process_name="djoin.exe" OR process_name="dllhost.exe" OR process_name="dllhst3g.exe" OR process_name="dmcertinst.exe" OR process_name="dmcfghost.exe" OR process_name="dmclient.exe" OR process_name="dnscacheugc.exe" OR process_name="doskey.exe" OR process_name="dpapimig.exe" OR process_name="dpnsvr.exe" OR process_name="driverquery.exe" OR process_name="drvcfg.exe" OR process_name="drvinst.exe" OR process_name="dsregcmd.exe" OR process_name="dstokenclean.exe" OR process_name="dvdplay.exe" OR process_name="dvdupgrd.exe" OR process_name="dwm.exe" OR process_name="dxdiag.exe" OR process_name="easinvoker.exe" OR process_name="efsui.exe" OR process_name="embeddedapplauncher.exe" OR process_name="esentutl.exe" OR process_name="eudcedit.exe" OR process_name="eventcreate.exe" OR process_name="eventvwr.exe" OR process_name="expand.exe" OR process_name="extrac32.exe" OR process_name="fc.exe" OR process_name="fhmanagew.exe" OR process_name="find.exe" OR process_name="findstr.exe" OR process_name="finger.exe" OR process_name="fixmapi.exe" OR process_name="fltmc.exe" OR process_name="fodhelper.exe" OR process_name="fontdrvhost.exe" OR process_name="fontview.exe" OR process_name="forfiles.exe" OR process_name="fsavailux.exe" OR process_name="fsquirt.exe" OR process_name="fsutil.exe" OR process_name="ftp.exe" OR process_name="fvenotify.exe" OR process_name="fveprompt.exe" OR process_name="getmac.exe" OR process_name="gpresult.exe" OR process_name="gpscript.exe" OR process_name="gpupdate.exe" OR process_name="grpconv.exe" OR process_name="hdwwiz.exe" OR process_name="help.exe" OR process_name="hwrcomp.exe" OR process_name="hwrreg.exe" OR process_name="icacls.exe" OR process_name="icardagt.exe" OR process_name="icsunattend.exe" OR process_name="ie4uinit.exe" OR process_name="ieunatt.exe" OR process_name="ieetwcollector.exe" OR process_name="iexpress.exe" OR process_name="immersivetpmvscmgrsvr.exe" OR process_name="ipconfig.exe" OR process_name="irftp.exe" OR process_name="iscsicli.exe" OR process_name="iscsicpl.exe" OR process_name="isoburn.exe" OR process_name="klist.exe" OR process_name="ksetup.exe" OR process_name="ktmutil.exe" OR process_name="label.exe" OR process_name="licensingdiag.exe" OR process_name="lodctr.exe" OR process_name="logagent.exe" OR process_name="logman.exe" OR process_name="logoff.exe" OR process_name="lpkinstall.exe" OR process_name="lpksetup.exe" OR process_name="lpremove.exe" OR process_name="lsass.exe" OR process_name="lsm.exe" OR process_name="makecab.exe" OR process_name="manage-bde.exe" OR process_name="mblctr.exe" OR process_name="mcbuilder.exe" OR process_name="mctadmin.exe" OR process_name="mfpmp.exe" OR process_name="mmc.exe" OR process_name="mobsync.exe" OR process_name="mountvol.exe" OR process_name="mpnotify.exe" OR process_name="msconfig.exe" OR process_name="msdt.exe" OR process_name="msdtc.exe" OR process_name="msfeedssync.exe" OR process_name="msg.exe" OR process_name="mshta.exe" OR process_name="msiexec.exe" OR process_name="msinfo32.exe" OR process_name="mspaint.exe" OR process_name="msra.exe" OR process_name="mstsc.exe" OR process_name="mtstocom.exe" OR process_name="nbtstat.exe" OR process_name="ndadmin.exe" OR process_name="net.exe" OR process_name="net1.exe" OR process_name="netbtugc.exe" OR process_name="netcfg.exe" OR process_name="netiougc.exe" OR process_name="netsh.exe" OR process_name="newdev.exe" OR process_name="nltest.exe" OR process_name="notepad.exe" OR process_name="nslookup.exe" OR process_name="ntoskrnl.exe" OR process_name="ntprint.exe" OR process_name="ocsetup.exe" OR process_name="odbcad32.exe" OR process_name="odbcconf.exe" OR process_name="omadmclient.exe" OR process_name="omadmprc.exe" OR process_name="openfiles.exe" OR process_name="osk.exe" OR process_name="p2phost.exe" OR process_name="pcalua.exe" OR process_name="pcaui.exe" OR process_name="pcawrk.exe" OR process_name="pcwrun.exe" OR process_name="perfmon.exe" OR process_name="phoneactivate.exe" OR process_name="plasrv.exe" OR process_name="poqexec.exe" OR process_name="powercfg.exe" OR process_name="prevhost.exe" OR process_name="print.exe" OR process_name="printfilterpipelinesvc.exe" OR process_name="printui.exe" OR process_name="proquota.exe" OR process_name="provtool.exe" OR process_name="psr.exe" OR process_name="pwlauncher.exe" OR process_name="qappsrv.exe" OR process_name="qprocess.exe" OR process_name="query.exe" OR process_name="quser.exe" OR process_name="qwinsta.exe" OR process_name="rasautou.exe" OR process_name="rasdial.exe" OR process_name="raserver.exe" OR process_name="rasphone.exe" OR process_name="rdpclip.exe" OR process_name="rdpinput.exe" OR process_name="rdrleakdiag.exe" OR process_name="recdisc.exe" OR process_name="recover.exe" OR process_name="reg.exe" OR process_name="regedt32.exe" OR process_name="regini.exe" OR process_name="regsvr32.exe" OR process_name="rekeywiz.exe" OR process_name="relog.exe" OR process_name="repair-bde.exe" OR process_name="replace.exe" OR process_name="reset.exe" OR process_name="resmon.exe" OR process_name="rmttpmvscmgrsvr.exe" OR process_name="rrinstaller.exe" OR process_name="rstrui.exe" OR process_name="runas.exe" OR process_name="rundll32.exe" OR process_name="runonce.exe" OR process_name="rwinsta.exe" OR process_name="sbunattend.exe" OR process_name="sc.exe" OR process_name="schtasks.exe" OR process_name="sdbinst.exe" OR process_name="sdchange.exe" OR process_name="sdclt.exe" OR process_name="sdiagnhost.exe" OR process_name="secinit.exe" OR process_name="services.exe" OR process_name="sessionmsg.exe" OR process_name="sethc.exe" OR process_name="setspn.exe" OR process_name="setupcl.exe" OR process_name="setupugc.exe" OR process_name="setx.exe" OR process_name="sfc.exe" OR process_name="shadow.exe" OR process_name="shrpubw.exe" OR process_name="shutdown.exe" OR process_name="sigverif.exe" OR process_name="sihost.exe" OR process_name="slui.exe" OR process_name="smss.exe" OR process_name="snmptrap.exe" OR process_name="sort.exe" OR process_name="spinstall.exe" OR process_name="spoolsv.exe" OR process_name="sppsvc.exe" OR process_name="spreview.exe" OR process_name="srdelayed.exe" OR process_name="subst.exe" OR process_name="svchost.exe" OR process_name="sxstrace.exe" OR process_name="syskey.exe" OR process_name="systeminfo.exe" OR process_name="systemreset.exe" OR process_name="systray.exe" OR process_name="tabcal.exe" OR process_name="takeown.exe" OR process_name="taskeng.exe" OR process_name="taskhost.exe" OR process_name="taskhostw.exe" OR process_name="taskkill.exe" OR process_name="tasklist.exe" OR process_name="taskmgr.exe" OR process_name="tcmsetup.exe" OR process_name="timeout.exe" OR process_name="tpmvscmgr.exe" OR process_name="tpmvscmgrsvr.exe" OR process_name="tracerpt.exe" OR process_name="tscon.exe" OR process_name="tsdiscon.exe" OR process_name="tskill.exe" OR process_name="typeperf.exe" OR process_name="tzsync.exe" OR process_name="tzutil.exe" OR process_name="ucsvc.exe" OR process_name="unlodctr.exe" OR process_name="unregmp2.exe" OR process_name="upnpcont.exe" OR process_name="userinit.exe" OR process_name="vds.exe" OR process_name="vdsldr.exe" OR process_name="verclsid.exe" OR process_name="verifier.exe" OR process_name="verifiergui.exe" OR process_name="vmicsvc.exe" OR process_name="vssadmin.exe" OR process_name="w32tm.exe" OR process_name="waitfor.exe" OR process_name="wbadmin.exe" OR process_name="wbengine.exe" OR process_name="wecutil.exe" OR process_name="wermgr.exe" OR process_name="wevtutil.exe" OR process_name="wextract.exe" OR process_name="where.exe" OR process_name="whoami.exe" OR process_name="wiaacmgr.exe" OR process_name="wiawow64.exe" OR process_name="wifitask.exe" OR process_name="wimserv.exe" OR process_name="wininit.exe" OR process_name="winload.exe" OR process_name="winlogon.exe" OR process_name="winresume.exe" OR process_name="winrs.exe" OR process_name="winrshost.exe" OR process_name="winver.exe" OR process_name="wisptis.exe" OR process_name="wkspbroker.exe" OR process_name="wksprt.exe" OR process_name="wlanext.exe" OR process_name="wlrmdr.exe" OR process_name="wowreg32.exe" OR process_name="wpnpinst.exe" OR process_name="wpr.exe" OR process_name="write.exe" OR process_name="wscript.exe" OR process_name="wsmprovhost.exe" OR process_name="wsqmcons.exe" OR process_name="wuapihost.exe" OR process_name="wuapp.exe" OR process_name="wuauclt.exe" OR process_name="wusa.exe" OR process_name="xcopy.exe" OR process_name="xpsrchvw.exe" OR process_name="xwizard.exe" | where process_path!="c:\\windows\\system32" AND process_path!="c:\\windows\\syswow64" | eval start_time = timestamp, end_time = timestamp, entities = mvappend(device), body = "TBD" | into write_ssa_detected_events();</td></tr><tr><td>known_false_positives</td><td>None</td></tr><tr><td>tags</td><td>{'mitre_technique_id': ['T1036'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'risk_severity': 'low'}</td></tr></table>
<h4>short_lived_windows_accounts.yml</h4>

<table><tr><td>name</td><td>Short Lived Windows Accounts</td></tr><tr><td>id</td><td>b25f6f62-0782-43c1-b403-083231ffd97d</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-06</td></tr><tr><td>description</td><td>This search detects accounts that were created and deleted in a short time period.</td></tr><tr><td>how_to_implement</td><td>This search requires you to have enabled your Group Management Audit Logs in your Local Windows Security Policy and be ingesting those logs.  More information on how to enable them can be found here: http://whatevernetworks.com/auditing-group-membership-changes-in-active-directory/</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` values(All_Changes.result_id) as result_id count min(_time) as firstTime max(_time) as lastTime from datamodel=Change where All_Changes.result_id=4720 OR All_Changes.result_id=4726 by _time span=4h All_Changes.user All_Changes.dest | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name("All_Changes")` | search result_id = 4720 result_id=4726 | transaction user connected=false maxspan=240m | table firstTime lastTime count user dest result_id | `short_lived_windows_accounts_filter`</td></tr><tr><td>known_false_positives</td><td>It is possible that an administrator created and deleted an account in a short time period.  Verifying activity with an administrator is advised.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Account Monitoring and Controls'], 'mitre_attack_id': ['T1136.001'], 'cis20': ['CIS 16'], 'nist': ['PR.IP'], 'security_domain': 'access', 'asset_type': 'Windows'}</td></tr></table>
<h4>registry_keys_used_for_privilege_escalation.yml</h4>

<table><tr><td>name</td><td>Registry Keys Used For Privilege Escalation</td></tr><tr><td>id</td><td>c9f4b923-f8af-4155-b697-1354f5bcbc5e</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for modifications to registry keys that can be used to elevate privileges. The registry keys under "Image File Execution Options" are used to intercept calls to an executable and can be used to attach malicious binaries to benign system binaries.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must be ingesting data that records registry activity from your hosts to populate the endpoint data model in the registry node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://blog.malwarebytes.com/101/2015/12/an-introduction-to-image-file-execution-options/']</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Registry.registry_key_name) as registry_key_name values(Registry.registry_path) as registry_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where (Registry.registry_path="*Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options*") AND (Registry.registry_key_name=GlobalFlag OR Registry.registry_key_name=Debugger) by Registry.dest  Registry.user | `security_content_ctime(lastTime)`  | `security_content_ctime(firstTime)` | `drop_dm_object_name(Registry)` | `registry_keys_used_for_privilege_escalation_filter`</td></tr><tr><td>known_false_positives</td><td>There are many legitimate applications that must execute upon system startup and will use these registry keys to accomplish that task.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Privilege Escalation', 'Suspicious Windows Registry Activities'], 'mitre_attack_id': ['T1547.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>credential_dumping_via_symlink_to_shadow_copy.yml</h4>

<table><tr><td>name</td><td>Credential Dumping via Symlink to Shadow Copy</td></tr><tr><td>id</td><td>c5eac648-fae0-4263-91a6-773df1f4c903</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2019-12-10</td></tr><tr><td>description</td><td>This search detects the creation of a symlink to a shadow copy.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://2017.zeronights.org/wp-content/uploads/materials/ZN17_Kheirkhabarov_Hunting_for_Credentials_Dumping_in_Windows_Environment.pdf']</td></tr><tr><td>author</td><td>Patrick Bareiss, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=cmd.exe Processes.process=*mklink* Processes.process=*HarddiskVolumeShadowCopy* by Processes.dest Processes.user Processes.process_name Processes.process  Processes.parent_process Processes.process_id Processes.parent_process_id | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `credential_dumping_via_symlink_to_shadow_copy_filter` </td></tr><tr><td>known_false_positives</td><td>unknown</td></tr><tr><td>tags</td><td>{'analytics_story': ['Credential Dumping'], 'mitre_attack_id': ['T1003.003'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8', 'CIS 16'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>attempted_credential_dump_from_registry_via_reg_exe.yml</h4>

<table><tr><td>name</td><td>Attempted Credential Dump From Registry via Reg exe</td></tr><tr><td>id</td><td>e9fb4a59-c5fb-440a-9f24-191fbc6b2911</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2019-12-02</td></tr><tr><td>description</td><td>Monitor for execution of reg.exe with parameters specifying an export of keys that contain hashed credentials that attackers may try to crack offline.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints, to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Patrick Bareiss, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process_name=reg.exe OR Processes.process_name=cmd.exe) Processes.process=*save* (Processes.process=*HKEY_LOCAL_MACHINE\\Security* OR Processes.process=*HKEY_LOCAL_MACHINE\\SAM* OR Processes.process=*HKEY_LOCAL_MACHINE\\System* OR Processes.process=*HKLM\\Security* OR Processes.process=*HKLM\\System* OR Processes.process=*HKLM\\SAM*) by Processes.user Processes.process_name Processes.process Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `attempted_credential_dump_from_registry_via_reg_exe_filter`</td></tr><tr><td>known_false_positives</td><td>None identified.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Credential Dumping'], 'mitre_attack_id': ['T1003.002'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 5', 'CIS 16'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_mimikatz_via_powershell_and_eventcode_4703.yml</h4>

<table><tr><td>name</td><td>Detect Mimikatz Via PowerShell And EventCode 4703</td></tr><tr><td>id</td><td>98917be2-bfc8-475a-8618-a9bb06575188</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2019-02-27</td></tr><tr><td>description</td><td>This search looks for PowerShell requesting privileges consistent with credential dumping.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting Windows Security logs. You must also enable the account change auditing here: http://docs.splunk.com/Documentation/Splunk/7.0.2/Data/MonitorWindowseventlogdata. Additionally, this search requires you to enable your Group Management Audit Logs in your Local Windows Security Policy and to be ingesting those logs.  More information on how to enable them can be found here: http://whatevernetworks.com/auditing-group-membership-changes-in-active-directory/. Finally, please make sure that the local administrator group name is "Administrators" to be able to look for the right group membership changes.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>`wineventlog_security` signature_id=4703 Process_Name=*powershell.exe | rex field=Message "Enabled Privileges:\s+(?<privs>\w+)\s+Disabled Privileges:" | where privs="SeDebugPrivilege" | stats count min(_time) as firstTime max(_time) as lastTime by dest, Process_Name, privs, Process_ID, Message | rename privs as "Enabled Privilege" | rename Process_Name as process |  `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_mimikatz_via_powershell_and_eventcode_4703_filter`</td></tr><tr><td>known_false_positives</td><td>The activity may be legitimate. PowerShell is often used by administrators to perform various tasks, and it's possible this event could be generated in those cases. In these cases, false positives should be fairly obvious and you may need to tweak the search to eliminate noise.</td></tr><tr><td>tags</td><td>{'mitre_attack_id': ['T1003.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 5', 'CIS 16'], 'nist': ['PR.IP', 'PR.AC', 'DE.CM'], 'security_domain': 'access', 'asset_type': 'Windows'}</td></tr></table>
<h4>script_execution_via_wmi.yml</h4>

<table><tr><td>name</td><td>Script Execution via WMI</td></tr><tr><td>id</td><td>aa73f80d-d728-4077-b226-81ea0c8be589</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-03-16</td></tr><tr><td>description</td><td>This search looks for scripts launched via WMI.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.process_name = "scrcons.exe" by Processes.user Processes.dest Processes.process_name  | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| `script_execution_via_wmi_filter` </td></tr><tr><td>known_false_positives</td><td>Although unlikely, administrators may use wmi to launch scripts for legitimate purposes.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious WMI Use'], 'mitre_attack_id': ['T1047'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 5'], 'nist': ['PR.PT', 'PR.AT', 'PR.AC', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>common_ransomware_extensions.yml</h4>

<table><tr><td>name</td><td>Common Ransomware Extensions</td></tr><tr><td>id</td><td>a9e5c5db-db11-43ca-86a8-c852d1b2c0ec</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-03-16</td></tr><tr><td>description</td><td>The search looks for file modifications with extensions commonly used by Ransomware</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records the filesystem activity from your hosts to populate the Endpoint file-system data model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.\
This search produces fields (`query`,`query_length`,`count`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** Name, **Field:** Name\
1. \
1. **Label:** File Extension, **Field:** file_extension\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem by Filesystem.file_name | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`| rex field=file_name "(?<file_extension>\.[^\.]+)$" | `ransomware_extensions` | `common_ransomware_extensions_filter`</td></tr><tr><td>known_false_positives</td><td>It is possible for a legitimate file with these extensions to be created. If this is a true ransomware attack, there will be a large number of files created with these extensions.</td></tr><tr><td>tags</td><td>{'analytics_story': ['SamSam Ransomware', 'Ransomware'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>unsigned_image_loaded_by_lsass.yml</h4>

<table><tr><td>name</td><td>Unsigned Image Loaded by LSASS</td></tr><tr><td>id</td><td>56ef054c-76ef-45f9-af4a-a634695dcd65</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2019-12-06</td></tr><tr><td>description</td><td>This search detects loading of unsigned images by LSASS.</td></tr><tr><td>how_to_implement</td><td>This search needs Sysmon Logs with a sysmon configuration, which includes EventCode 7 with lsass.exe. This search uses an input macro named `sysmon`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Sysmon logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://2017.zeronights.org/wp-content/uploads/materials/ZN17_Kheirkhabarov_Hunting_for_Credentials_Dumping_in_Windows_Environment.pdf']</td></tr><tr><td>author</td><td>Patrick Bareiss, Splunk</td></tr><tr><td>search</td><td>`sysmon` EventID=7 Image=*lsass.exe Signed=false | stats count min(_time) as firstTime max(_time) as lastTime by Computer, Image, ImageLoaded, Signed, SHA1 | rename Computer as dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `unsigned_image_loaded_by_lsass_filter` </td></tr><tr><td>known_false_positives</td><td>Other tools could load images into LSASS for legitimate reason. But enterprise tools should always use signed DLLs.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Credential Dumping'], 'mitre_attack_id': ['T1003.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8', 'CIS 16'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Windows'}</td></tr></table>
<h4>unload_sysmon_filter_driver.yml</h4>

<table><tr><td>name</td><td>Unload Sysmon Filter Driver</td></tr><tr><td>id</td><td>c77162d3-f93c-45cc-80c8-22f665664g9f</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-22</td></tr><tr><td>description</td><td>Attackers often disable security tools to avoid detection. This search looks for the usage of process `fltMC.exe` to unload a Sysmon Driver that will stop sysmon from collecting the data.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model. This search is also shipped with `unload_sysmon_filter_driver_filter` macro, update this macro to filter out false positives.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime values(Processes.process) as process max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=fltMC.exe AND Processes.process=*unload* AND Processes.process=*SysmonDrv*  by Processes.process_name Processes.process_id Processes.parent_process_name Processes.process Processes.dest Processes.user | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` |`unload_sysmon_filter_driver_filter`| table firstTime lastTime dest user count process_name process_id parent_process_name process</td></tr><tr><td>known_false_positives</td><td></td></tr><tr><td>tags</td><td>{'analytics_story': ['Disabling Security Tools'], 'mitre_attack_id': ['T1562.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': ''}</td></tr></table>
<h4>prohibited_software_on_endpoint.yml</h4>

<table><tr><td>name</td><td>Prohibited Software On Endpoint</td></tr><tr><td>id</td><td>a51bfe1a-94f0-48cc-b4e4-b6ae50145893</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2019-10-11</td></tr><tr><td>description</td><td>This search looks for applications on the endpoint that you have marked as prohibited.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node. This is typically populated via endpoint detection-and-response products, such as Carbon Black or endpoint data sources, such as Sysmon. The data used for this search is usually generated via logs that report process tracking in your Windows audit settings. In addition, you must also have only the `process_name` (not the entire process path) marked as "prohibited" in the Enterprise Security `interesting processes` table. To include the process names marked as "prohibited", which is included with ES Content Updates, run the included search <code>Add Prohibited Processes to Enterprise Security</code>.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest Processes.user Processes.process_name | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)` | `prohibited_softwares` | `prohibited_software_on_endpoint_filter`</td></tr><tr><td>known_false_positives</td><td>None identified</td></tr><tr><td>tags</td><td>{'analytics_story': ['Monitor for Unauthorized Software', 'Emotet Malware  DHS Report TA18-201A ', 'SamSam Ransomware'], 'kill_chain_phases': ['Installation', 'Command and Control', 'Actions on Objectives'], 'cis20': ['CIS 2'], 'nist': ['ID.AM', 'PR.DS'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_mimikatz_using_loaded_images.yml</h4>

<table><tr><td>name</td><td>Detect Mimikatz Using Loaded Images</td></tr><tr><td>id</td><td>29e307ba-40af-4ab2-91b2-3c6b392bbba0</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2019-12-03</td></tr><tr><td>description</td><td>This search looks for reading loaded Images unique to credential dumping with Mimikatz.</td></tr><tr><td>how_to_implement</td><td>This search needs Sysmon Logs and a sysmon configuration, which includes EventCode 7 with powershell.exe. This search uses an input macro named `sysmon`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Sysmon logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://cyberwardog.blogspot.com/2017/03/chronicles-of-threat-hunter-hunting-for.html']</td></tr><tr><td>author</td><td>Patrick Bareiss, Splunk</td></tr><tr><td>search</td><td>`sysmon` EventCode=7 | stats values(ImageLoaded) as ImageLoaded values(ProcessId) as ProcessId by Computer, Image | search ImageLoaded=*WinSCard.dll ImageLoaded=*cryptdll.dll ImageLoaded=*hid.dll ImageLoaded=*samlib.dll ImageLoaded=*vaultcli.dll | rename Computer as dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_mimikatz_using_loaded_images_filter`</td></tr><tr><td>known_false_positives</td><td>Other tools can import the same DLLs. These tools should be part of a whtelist.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Credential Dumping', 'Detect Zerologon Attack'], 'mitre_attack_id': ['T1003.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 6', 'CIS 8'], 'nist': ['DE.AE', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Windows'}</td></tr></table>
<h4>samsam_test_file_write.yml</h4>

<table><tr><td>name</td><td>Samsam Test File Write</td></tr><tr><td>id</td><td>69c12d59-d951-431e-ab77-ec426b8d65e6</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-12-14</td></tr><tr><td>description</td><td>The search looks for a file named "test.txt" written to the windows system directory tree, which is consistent with Samsam propagation.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records the file-system activity from your hosts to populate the Endpoint file-system data-model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_name) as file_name from datamodel=Endpoint.Filesystem where Filesystem.file_path=*\\windows\\system32\\test.txt by Filesystem.file_path | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `samsam_test_file_write_filter`</td></tr><tr><td>known_false_positives</td><td>No false positives have been identified.</td></tr><tr><td>tags</td><td>{'analytics_story': ['SamSam Ransomware'], 'kill_chain_phases': ['Delivery'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>first_time_seen_child_process_of_zoom.yml</h4>

<table><tr><td>name</td><td>First Time Seen Child Process of Zoom</td></tr><tr><td>id</td><td>e91bd102-d630-4e76-ab73-7e3ba22c5961</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-05-20</td></tr><tr><td>description</td><td>This search looks for child processes spawned by zoom.exe or zoom.us that has not previously been seen.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You should run the baseline search `Previously Seen Zoom Child Processes - Initial` to build the initial table of child processes and hostnames for this search to work. You should also schedule at the same interval as this search the second baseline search `Previously Seen Zoom Child Processes - Update` to keep this table up to date and to age out old child processes. Please update the `previously_seen_zoom_child_processes_window` macro to adjust the time window.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` min(_time) as firstTime values(Processes.parent_process_name) as parent_process_name values(Processes.parent_process_id) as parent_process_id values(Processes.process_name) as process_name values(Processes.process) as process from datamodel=Endpoint.Processes where (Processes.parent_process_name=zoom.exe OR Processes.parent_process_name=zoom.us) by Processes.process_id Processes.dest | `drop_dm_object_name(Processes)` | lookup zoom_first_time_child_process dest as dest process_name as process_name OUTPUT firstTimeSeen | where isnull(firstTimeSeen) OR firstTimeSeen > relative_time(now(), "`previously_seen_zoom_child_processes_window`") | `security_content_ctime(firstTime)` | table firstTime dest, process_id, process_name, parent_process_id, parent_process_name |`first_time_seen_child_process_of_zoom_filter`</td></tr><tr><td>known_false_positives</td><td>A new child process of zoom isn't malicious by that fact alone. Further investigation of the actions of the child process is needed to verify any malicious behavior is taken.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious Zoom Child Processes'], 'mitre_attack_id': ['T1068'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 8'], 'nist': ['PR.PT', 'DE.CM', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>macos___re_opened_applications.yml</h4>

<table><tr><td>name</td><td>MacOS - Re-opened Applications</td></tr><tr><td>id</td><td>40bb64f9-f619-4e3d-8732-328d40377c4b</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-02-07</td></tr><tr><td>description</td><td>This search looks for processes referencing the plist files that determine which applications are re-opened when a user reboots their machine.</td></tr><tr><td>how_to_implement</td><td>In order to properly run this search, Splunk needs to ingest process data from your osquery deployed agents with the [splunk.conf](https://github.com/splunk/TA-osquery/blob/master/config/splunk.conf) pack enabled. Also the [TA-OSquery](https://github.com/splunk/TA-osquery) must be deployed across your indexers and universal forwarders in order to have the data populate the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Jamie Windley, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process="*com.apple.loginwindow*" by Processes.user Processes.process_name Processes.parent_process_name Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `macos___re_opened_applications_filter`</td></tr><tr><td>known_false_positives</td><td>At this stage, there are no known false positives. During testing, no process events refering the com.apple.loginwindow.plist files were observed during normal operation of re-opening applications on reboot. Therefore, it can be asumed that any occurences of this in the process events would be worth investigating. In the event that the legitimate modification by the system of these files is in fact logged to the process log, then the process_name of that process can be whitelisted.</td></tr><tr><td>tags</td><td>{'kill_chain_phases': ['Installation', 'Command and Control'], 'cis20': ['CIS 8'], 'nist': ['DE.DP', 'DE.CM'], 'security_domain': 'threat', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>suspicious_java_classes.yml</h4>

<table><tr><td>name</td><td>Suspicious Java Classes</td></tr><tr><td>id</td><td>if1fea6da-3c86-4c1d-b255-fc3b2781a491</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-12-06</td></tr><tr><td>description</td><td>This search looks for suspicious Java classes that are often used to exploit remote command execution in common Java frameworks, such as Apache Struts.</td></tr><tr><td>how_to_implement</td><td>In order to properly run this search, Splunk needs to ingest data from your web-traffic appliances that serve or sit in the path of your Struts application servers. This can be accomplished by indexing data from a web proxy, or by using network traffic-analysis tools, such as Splunk Stream or Bro.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Jose Hernandez, Splunk</td></tr><tr><td>search</td><td>`stream_http` http_method=POST http_content_length>1 | regex form_data="(?i)java\.lang\.(?:runtime|processbuilder)" | rename src_ip as src | stats count earliest(_time) as firstTime, latest(_time) as lastTime, values(url) as uri, values(status) as status, values(http_user_agent) as http_user_agent by src, dest | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `suspicious_java_classes_filter`</td></tr><tr><td>known_false_positives</td><td>There are no known false positives.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Apache Struts Vulnerability'], 'kill_chain_phases': ['Exploitation'], 'cis20': ['CIS 7', 'CIS 12'], 'nist': ['DE.AE'], 'security_domain': 'threat', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>suspicious_reg_exe_process.yml</h4>

<table><tr><td>name</td><td>Suspicious Reg exe Process</td></tr><tr><td>id</td><td>a6b3ab4e-dd77-4213-95fa-fc94701995e0</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-22</td></tr><tr><td>description</td><td>This search looks for reg.exe being launched from a command prompt not started by the user. When a user launches cmd.exe, the parent process is usually explorer.exe. This search filters out those instances.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://car.mitre.org/wiki/CAR-2013-03-001']</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.parent_process_name != explorer.exe Processes.process_name =cmd.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest Processes.process_id Processes.parent_process_id | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | search [| tstats `security_content_summariesonly` count FROM datamodel=Endpoint.Processes where Processes.parent_process_name=cmd.exe Processes.process_name= reg.exe by Processes.parent_process_id Processes.dest Processes.process_name | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename parent_process_id as process_id |dedup process_id| table process_id dest] | `suspicious_reg_exe_process_filter` </td></tr><tr><td>known_false_positives</td><td>It's possible for system administrators to write scripts that exhibit this behavior. If this is the case, the search will need to be modified to filter them out.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Defense Evasion Tactics', 'Disabling Security Tools', 'DHS Report TA18-074A'], 'mitre_attack_id': ['T1112'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>access_lsass_memory_for_dump_creation.yml</h4>

<table><tr><td>name</td><td>Access LSASS Memory for Dump Creation</td></tr><tr><td>id</td><td>fb4c31b0-13e8-4155-8aa5-24de4b8d6717</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2019-12-06</td></tr><tr><td>description</td><td>Detect memory dumping of the LSASS process.</td></tr><tr><td>how_to_implement</td><td>This search requires Sysmon Logs and a Sysmon configuration, which includes EventCode 10 for lsass.exe. This search uses an input macro named `sysmon`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Sysmon logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://2017.zeronights.org/wp-content/uploads/materials/ZN17_Kheirkhabarov_Hunting_for_Credentials_Dumping_in_Windows_Environment.pdf']</td></tr><tr><td>author</td><td>Patrick Bareiss, Splunk</td></tr><tr><td>search</td><td>`sysmon` EventCode=10 TargetImage=*lsass.exe CallTrace=*dbgcore.dll* OR CallTrace=*dbghelp.dll* | stats count min(_time) as firstTime max(_time) as lastTime by Computer, TargetImage, TargetProcessId, SourceImage, SourceProcessId | rename Computer as dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `access_lsass_memory_for_dump_creation_filter` </td></tr><tr><td>known_false_positives</td><td>Administrators can create memory dumps for debugging purposes, but memory dumps of the LSASS process would be unusual.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Credential Dumping'], 'mitre_attack_id': ['T1003.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 6', 'CIS 8'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Windows'}</td></tr></table>
<h4>create_or_delete_windows_shares_using_net_exe.yml</h4>

<table><tr><td>name</td><td>Create or delete windows shares using net exe</td></tr><tr><td>id</td><td>qw9919ed-fe5f-492c-b139-151bb162140e</td></tr><tr><td>version</td><td>5</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for the creation or deletion of hidden shares using net.exe.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://attack.mitre.org/techniques/T1077/', 'https://attack.mitre.org/techniques/T1126/']</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.user) as user values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processs.process_name=net.exe OR Processes.process_name=net1.exe) by Processes.process Processes.process_name Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | search process=*share* | `create_or_delete_windows_shares_using_net_exe_filter` </td></tr><tr><td>known_false_positives</td><td>Administrators often leverage net.exe to create or delete network shares. You should verify that the activity was intentional and is legitimate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Hidden Cobra Malware'], 'mitre_attack_id': ['T1059.003'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>unsuccessful_netbackup_backups.yml</h4>

<table><tr><td>name</td><td>Unsuccessful Netbackup backups</td></tr><tr><td>id</td><td>a34aae96-ccf8-4aaa-952c-3ea21444444f</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-09-12</td></tr><tr><td>description</td><td>This search gives you the hosts where a backup was attempted and then failed.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search you need to obtain data from your backup solution, either from the backup logs on your endpoints or from a central server responsible for performing the backups. If you do not use Netbackup, you can modify this search for your specific backup solution.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>`netbackup` | stats latest(_time) as latestTime by COMPUTERNAME, MESSAGE | search MESSAGE="An error occurred, failed to backup." | `security_content_ctime(latestTime)` | rename COMPUTERNAME as dest, MESSAGE as signature | table latestTime, dest, signature | `unsuccessful_netbackup_backups_filter`</td></tr><tr><td>known_false_positives</td><td>None identified</td></tr><tr><td>tags</td><td>{'analytics_story': ['Monitor Backup Solution'], 'cis20': ['CIS 10'], 'nist': ['PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>suspicious_writes_to_windows_recycle_bin.yml</h4>

<table><tr><td>name</td><td>Suspicious writes to windows Recycle Bin</td></tr><tr><td>id</td><td>b5541828-8ffd-4070-9d95-b3da4de924cb</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-22</td></tr><tr><td>description</td><td>This search detects writes to the recycle bin by a process other than explorer.exe.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search you need to be ingesting information on filesystem and process logs responsible for the changes from your endpoints into the `Endpoint` datamodel in the `Processes` and `Filesystem` nodes.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.file_path) as file_path values(Filesystem.file_name) as file_name FROM datamodel=Endpoint.Filesystem where Filesystem.file_path = "*$Recycle.Bin*" by Filesystem.process_id Filesystem.dest | `drop_dm_object_name("Filesystem")`| search [| tstats `security_content_summariesonly` values(Processes.user) as user values(Processes.process_name) as process_name values(Processes.parent_process_name) as parent_process_name FROM datamodel=Endpoint.Processes where Processes.process_name != "explorer.exe" by Processes.process_id Processes.dest| `drop_dm_object_name("Processes")` | table process_id dest] | `suspicious_writes_to_windows_recycle_bin_filter`</td></tr><tr><td>known_false_positives</td><td>Because the Recycle Bin is a hidden folder in modern versions of Windows, it would be unusual for a process other than explorer.exe to write to it. Incidents should be investigated as appropriate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Collection and Staging'], 'mitre_attack_id': ['T1036'], 'cis20': ['CIS 8'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Windows'}</td></tr></table>
<h4>attempt_to_add_certificate_to_untrusted_store.yml</h4>

<table><tr><td>name</td><td>Attempt To Add Certificate To Untrusted Store</td></tr><tr><td>id</td><td>6bc5243e-ef36-45dc-9b12-f4a6be131159</td></tr><tr><td>version</td><td>5</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>Attempt to add a certificate to the untrusted certificate store</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime values(Processes.process) as process max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=certutil.exe (Processes.process=*-addstore* AND Processes.process=*disallowed* ) by Processes.parent_process Processes.process_name Processes.user | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` | `attempt_to_add_certificate_to_untrusted_store_filter`</td></tr><tr><td>known_false_positives</td><td>There may be legitimate reasons for administrators to add a certificate to the untrusted certificate store. In such cases, this will typically be done on a large number of systems.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Disabling Security Tools'], 'mitre_attack_id': ['T1553.004'], 'kill_chain_phases': ['Installation', 'Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 5', 'CIS 8'], 'nist': ['PR.PT', 'DE.CM', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>scheduled_tasks_used_in_badrabbit_ransomware.yml</h4>

<table><tr><td>name</td><td>Scheduled tasks used in BadRabbit ransomware</td></tr><tr><td>id</td><td>1297fb80-f42a-4b4a-9c8b-78c066437cf6</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for flags passed to schtasks.exe on the command-line that indicate that task names related to the execution of Bad Rabbit ransomware were created or deleted.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Processes.process) as process  from datamodel=Endpoint.Processes where Processes.process_name=schtasks.exe (Processes.process= "*create*"  OR Processes.process= "*delete*") by Processes.parent_process Processes.process_name Processes.user | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` | search (process=*rhaegal* OR process=*drogon* OR *viserion_*) | `scheduled_tasks_used_in_badrabbit_ransomware_filter`</td></tr><tr><td>known_false_positives</td><td>No known false positives</td></tr><tr><td>tags</td><td>{'analytics_story': ['Ransomware'], 'mitre_attack_id': ['T1053.005'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3'], 'nist': ['PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>system_processes_run_from_unexpected_locations.yml</h4>

<table><tr><td>name</td><td>System Processes Run From Unexpected Locations</td></tr><tr><td>id</td><td>a34aae96-ccf8-4aef-952c-3ea21444444d</td></tr><tr><td>version</td><td>5</td></tr><tr><td>date</td><td>2020-02-04</td></tr><tr><td>description</td><td>This search looks for system processes that normally run out of C:\Windows\System32\ or C:\Windows\SysWOW64 that are not run from that location.  This can indicate a malicious process that is trying to hide as a legitimate process.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search you need to ingest details about process execution from your hosts. Specifically, this search requires the process name and the full path to the process executable.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.process_path !="C:\\Windows\\System32*" Processes.process_path !="C:\\Windows\\SysWOW64*" by Processes.user Processes.dest Processes.process_name Processes.process_id Processes.process_path Processes.parent_process_name Processes.process_hash| `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| `is_windows_system_file` | `system_processes_run_from_unexpected_locations_filter`</td></tr><tr><td>known_false_positives</td><td>None identified</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious Command-Line Executions', 'Unusual Processes', 'Ransomware'], 'mitre_attack_id': ['T1036'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_prohibited_applications_spawning_cmd_exe.yml</h4>

<table><tr><td>name</td><td>Detect Prohibited Applications Spawning cmd exe</td></tr><tr><td>id</td><td>dcfd6b40-42f9-469d-a433-2e53f7486664</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for executions of cmd.exe spawned by a process that is often abused by attackers and that does not typically launch cmd.exe.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts and populates the Endpoint data model with the resultant dataset. This search includes a lookup file, `prohibited_apps_launching_cmd.csv`, that contains a list of processes that should not be spawning cmd.exe. You can modify this lookup to better suit your environment.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=cmd.exe by Processes.parent_process_name Processes.process_name Processes.dest Processes.user| `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` |search [`prohibited_apps_launching_cmd`] | `detect_prohibited_applications_spawning_cmd_exe_filter`</td></tr><tr><td>known_false_positives</td><td>There are circumstances where an application may legitimately execute and interact with the Windows command-line interface. Investigate and modify the lookup file, as appropriate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious Command-Line Executions', 'Suspicious MSHTA Activity', 'Suspicious Zoom Child Processes'], 'mitre_attack_id': ['T1059.003'], 'kill_chain_phases': ['Exploitation'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>credential_extraction_lazagne_command_options_ssa.yml</h4>

<table><tr><td>name</td><td>Credential Extraction indicative of Lazagne command line options</td></tr><tr><td>id</td><td>341975fa-4ad0-4f01-9acc-df4f69742db7</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-10-18</td></tr><tr><td>description</td><td>Credential extraction is often an illegal recovery of credential material from secured authentication resources and repositories. This process may also involve decryption or other transformations of the stored credential material. LaZagne is a tool that extracts various kinds of credentials from a local computer, including account passwords, domain passwords, browser passwords, etc.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting Windows Security logs from devices of interest, including the event ID 4688 with enabled command line logging.</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>type</td><td>SSA</td></tr><tr><td>author</td><td>Stanislav Miskovic, Splunk</td></tr><tr><td>search</td><td> | from read_ssa_enriched_events()
| eval timestamp=parse_long(ucast(map_get(input_event, "_time"), "string", null)), cmd_line=ucast(map_get(input_event, "process"), "string", null) | where cmd_line != null AND match_regex(cmd_line, /(?i)all\s+\-oA\s+\-output/)=true
| eval start_time = timestamp, end_time = timestamp, entities = mvappend( ucast(map_get(input_event, "dest_user_id"), "string", null), ucast(map_get(input_event, "dest_device_id"), "string", null)), body = "TBD" | into write_ssa_detected_events();</td></tr><tr><td>eli5</td><td>This detection identifies the most common LaZagne invocation, in which it is instructed to extract all available passwords and output them to a file. For more details on LaZagne see https://github.com/AlessandroZ/LaZagne</td></tr><tr><td>known_false_positives</td><td>None identified.</td></tr><tr><td>tags</td><td>{'cis20': ['CIS 16'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_technique_id': ['T1003', 'T1555'], 'nist': ['PR.IP', 'PR.AC'], 'risk_severity': 'high', 'security_domain': 'endpoint', 'asset_type': 'Windows'}</td></tr></table>
<h4>processes_tapping_keyboard_events.yml</h4>

<table><tr><td>name</td><td>Processes Tapping Keyboard Events</td></tr><tr><td>id</td><td>2a371608-331d-4034-ae2c-21dda8f1d0ec</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2019-01-25</td></tr><tr><td>description</td><td>This search looks for processes in an MacOS system that is tapping keyboard events in MacOS, and essentially monitoring all keystrokes made by a user. This is a common technique used by RATs to log keystrokes from a victim, although it can also be used by legitimate processes like Siri to react on human input</td></tr><tr><td>how_to_implement</td><td>In order to properly run this search, Splunk needs to ingest data from your osquery deployed agents with the [osx-attacks.conf](https://github.com/facebook/osquery/blob/experimental/packs/osx-attacks.conf#L599) pack enabled. Also the [TA-OSquery](https://github.com/d1vious/TA-osquery) must be deployed across your indexers and universal forwarders in order to have the osquery data populate the Alerts data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Jose Hernandez, Splunk</td></tr><tr><td>search</td><td>| from datamodel Alerts.Alerts | search app=osquery:results name=pack_osx-attacks_Keyboard_Event_Taps | rename columns.cmdline as cmd, columns.name as process_name, columns.pid as process_id| dedup host,process_name | table host,process_name, cmd, process_id | `processes_tapping_keyboard_events_filter`</td></tr><tr><td>known_false_positives</td><td>There might be some false positives as keyboard event taps are used by processes like Siri and Zoom video chat, for some good examples of processes to exclude please see [this](https://github.com/facebook/osquery/pull/5345#issuecomment-454639161) comment.</td></tr><tr><td>tags</td><td>{'analytics_story': ['ColdRoot MacOS RAT'], 'kill_chain_phases': ['Command and Control'], 'cis20': ['CIS 4', 'CIS 8'], 'nist': ['DE.DP'], 'security_domain': 'threat', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>suspicious_lnk_file_launching_a_process.yml</h4>

<table><tr><td>name</td><td>Suspicious LNK file launching a process</td></tr><tr><td>id</td><td>5d814af1-1041-47b5-a9ac-d754e82e9a26</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for a ``*.lnk` file under `C:\User*` or `*\Local\Temp\*` executing a process. This is common behavior used by various spear phishing tools.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records filesystem and process activity from your hosts to populate the Endpoint data model. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>Jose Hernandez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Filesystem where Filesystem.file_name="*.lnk" AND (Filesystem.file_path="C:\\Users*" OR Filesystem.file_path="*Local\\Temp*")  by _time span=1h Filesystem.process_id Filesystem.file_name Filesystem.file_path Filesystem.file_hash Filesystem.user | `drop_dm_object_name(Filesystem)` | rename process_id as lnk_pid | join lnk_pid, _time [| tstats `security_content_summariesonly` count FROM datamodel=Endpoint.Processes where Processes.process_name=*  by _time span=1h Processes.parent_process_id Processes.process_id Processes.process_name Processes.dest Processes.process_path Processes.process | `drop_dm_object_name(Processes)` | rename parent_process_id as lnk_pid | fields _time lnk_pid process_id dest process_name process_path process] | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | table firstTime, lastTime, lnk_pid, process_id, user, dest, file_name, file_path, process_name, process, process_path, file_hash | `suspicious_lnk_file_launching_a_process_filter` </td></tr><tr><td>known_false_positives</td><td>This detection should yield little or no false positive results. It is uncommon for LNK files to execute process from temporary or user directories.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Phishing Payloads'], 'mitre_attack_id': ['T1566.002'], 'kill_chain_phases': ['Installation', 'Actions on Objectives'], 'cis20': ['CIS 7', 'CIS 8'], 'nist': ['ID.AM', 'PR.DS'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_processes_used_for_system_network_configuration_discovery.yml</h4>

<table><tr><td>name</td><td>Detect processes used for System Network Configuration Discovery</td></tr><tr><td>id</td><td>a51bfe1a-94f0-48cc-b1e4-16ae10145893</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-11-20</td></tr><tr><td>description</td><td>This search looks for fast execution of processes used for system network configuration discovery on the endpoint.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records registry activity from your hosts to populate the Endpoint data model in the processes node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon. The data used for this search is usually generated via logs that report reads and writes to the registry or that are populated via Windows event logs, after enabling process tracking in your Windows audit settings.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest Processes.process_name Processes.user _time | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)` | search `system_network_configuration_discovery_tools` | transaction dest connected=false maxpause=5m |where eventcount>=5 | table firstTime lastTime dest user process_name process parent_process eventcount | `detect_processes_used_for_system_network_configuration_discovery_filter`</td></tr><tr><td>known_false_positives</td><td>It is uncommon for normal users to execute a series of commands used for network discovery. System administrators often use scripts to execute these commands. These can generate false positives.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Unusual Processes'], 'kill_chain_phases': ['Installation', 'Command and Control', 'Actions on Objectives'], 'cis20': ['CIS 2'], 'nist': ['ID.AM', 'PR.DS'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>monitor_registry_keys_for_print_monitors.yml</h4>

<table><tr><td>name</td><td>Monitor Registry Keys for Print Monitors</td></tr><tr><td>id</td><td>f5f6af30-7ba7-4295-bfe9-07de87c01bbc</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-11-02</td></tr><tr><td>description</td><td>This search looks for registry activity associated with modifications to the registry key `HKLM\SYSTEM\CurrentControlSet\Control\Print\Monitors`. In this scenario, an attacker can load an arbitrary .dll into the print-monitor registry by giving the full path name to the after.dll. The system will execute the .dll with elevated (SYSTEM) permissions and will persist after reboot.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must be ingesting data that records registry activity from your hosts to populate the endpoint data model in the registry node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or via other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report registry modifications.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where Registry.action=modified AND Registry.registry_path="*CurrentControlSet\\Control\\Print\\Monitors*" by Registry.dest, Registry.registry_key_name Registry.status Registry.user Registry.registry_path Registry.action | `drop_dm_object_name(Registry)` | `monitor_registry_keys_for_print_monitors_filter`</td></tr><tr><td>known_false_positives</td><td>You will encounter noise from legitimate print-monitor registry entries.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious Windows Registry Activities', 'Windows Persistence Techniques'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8', 'CIS 5'], 'nist': ['PR.PT', 'DE.CM', 'PR.AC'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>wmi_permanent_event_subscription___sysmon.yml</h4>

<table><tr><td>name</td><td>WMI Permanent Event Subscription - Sysmon</td></tr><tr><td>id</td><td>ad05aae6-3b2a-4f73-af97-57bd26cee3b9</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-10-23</td></tr><tr><td>description</td><td>This search looks for the creation of WMI permanent event subscriptions.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must be collecting Sysmon data using Sysmon version 6.1 or greater and have Sysmon configured to generate alerts for WMI activity. In addition, you must have at least version 6.0.4 of the Sysmon TA installed to properly parse the fields.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>`sysmon` EventCode=21 | rename host as dest | table _time, dest, user, Operation, EventType, Query, Consumer, Filter | `wmi_permanent_event_subscription___sysmon_filter`</td></tr><tr><td>known_false_positives</td><td>Although unlikely, administrators may use event subscriptions for legitimate purposes.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious WMI Use'], 'mitre_attack_id': ['T1047'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 5'], 'nist': ['PR.PT', 'PR.AT', 'PR.AC', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>shim_database_installation_with_suspicious_parameters.yml</h4>

<table><tr><td>name</td><td>Shim Database Installation With Suspicious Parameters</td></tr><tr><td>id</td><td>404620de-46d8-48b6-90cc-8a8d7b0876a3</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-22</td></tr><tr><td>description</td><td>This search detects the process execution and arguments required to silently create a shim database.  The sdbinst.exe application is used to install shim database files (.sdb). A shim is a small library which transparently intercepts an API, changes the parameters passed, handles the operation itself, or redirects the operation elsewhere.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = sdbinst.exe Processes.process="*-p*" Processes.process="*-q*" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `shim_database_installation_with_suspicious_parameters_filter`</td></tr><tr><td>known_false_positives</td><td>None identified</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Persistence Techniques'], 'mitre_attack_id': ['T1546.011'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>credential_extraction_ms_debuggers_kernel_peek.yml</h4>

<table><tr><td>name</td><td>Credential Extraction native Microsoft debuggers peek into the kernel</td></tr><tr><td>id</td><td>c20bb8ec-e1b0-4640-b0ef-3a4c54f8c112</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-10-18</td></tr><tr><td>description</td><td>Credential extraction is often an illegal recovery of credential material from secured authentication resources and repositories. This process may also involve decryption or other transformations of the stored credential material. Native Microsoft debuggers, such as kd, ntkd, livekd and windbg, can be leveraged to read credential material directly from memory and process dumps.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting Windows Security logs from devices of interest, including the event ID 4688 with enabled command line logging.</td></tr><tr><td>references</td><td>['https://medium.com/@clermont1050/covid-19-cyber-infection-c615ead7c29']</td></tr><tr><td>type</td><td>SSA</td></tr><tr><td>author</td><td>Stanislav Miskovic, Splunk</td></tr><tr><td>search</td><td> | from read_ssa_enriched_events()
| eval timestamp=parse_long(ucast(map_get(input_event, "_time"), "string", null)), cmd_line=ucast(map_get(input_event, "process"), "string", null), process_name=ucast(map_get(input_event, "process_name"), "string", null), parent_process_name=ucast(map_get(input_event, "parent_process_name"), "string", null) | where cmd_line != null AND parent_process_name != null AND process_name != null  AND ( match_regex(parent_process_name, /(?i)ntkd\.exe/)=true OR match_regex(parent_process_name, /(?i)livekd\.exe/)=true ) AND match_regex(process_name, /(?i)conhost\.exe/)=true AND match_regex(cmd_line, /(?i)0xffffffff/)=true AND match_regex(cmd_line, /(?i)\-ForceV1/)=true
| eval start_time = timestamp, end_time = timestamp, entities = mvappend( ucast(map_get(input_event, "dest_user_id"), "string", null), ucast(map_get(input_event, "dest_device_id"), "string", null)), body = "TBD" | into write_ssa_detected_events();</td></tr><tr><td>eli5</td><td>This detection spots when native Microsoft debuggers ask for something inside the kernel (via ForceV1) while retrieving credentials.</td></tr><tr><td>known_false_positives</td><td>Although unlikely, using debuggers this way may be indicative of developers analyzing crash dumps of their code. Note, even for developers this is an unusual way of working on code - debuggers are mostly used to step through code, not analyze its crash dumps.</td></tr><tr><td>tags</td><td>{'cis20': ['CIS 16'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_technique_id': ['T1003'], 'nist': ['PR.IP', 'PR.AC'], 'risk_severity': 'medium', 'security_domain': 'endpoint', 'asset_type': 'Windows'}</td></tr></table>
<h4>detect_use_of_cmd_exe_to_launch_script_interpreters.yml</h4>

<table><tr><td>name</td><td>Detect Use of cmd exe to Launch Script Interpreters</td></tr><tr><td>id</td><td>b89919ed-fe5f-492c-b139-95dbb162039e</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for the execution of the cscript.exe or wscript.exe processes, with a parent of cmd.exe. The search will return the count, the first and last time this execution was seen on a machine, the user, and the destination of the machine</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process) min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.parent_process_name="cmd.exe" (Processes.process_name=cscript.exe OR Processes.process_name =wscript.exe) by Processes.parent_process Processes.process_name Processes.user Processes.dest | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` | `detect_use_of_cmd_exe_to_launch_script_interpreters_filter`</td></tr><tr><td>known_false_positives</td><td>Some legitimate applications may exhibit this behavior.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Emotet Malware  DHS Report TA18-201A ', 'Suspicious Command-Line Executions'], 'mitre_attack_id': ['T1059.003'], 'kill_chain_phases': ['Exploitation'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>child_processes_of_spoolsv_exe.yml</h4>

<table><tr><td>name</td><td>Child Processes of Spoolsv exe</td></tr><tr><td>id</td><td>aa0c4aeb-5b18-41c4-8c07-f1442d7599df</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-03-16</td></tr><tr><td>description</td><td>This search looks for child processes of spoolsv.exe. This activity is associated with a POC privilege-escalation exploit associated with CVE-2018-8440. Spoolsv.exe is the process associated with the Print Spooler service in Windows and typically runs as SYSTEM.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model. Update the `children_of_spoolsv_filter` macro to filter out legitimate child processes spawned by spoolsv.exe.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process_name) as process_name values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.parent_process_name=spoolsv.exe AND Processes.process_name!=regsvr32.exe by Processes.dest Processes.parent_process Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `child_processes_of_spoolsv_exe_filter` </td></tr><tr><td>known_false_positives</td><td>Some legitimate printer-related processes may show up as children of spoolsv.exe. You should confirm that any activity as legitimate and may be added as exclusions in the search.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Privilege Escalation'], 'mitre_attack_id': ['T1068'], 'kill_chain_phases': ['Exploitation'], 'cis20': ['CIS 5', 'CIS 8'], 'nist': ['PR.AC', 'PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_usb_device_insertion.yml</h4>

<table><tr><td>name</td><td>Detect USB device insertion</td></tr><tr><td>id</td><td>104658f4-afdc-499f-9719-17a43f9826f5</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-11-27</td></tr><tr><td>description</td><td>The search is used to detect hosts that generate Windows Event ID 4663 for successful attempts to write to or read from a removable storage and Event ID 4656 for failures, which occurs when a USB drive is plugged in. In this scenario we are querying the Change_Analysis data model to look for Windows Event ID 4656 or 4663 where the priority of the affected host is marked as high in the ES Assets and Identity Framework.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must ingest Windows Security Event logs and track event code 4663 and 4656. Ensure that the field from the event logs is being mapped to the result_id field in the Change_Analysis data model. To minimize the alert volume, this search leverages the Assets and Identity framework to filter out events from those assets not marked high priority in the Enterprise Security Assets and Identity Framework.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count earliest(_time) AS earliest latest(_time) AS latest from datamodel=Change_Analysis where (nodename = All_Changes) All_Changes.result="Removable Storage device" (All_Changes.result_id=4663 OR All_Changes.result_id=4656) (All_Changes.src_priority=high) by All_Changes.dest | `drop_dm_object_name("All_Changes")`| `security_content_ctime(earliest)`| `security_content_ctime(latest)`  | `detect_usb_device_insertion_filter`</td></tr><tr><td>known_false_positives</td><td>Legitimate USB activity will also be detected. Please verify and investigate as appropriate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Data Protection'], 'kill_chain_phases': ['Installation', 'Actions on Objectives'], 'cis20': ['CIS 13'], 'nist': ['PR.PT', 'PR.DS'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>file_with_samsam_extension.yml</h4>

<table><tr><td>name</td><td>File with Samsam Extension</td></tr><tr><td>id</td><td>02c6cfc2-ae66-4735-bfc7-6291da834cbf</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-12-14</td></tr><tr><td>description</td><td>The search looks for file writes with extensions consistent with a SamSam ransomware attack.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records file-system activity from your hosts to populate the Endpoint file-system data-model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem by Filesystem.file_name | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`| rex field=file_name "(?<file_extension>\.[^\.]+)$" | search file_extension=.stubbin OR file_extension=.berkshire OR file_extension=.satoshi OR file_extension=.sophos OR file_extension=.keyxml | `file_with_samsam_extension_filter`</td></tr><tr><td>known_false_positives</td><td>Because these extensions are not typically used in normal operations, you should investigate all results.</td></tr><tr><td>tags</td><td>{'analytics_story': ['SamSam Ransomware'], 'kill_chain_phases': ['Installation'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>kerberoasting_spn_request_with_rc4_encryption.yml</h4>

<table><tr><td>name</td><td>Kerberoasting spn request with RC4 encryption</td></tr><tr><td>id</td><td>5cc67381-44fa-4111-8a37-7a230943f027</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-10-16</td></tr><tr><td>description</td><td>This search detects a potential kerberoasting attack via service principal name requests</td></tr><tr><td>how_to_implement</td><td>You must be ingesting endpoint data that tracks process activity, and include the windows security event logs that contain kerberos</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://github.com/redcanaryco/atomic-red-team/blob/master/atomics/T1208/T1208.md', 'https://www.trimarcsecurity.com/post/trimarcresearch-detecting-kerberoasting-activity']</td></tr><tr><td>author</td><td>Jose Hernandez, Patrick Bareiss, Splunk</td></tr><tr><td>search</td><td>`wineventlog_security` EventCode=4769 Ticket_Options=0x40810000 Ticket_Encryption_Type=0x17 | stats count min(_time) as firstTime max(_time) as lastTime by dest, service, service_id, Ticket_Encryption_Type, Ticket_Options | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `kerberoasting_spn_request_with_rc4_encryption_filter`</td></tr><tr><td>known_false_positives</td><td>Older systems that support kerberos RC4 by default NetApp may generate false positives</td></tr><tr><td>tags</td><td>{'analytics_story': ['Lateral Movement'], 'mitre_attack_id': ['T1558.003'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8', 'CIS 16'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint', 'automated_detection_testing': 'passed', 'dataset': ['https://attack-range-attack-data.s3-us-west-2.amazonaws.com/T1558.003/windows-security.log']}</td></tr></table>
<h4>deleting_shadow_copies.yml</h4>

<table><tr><td>name</td><td>Deleting Shadow Copies</td></tr><tr><td>id</td><td>b89919ed-ee5f-492c-b139-95dbb162039e</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>The vssadmin.exe utility is used to interact with the Volume Shadow Copy Service.  Wmic is an interface to the Windows Management Instrumentation.  This search looks for either of these tools being used to delete shadow copies.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process_name=vssadmin.exe OR Processes.process_name=wmic.exe)  by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | search process=*delete* AND process=*shadow* | `deleting_shadow_copies_filter`</td></tr><tr><td>known_false_positives</td><td>vssadmin.exe and wmic.exe are standard applications shipped with modern versions of windows. They may be used by administrators to legitimately delete old backup copies, although this is typically rare.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Log Manipulation', 'SamSam Ransomware', 'Ransomware'], 'mitre_attack_id': ['T1485'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8', 'CIS 10'], 'nist': ['PR.PT', 'DE.CM', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>credential_extraction_fgdump_cachedump_s_option_ssa.yml</h4>

<table><tr><td>name</td><td>Credential Extraction indicative of FGDump and CacheDump with s option</td></tr><tr><td>id</td><td>312582f2-5e91-42c1-a275-cd67f31373c8</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-10-18</td></tr><tr><td>description</td><td>Credential extraction is often an illegal recovery of credential material from secured authentication resources and repositories. This process may also involve decryption or other transformations of the stored credential material. FGdump is a newer version of pwdump tool that extracts NTLM and LanMan password hashes from Windows. Cachedump is a publicly-available tool that extracts cached password hashes from a system's registry.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting Windows Security logs from devices of interest, including the event ID 4688 with enabled command line logging.</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>type</td><td>SSA</td></tr><tr><td>author</td><td>Stanislav Miskovic, Splunk</td></tr><tr><td>search</td><td> | from read_ssa_enriched_events()
| eval timestamp=parse_long(ucast(map_get(input_event, "_time"), "string", null)), cmd_line=ucast(map_get(input_event, "process"), "string", null), process_name=ucast(map_get(input_event, "process_name"), "string", null), process_path=ucast(map_get(input_event, "process_path"), "string", null), parent_process_name=ucast(map_get(input_event, "parent_process_name"), "string", null) | where cmd_line != null AND process_name != null AND parent_process_name != null AND match_regex(parent_process_name, /(?i)System32\\services.exe/)=true AND match_regex(process_name, /(?i)cachedump\d{0,2}.exe/)=true AND match_regex(process_path, /(?i)\\Temp/)=true AND match_regex(cmd_line, /(?i)\-s/)=true
| eval start_time = timestamp, end_time = timestamp, entities = mvappend( ucast(map_get(input_event, "dest_user_id"), "string", null), ucast(map_get(input_event, "dest_device_id"), "string", null)), body = "TBD" | into write_ssa_detected_events();</td></tr><tr><td>eli5</td><td>This detection identifies one of the inevitable stages of FGdump in which CacheDump is called. Note, CacheDump activity may also be embedded in other exploit tools. For more details on FGdump stages see https://github.com/interference-security/kali-windows-binaries/tree/master/fgdump</td></tr><tr><td>known_false_positives</td><td>None identified.</td></tr><tr><td>tags</td><td>{'cis20': ['CIS 16'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_technique_id': ['T1003'], 'nist': ['PR.AC', 'PR.IP'], 'risk_severity': 'high', 'security_domain': 'endpoint', 'asset_type': 'Windows'}</td></tr></table>
<h4>execution_of_file_with_multiple_extensions.yml</h4>

<table><tr><td>name</td><td>Execution of File with Multiple Extensions</td></tr><tr><td>id</td><td>b06a555e-dce0-417d-a2eb-28a5d8d66ef7</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for processes launched from files that have double extensions in the file name. This is typically done to obscure the "real" file extension and make it appear as though the file being accessed is a data file, as opposed to executable content.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process = *.doc.exe OR Processes.process = *.htm.exe OR Processes.process = *.html.exe OR Processes.process = *.txt.exe OR Processes.process = *.pdf.exe OR Processes.process = *.doc.exe by Processes.dest Processes.user Processes.process Processes.parent_process | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)` | `execution_of_file_with_multiple_extensions_filter`</td></tr><tr><td>known_false_positives</td><td>None identified.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows File Extension and Association Abuse'], 'mitre_attack_id': ['T1036'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 8'], 'nist': ['DE.CM', 'PR.PT', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>creation_of_shadow_copy.yml</h4>

<table><tr><td>name</td><td>Creation of Shadow Copy</td></tr><tr><td>id</td><td>eb120f5f-b879-4a63-97c1-93352b5df844</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2019-12-10</td></tr><tr><td>description</td><td>Monitor for signs that Ntdsutil, Vssadmin, or Wmic has been used to create a shadow copy.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints, to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://2017.zeronights.org/wp-content/uploads/materials/ZN17_Kheirkhabarov_Hunting_for_Credentials_Dumping_in_Windows_Environment.pdf']</td></tr><tr><td>author</td><td>Patrick Bareiss, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process_name=ntdsutil.exe Processes.process=*ntds* Processes.process=*create*) OR (Processes.process_name=vssadmin.exe Processes.process=*create* Processes.process=*shadow*) OR (Processes.process_name=wmic.exe Processes.process=*shadowcopy* Processes.process=*create*) by Processes.dest Processes.user Processes.process_name Processes.process  Processes.parent_process Processes.process_id Processes.parent_process_id | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `creation_of_shadow_copy_filter`</td></tr><tr><td>known_false_positives</td><td>Legtimate administrator usage of Ntdsutil, Vssadmin, or Wmic will create false positives.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Credential Dumping'], 'mitre_attack_id': ['T1003.003'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8', 'CIS 16'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>credential_extraction_ms_debuggers_z_option.yml</h4>

<table><tr><td>name</td><td>Credential Extraction native Microsoft debuggers via z command line option</td></tr><tr><td>id</td><td>adc51a77-90c9-4358-b43c-f10dd1a27d05</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-10-18</td></tr><tr><td>description</td><td>Credential extraction is often an illegal recovery of credential material from secured authentication resources and repositories. This process may also involve decryption or other transformations of the stored credential material. Native Microsoft debuggers, such as kd, ntkd, livekd and windbg, can be leveraged to read credential material directly from memory and process dumps.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting Windows Security logs from devices of interest, including the event ID 4688 with enabled command line logging.</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>type</td><td>SSA</td></tr><tr><td>author</td><td>Stanislav Miskovic, Splunk</td></tr><tr><td>search</td><td> | from read_ssa_enriched_events()
| eval timestamp=parse_long(ucast(map_get(input_event, "_time"), "string", null)), cmd_line=ucast(map_get(input_event, "process"), "string", null), process_name=ucast(map_get(input_event, "process_name"), "string", null) | where cmd_line != null AND process_name != null AND ( match_regex(process_name, /^(?i)ntkd\.exe/)=true OR match_regex(process_name, /^(?i)kd\.exe/)=true ) AND match_regex(cmd_line, /(?i)\-z\s+/)=true
| eval start_time = timestamp, end_time = timestamp, entities = mvappend( ucast(map_get(input_event, "dest_user_id"), "string", null), ucast(map_get(input_event, "dest_device_id"), "string", null)), body = "TBD" | into write_ssa_detected_events();</td></tr><tr><td>eli5</td><td>This detects use of -z command line option which specifies location of the credentials dump file to native Microsoft debuggers.</td></tr><tr><td>known_false_positives</td><td>Although unlikely, using debuggers this way may be indicative of developers analyzing crash dumps of their code. Note, even for developers this is an unusual way of working on code - debuggers are mostly used to step through code, not analyze its crash dumps.</td></tr><tr><td>tags</td><td>{'cis20': ['CIS 16'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_technique_id': ['T1003'], 'nist': ['PR.AC', 'PR.IP'], 'risk_severity': 'medium', 'security_domain': 'endpoint', 'asset_type': 'Windows'}</td></tr></table>
<h4>sc_exe_manipulating_windows_services.yml</h4>

<table><tr><td>name</td><td>Sc exe Manipulating Windows Services</td></tr><tr><td>id</td><td>f0c693d8-2a89-4ce7-80b4-98fea4c3ea6d</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for arguments to sc.exe indicating the creation or modification of a Windows service.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = sc.exe (Processes.process="* create *" OR Processes.process="* config *") by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `sc_exe_manipulating_windows_services_filter`</td></tr><tr><td>known_false_positives</td><td>Using sc.exe to manipulate Windows services is uncommon. However, there may be legitimate instances of this behavior. It is important to validate and investigate as appropriate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Service Abuse', 'DHS Report TA18-074A', 'Orangeworm Attack Group', 'Windows Persistence Techniques', 'Disabling Security Tools'], 'mitre_attack_id': ['T1543.003'], 'kill_chain_phases': ['Installation'], 'cis20': ['CIS 3', 'CIS 5', 'CIS 8'], 'nist': ['PR.IP', 'PR.PT', 'PR.AC', 'PR.AT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>spike_in_file_writes.yml</h4>

<table><tr><td>name</td><td>Spike in File Writes</td></tr><tr><td>id</td><td>fdb0f805-74e4-4539-8c00-618927333aae</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-03-16</td></tr><tr><td>description</td><td>The search looks for a sharp increase in the number of files written to a particular host</td></tr><tr><td>how_to_implement</td><td>In order to implement this search, you must populate the Endpoint file-system data model node. This is typically populated via endpoint detection and response products, such as Carbon Black or endpoint data sources such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the file system.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count FROM datamodel=Endpoint.Filesystem where Filesystem.action=created by _time span=1h, Filesystem.dest | `drop_dm_object_name(Filesystem)` | eventstats max(_time) as maxtime | stats count as num_data_samples max(eval(if(_time >= relative_time(maxtime, "-1d@d"), count, null))) as "count" avg(eval(if(_time<relative_time(maxtime, "-1d@d"), count,null))) as avg stdev(eval(if(_time<relative_time(maxtime, "-1d@d"), count, null))) as stdev by "dest" | eval upperBound=(avg+stdev*4), isOutlier=if((count > upperBound) AND num_data_samples >=20, 1, 0) | search isOutlier=1 | `spike_in_file_writes_filter` </td></tr><tr><td>known_false_positives</td><td>It is important to understand that if you happen to install any new applications on your hosts or are copying a large number of files, you can expect to see a large increase of file modifications.</td></tr><tr><td>tags</td><td>{'analytics_story': ['SamSam Ransomware', 'Ransomware'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>unusually_long_command_line.yml</h4>

<table><tr><td>name</td><td>Unusually Long Command Line</td></tr><tr><td>id</td><td>c77162d3-f93c-45cc-80c8-22f6a4264e7f</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-03-16</td></tr><tr><td>description</td><td>Command lines that are extremely long may be indicative of malicious activity on your hosts.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting endpoint data that tracks process activity, including parent-child relationships, from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the process field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes by Processes.user Processes.dest Processes.process_name Processes.process | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`|  eval processlen=len(process) | eventstats stdev(processlen) as stdev, avg(processlen) as avg by dest | stats max(processlen) as maxlen, values(stdev) as stdevperhost, values(avg) as avgperhost by dest, user, process_name, process | `unusually_long_command_line_filter` | eval threshold = 10 | where maxlen > ((threshold*stdevperhost) + avgperhost)</td></tr><tr><td>known_false_positives</td><td>Some legitimate applications start with long command lines.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious Command-Line Executions', 'Unusual Processes', 'Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns', 'Ransomware'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': ''}</td></tr></table>
<h4>osquery_pack___coldroot_detection.yml</h4>

<table><tr><td>name</td><td>Osquery pack - ColdRoot detection</td></tr><tr><td>id</td><td>a6fffe5e-05c3-4c04-badc-887607fbb8dc</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2019-01-29</td></tr><tr><td>description</td><td>This search looks for ColdRoot events from the osx-attacks osquery pack.</td></tr><tr><td>how_to_implement</td><td>In order to properly run this search, Splunk needs to ingest data from your osquery deployed agents with the [osx-attacks.conf](https://github.com/facebook/osquery/blob/experimental/packs/osx-attacks.conf#L599) pack enabled. Also the [TA-OSquery](https://github.com/d1vious/TA-osquery) must be deployed across your indexers and universal forwarders in order to have the osquery data populate the Alerts data model</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| from datamodel Alerts.Alerts | search app=osquery:results (name=pack_osx-attacks_OSX_ColdRoot_RAT_Launchd OR name=pack_osx-attacks_OSX_ColdRoot_RAT_Files) | rename columns.path as path | bucket _time span=30s | stats count(path) by _time, host, user, path | `osquery_pack___coldroot_detection_filter`</td></tr><tr><td>known_false_positives</td><td>There are no known false positives.</td></tr><tr><td>tags</td><td>{'analytics_story': ['ColdRoot MacOS RAT'], 'kill_chain_phases': ['Installation', 'Command and Control'], 'cis20': ['CIS 4', 'CIS 8'], 'nist': ['DE.DP', 'DE.CM', 'PR.PT'], 'security_domain': 'threat', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>first_time_seen_command_line_argument.yml</h4>

<table><tr><td>name</td><td>First time seen command line argument</td></tr><tr><td>id</td><td>9be56c82-b1cc-4318-87eb-q138afaaqa39</td></tr><tr><td>version</td><td>5</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for command-line arguments that use a `/c` parameter to execute a command that has not previously been seen.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must be ingesting logs with both the process name and command line from your endpoints. The complete process name with command-line arguments are mapped to the "process" field in the Endpoint data model. Please make sure you run the support search "Previously seen command line arguments,"&#151;which creates a lookup file called `previously_seen_cmd_line_arguments.csv`&#151;a historical baseline of all command-line arguments. You must also validate this list. For the search to do accurate calculation, ensure the search scheduling is the same value as the `relative_time` evaluation function.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = cmd.exe Processes.process = "* /c *" by Processes.process Processes.process_name Processes.parent_process_name Processes.dest| `drop_dm_object_name(Processes)`| `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | search [| tstats `security_content_summariesonly` earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = cmd.exe Processes.process = "* /c *" by Processes.process | `drop_dm_object_name(Processes)` | inputlookup append=t previously_seen_cmd_line_arguments | stats min(firstTime) as firstTime, max(lastTime) as lastTime by process | outputlookup previously_seen_cmd_line_arguments | eval newCmdLineArgument=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newCmdLineArgument=1 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | table process] | `first_time_seen_command_line_argument_filter` </td></tr><tr><td>known_false_positives</td><td>Legitimate programs can also use command-line arguments to execute. Please verify the command-line arguments to check what command/program is being executed. We recommend customizing the `first_time_seen_cmd_line_filter` macro to exclude legitimate parent_process_name</td></tr><tr><td>tags</td><td>{'analytics_story': ['DHS Report TA18-074A', 'Suspicious Command-Line Executions', 'Orangeworm Attack Group', 'Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns', 'Hidden Cobra Malware'], 'mitre_attack_id': ['T1059.001', 'T1059.003'], 'kill_chain_phases': ['Command and Control', 'Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 8'], 'nist': ['PR.PT', 'DE.CM', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_activity_related_to_pass_the_hash_attacks.yml</h4>

<table><tr><td>name</td><td>Detect Activity Related to Pass the Hash Attacks</td></tr><tr><td>id</td><td>f5939373-8054-40ad-8c64-cec478a22a4b</td></tr><tr><td>version</td><td>5</td></tr><tr><td>date</td><td>2020-10-15</td></tr><tr><td>description</td><td>This search looks for specific authentication events from the Windows Security Event logs to detect potential attempts at using the Pass-the-Hash technique.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must ingest your Windows Security Event logs and leverage the latest TA for Windows.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Patrick Bareiss, Splunk</td></tr><tr><td>search</td><td>`wineventlog_security` EventCode=4624 (Logon_Type=3 Logon_Process=NtLmSsp WorkstationName=WORKSTATION NOT AccountName="ANONYMOUS LOGON") OR (Logon_Type=9 Logon_Process=seclogo) | fillnull | stats count min(_time) as firstTime max(_time) as lastTime by EventCode, Logon_Type, WorkstationName, user, dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_activity_related_to_pass_the_hash_attacks_filter` </td></tr><tr><td>known_false_positives</td><td>Legitimate logon activity by authorized NTLM systems may be detected by this search. Please investigate as appropriate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Lateral Movement'], 'mitre_attack_id': ['T1550.002'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 5', 'CIS 16'], 'nist': ['PR.PT', 'PR.AT', 'PR.AC', 'PR.IP'], 'security_domain': 'access', 'asset_type': 'Endpoint', 'automated_detection_testing': 'passed', 'dataset': ['https://attack-range-attack-data.s3-us-west-2.amazonaws.com/T1550.002/windows-security.log']}</td></tr></table>
<h4>usn_journal_deletion.yml</h4>

<table><tr><td>name</td><td>USN Journal Deletion</td></tr><tr><td>id</td><td>b6e0ff70-b122-4227-9368-4cf322ab43c3</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2018-12-03</td></tr><tr><td>description</td><td>The fsutil.exe application is a legitimate Windows utility used to perform tasks related to the file allocation table (FAT) and NTFS file systems. The update sequence number (USN) change journal provides a log of all changes made to the files on the disk. This search looks for fsutil.exe deleting the USN journal.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=fsutil.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | search process="*deletejournal*" AND process="*usn*" | `usn_journal_deletion_filter`</td></tr><tr><td>known_false_positives</td><td>None identified</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Log Manipulation', 'Ransomware'], 'mitre_attack_id': ['T1070'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 6', 'CIS 8', 'CIS 10'], 'nist': ['DE.CM', 'PR.PT', 'DE.AE', 'DE.DP', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>hiding_files_and_directories_with_attrib_exe.yml</h4>

<table><tr><td>name</td><td>Hiding Files And Directories With Attrib exe</td></tr><tr><td>id</td><td>c77162d3-f93c-45cc-80c8-22f6b5264g9f</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>Attackers leverage an existing Windows binary, attrib.exe, to mark specific as hidden by using specific flags so that the victim does not see the file.  The search looks for specific command-line arguments to detect the use of attrib.exe to hide files.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) values(Processes.process) as process max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=attrib.exe (Processes.process=*+h*) by Processes.parent_process Processes.process_name Processes.user Processes.dest | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`| `hiding_files_and_directories_with_attrib_exe_filter` </td></tr><tr><td>known_false_positives</td><td>Some applications and users may legitimately use attrib.exe to interact with the files. </td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Defense Evasion Tactics', 'Windows Persistence Techniques'], 'mitre_attack_id': ['T1222.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': ''}</td></tr></table>
<h4>suspicious_file_write.yml</h4>

<table><tr><td>name</td><td>Suspicious File Write</td></tr><tr><td>id</td><td>57f76b8a-32f0-42ed-b358-d9fa3ca7bac8</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2019-04-25</td></tr><tr><td>description</td><td>The search looks for files created with names that have been linked to malicious activity.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records the filesystem activity from your hosts to populate the Endpoint file-system data model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or via other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file system reads and writes. In addition, this search leverages an included lookup file that contains the names of the files to watch for, as well as a note to communicate why that file name is being monitored. This lookup file can be edited to add or remove file the file names you want to monitor.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Filesystem.action) as action values(Filesystem.file_path) as file_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Filesystem by Filesystem.file_name Filesystem.dest | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name(Filesystem)` | `suspicious_writes` | `suspicious_file_write_filter`</td></tr><tr><td>known_false_positives</td><td>It's possible for a legitimate file to be created with the same name as one noted in the lookup file. Filenames listed in the lookup file should be unique enough that collisions are rare. Looking at the location of the file and the process responsible for the activity can help determine whether or not the activity is legitimate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Hidden Cobra Malware'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>wmi_permanent_event_subscription.yml</h4>

<table><tr><td>name</td><td>WMI Permanent Event Subscription</td></tr><tr><td>id</td><td>71bfdb13-f200-4c6c-b2c9-a2e07adf437d</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-10-23</td></tr><tr><td>description</td><td>This search looks for the creation of WMI permanent event subscriptions.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must be ingesting the Windows WMI activity logs. This can be done by adding a stanza to inputs.conf on the system generating logs with a title of [WinEventLog://Microsoft-Windows-WMI-Activity/Operational].</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>`wmi` EventCode=5861 Binding | rex field=Message "Consumer =\s+(?<consumer>[^;|^$]+)" | search consumer!="NTEventLogEventConsumer=\"SCM Event Log Consumer\"" | stats count min(_time) as firstTime max(_time) as lastTime by ComputerName, consumer, Message | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | rename ComputerName as dest | `wmi_permanent_event_subscription_filter`</td></tr><tr><td>known_false_positives</td><td>Although unlikely, administrators may use event subscriptions for legitimate purposes.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious WMI Use'], 'mitre_attack_id': ['T1047'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 5'], 'nist': ['PR.PT', 'PR.AT', 'PR.AC', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>credential_extraction_fgdump_cachedump_v_option_ssa.yml</h4>

<table><tr><td>name</td><td>Credential Extraction indicative of FGDump and CacheDump with v option</td></tr><tr><td>id</td><td>3c40b0ef-a03f-460a-9484-e4b9117cbb38</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-10-18</td></tr><tr><td>description</td><td>Credential extraction is often an illegal recovery of credential material from secured authentication resources and repositories. This process may also involve decryption or other transformations of the stored credential material. FGdump is a newer version of pwdump tool that extracts NTLM and LanMan password hashes from Windows. Cachedump is a publicly-available tool that extracts cached password hashes from a system's registry.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting Windows Security logs from devices of interest, including the event ID 4688 with enabled command line logging.</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>type</td><td>SSA</td></tr><tr><td>author</td><td>Stanislav Miskovic, Splunk</td></tr><tr><td>search</td><td> | from read_ssa_enriched_events()
| eval timestamp=parse_long(ucast(map_get(input_event, "_time"), "string", null)), cmd_line=ucast(map_get(input_event, "process"), "string", null), process_name=ucast(map_get(input_event, "process_name"), "string", null), process_path=ucast(map_get(input_event, "process_path"), "string", null) | where cmd_line != null AND process_name != null AND process_path != null AND match_regex(process_name, /(?i)cachedump\d{0,2}.exe/)=true AND match_regex(process_path, /(?i)\\Temp/)=true AND match_regex(cmd_line, /(?i)\-v/)=true
| eval start_time = timestamp, end_time = timestamp, entities = mvappend( ucast(map_get(input_event, "dest_user_id"), "string", null), ucast(map_get(input_event, "dest_device_id"), "string", null)), body = "TBD" | into write_ssa_detected_events();</td></tr><tr><td>eli5</td><td>This detection identifies one of the stages of FGdump in which CacheDump is called. Note, CacheDump activity may also be embedded in other exploit tools. For more details on FGdump stages see https://github.com/interference-security/kali-windows-binaries/tree/master/fgdump</td></tr><tr><td>known_false_positives</td><td>None identified.</td></tr><tr><td>tags</td><td>{'cis20': ['CIS 16'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_technique_id': ['T1003'], 'nist': ['PR.AC', 'PR.IP'], 'risk_severity': 'high', 'security_domain': 'endpoint', 'asset_type': 'Windows'}</td></tr></table>
<h4>detect_excessive_account_lockouts_from_endpoint.yml</h4>

<table><tr><td>name</td><td>Detect Excessive Account Lockouts From Endpoint</td></tr><tr><td>id</td><td>c026e3dd-7e18-4abb-8f41-929e836efe74</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search identifies endpoints that have caused a relatively high number of account lockouts in a short period.</td></tr><tr><td>how_to_implement</td><td>You must ingest your Windows security event logs in the `Change` datamodel under the nodename is `Account_Management`, for this search to execute successfully. Please consider updating the cron schedule and the count of lockouts you want to monitor, according to your environment. \
 **Splunk>Phantom Playbook Integration**\
If Splunk>Phantom is also configured in your environment, a Playbook called "Excessive Account Lockouts Enrichment and Response" can be configured to run when any results are found by this detection search. The Playbook executes the Contextual and Investigative searches in this Story, conducts additional information gathering on Windows endpoints, and takes a response action to shut down the affected endpoint. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/`, add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search, and set the corresponding Playbook to active. \
(Playbook Link:`https://my.phantom.us/4.1/playbook/excessive-account-lockouts-enrichment-and-response/`).\
</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Change.All_Changes where nodename=All_Changes.Account_Management All_Changes.result="lockout" by All_Changes.dest All_Changes.result |`drop_dm_object_name("All_Changes")` |`drop_dm_object_name("Account_Management")`| `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | search count > 5 | `detect_excessive_account_lockouts_from_endpoint_filter`</td></tr><tr><td>known_false_positives</td><td>It's possible that a widely used system, such as a kiosk, could cause a large number of account lockouts.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Account Monitoring and Controls'], 'mitre_attack_id': ['T1078.003'], 'cis20': ['CIS 16'], 'nist': ['PR.IP'], 'security_domain': 'access', 'asset_type': 'Windows'}</td></tr></table>
<h4>attempted_credential_dump_from_registry_via_reg_exe___ssa.yml</h4>

<table><tr><td>name</td><td>Attempted Credential Dump From Registry via Reg exe - SSA</td></tr><tr><td>id</td><td>14038953-e5f2-4daf-acff-5452062baf03</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-6-04</td></tr><tr><td>description</td><td>Monitor for execution of reg.exe with parameters specifying an export of keys that contain hashed credentials that attackers may try to crack offline.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting windows endpoint data that tracks process activity, including parent-child relationships from your endpoints.</td></tr><tr><td>type</td><td>SSA</td></tr><tr><td>references</td><td>['https://github.com/splunk/security-content/blob/55a17c65f9f56c2220000b62701765422b46125d/detections/attempted_credential_dump_from_registry_via_reg_exe.yml']</td></tr><tr><td>author</td><td>Jose Hernandez, Splunk</td></tr><tr><td>search</td><td> | from read_ssa_enriched_events() | eval timestamp=parse_long(ucast(map_get(input_event, "_time"), "string", null)) | eval process_name=lower(ucast(map_get(input_event, "process_name"), "string", null)), cmd_line=ucast(map_get(input_event, "process"), "string", null), dest_user_id=ucast(map_get(input_event, "dest_user_id"), "string", null), dest_device_id=ucast(map_get(input_event, "dest_device_id"), "string", null) | where process_name="cmd.exe" OR process_name="reg.exe" | where cmd_line != null  AND match_regex(cmd_line, /(?i)save\s+/)=true AND ( match_regex(cmd_line, /(?i)HKLM\\Security/)=true OR match_regex(cmd_line, /(?i)HKLM\\SAM/)=true OR match_regex(cmd_line, /(?i)HKLM\\System/)=true OR match_regex(cmd_line, /(?i)HKEY_LOCAL_MACHINE\\Security/)=true OR match_regex(cmd_line, /(?i)HKEY_LOCAL_MACHINE\\SAM/)=true OR match_regex(cmd_line, /(?i)HKEY_LOCAL_MACHINE\\System/)=true ) | eval start_time = timestamp, end_time = timestamp, entities = mvappend(dest_device_id, dest_user_id), body = "TBD" | into write_ssa_detected_events(); </td></tr><tr><td>known_false_positives</td><td>None identified.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Credential Dumping'], 'mitre_attack_id': ['T1003'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 5', 'CIS 16'], 'nist': ['DE.CM'], 'risk_severity': 'low', 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>execution_of_file_with_spaces_before_extension.yml</h4>

<table><tr><td>name</td><td>Execution of File With Spaces Before Extension</td></tr><tr><td>id</td><td>ab0353e6-a956-420b-b724-a8b4846d5d5a</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for processes launched from files with at least five spaces in the name before the extension. This is typically done to obfuscate the file extension by pushing it outside of the default view.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process_path) as process_path min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process = "*     .*" by Processes.dest Processes.user Processes.process Processes.process_name | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)` | `execution_of_file_with_spaces_before_extension_filter`</td></tr><tr><td>known_false_positives</td><td>None identified.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows File Extension and Association Abuse'], 'mitre_attack_id': ['T1036'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 8'], 'nist': ['DE.CM', 'PR.PT', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>extended_period_without_successful_netbackup_backups.yml</h4>

<table><tr><td>name</td><td>Extended Period Without Successful Netbackup Backups</td></tr><tr><td>id</td><td>a34aae96-ccf8-4aef-952c-3ea214444440</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-09-12</td></tr><tr><td>description</td><td>This search returns a list of hosts that have not successfully completed a backup in over a week.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search you need to first obtain data from your backup solution, either from the backup logs on your hosts, or from a central server responsible for performing the backups. If you do not use Netbackup, you can modify this search for your backup solution. Depending on how often you backup your systems, you may want to modify how far in the past to look for a successful backup, other than the default of seven days.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>`netbackup` MESSAGE="Disk/Partition backup completed successfully." | stats latest(_time) as latestTime by COMPUTERNAME | `security_content_ctime(latestTime)` | rename COMPUTERNAME as dest | eval isOutlier=if(latestTime <= relative_time(now(), "-7d@d"), 1, 0) | search isOutlier=1 | table latestTime, dest | `extended_period_without_successful_netbackup_backups_filter`</td></tr><tr><td>known_false_positives</td><td>None identified</td></tr><tr><td>tags</td><td>{'analytics_story': ['Monitor Backup Solution'], 'cis20': ['CIS 10'], 'nist': ['PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>windows_hosts_file_modification.yml</h4>

<table><tr><td>name</td><td>Windows hosts file modification</td></tr><tr><td>id</td><td>06a6fc63-a72d-41dc-8736-7e3dd9612116</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-11-02</td></tr><tr><td>description</td><td>The search looks for modifications to the hosts file on all Windows endpoints across your environment.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must be ingesting data that records the file-system activity from your hosts to populate the Endpoint.Filesystem data model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or by other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file-system reads and writes.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Filesystem  by Filesystem.file_name Filesystem.file_path Filesystem.dest | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | search Filesystem.file_name=hosts AND Filesystem.file_path=*Windows\\System32\\* | `drop_dm_object_name(Filesystem)` | `windows_hosts_file_modification_filter`</td></tr><tr><td>known_false_positives</td><td>There may be legitimate reasons for system administrators to add entries to this file.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Host Redirection'], 'kill_chain_phases': ['Command and Control'], 'cis20': ['CIS 3', 'CIS 8', 'CIS 12'], 'nist': ['PR.IP', 'PR.PT', 'PR.AC', 'DE.AE', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>system_information_discovery_detection.yml</h4>

<table><tr><td>name</td><td>System Information Discovery Detection</td></tr><tr><td>id</td><td>8e99f89e-ae58-4ebc-bf52-ae0b1a277e72</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-10-12</td></tr><tr><td>description</td><td>Detect system information discovery techniques used by attackers to understand configurations of the system to further exploit it.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://oscp.infosecsanyam.in/priv-escalation/windows-priv-escalation']</td></tr><tr><td>author</td><td>Patrick Bareiss, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process="*wmic* qfe*" OR Processes.process=*systeminfo* OR Processes.process=*hostname*) by Processes.user Processes.process_name Processes.process Processes.dest | `drop_dm_object_name(Processes)` | eventstats dc(process) as dc_processes_by_dest by dest | where dc_processes_by_dest > 2 | stats values(process) min(firstTime) as firstTime max(lastTime) as lastTime by user, dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `system_information_discovery_detection_filter`</td></tr><tr><td>known_false_positives</td><td>Administrators debugging servers</td></tr><tr><td>tags</td><td>{'analytics_story': ['Discovery Techniques'], 'asset_type': 'Windows', 'cis20': ['CIS 6', 'CIS 8'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1082'], 'nist': ['DE.CM'], 'security_domain': 'endpoint'}</td></tr></table>
<h4>credential_extraction_getaddbaccount_from_dump_ssa.yml</h4>

<table><tr><td>name</td><td>Credential Extraction via Get-ADDBAccount module present in PowerSploit and DSInternals</td></tr><tr><td>id</td><td>e4f126b5-e6bc-4a5c-b1a8-d07bc6c4a49f</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-10-18</td></tr><tr><td>description</td><td>Credential extraction is often an illegal recovery of credential material from secured authentication resources and repositories. This process may also involve decryption or other transformations of the stored credential material. PowerSploit and DSInternals are common exploit APIs offering PowerShell modules for various exploits of Windows and Active Directory environments.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting Windows Security logs from devices of interest, including the event ID 4688 with enabled command line logging.</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>type</td><td>SSA</td></tr><tr><td>author</td><td>Stanislav Miskovic, Splunk</td></tr><tr><td>search</td><td> | from read_ssa_enriched_events()
| eval timestamp=parse_long(ucast(map_get(input_event, "_time"), "string", null)), cmd_line=ucast(map_get(input_event, "process"), "string", null) | where cmd_line != null AND match_regex(cmd_line, /(?i)Get-ADDBAccount/)=true AND match_regex(cmd_line, /(?i)\-dbpath[\s;:\.\|]+/)=true
| eval start_time = timestamp, end_time = timestamp, entities = mvappend( ucast(map_get(input_event, "dest_user_id"), "string", null), ucast(map_get(input_event, "dest_device_id"), "string", null)), body = "TBD" | into write_ssa_detected_events();</td></tr><tr><td>eli5</td><td>This detection identifies triggering of the PowerSploit or DSInternals for extraction of all accounts from a previously dumped ntds.dit credential store.</td></tr><tr><td>known_false_positives</td><td>None identified.</td></tr><tr><td>tags</td><td>{'cis20': ['CIS 16'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_technique_id': ['T1003'], 'nist': ['PR.IP', 'PR.AC'], 'risk_severity': 'high', 'security_domain': 'endpoint', 'asset_type': 'Windows'}</td></tr></table>
<h4>processes_created_by_netsh.yml</h4>

<table><tr><td>name</td><td>Processes created by netsh</td></tr><tr><td>id</td><td>b89919ed-fe5f-492c-b139-95dbb162041e</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for processes launching netsh.exe to execute various commands via the netsh command-line utility. Netsh.exe is a command-line scripting utility that allows you to, either locally or remotely, display or modify the network configuration of a computer that is currently running. Netsh can be used as a persistence proxy technique to execute a helper .dll when netsh.exe is executed. In this search, we are looking for processes spawned by netsh.exe that are executing commands via the command line.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must be ingesting logs with the process name, command-line arguments, and parent processes from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.parent_process="*C:\\Windows\\System32\\netsh.exe*" AND Processes.process_path!="C:\\Program Files\\rempl\\sedlauncher.exe") by Processes.user Processes.dest Processes.parent_process Processes.parent_process_name Processes.process_name | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `processes_created_by_netsh_filter`</td></tr><tr><td>known_false_positives</td><td>It is unusual for netsh.exe to have any child processes in most environments. It makes sense to investigate the child process and verify whether the process spawned is legitimate. We explicitely exclude "C:\Program Files\rempl\sedlauncher.exe" process path since it is a legitimate process by Mircosoft.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Netsh Abuse'], 'mitre_attack_id': ['T1059.001', 'T1059.003'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>malicious_powershell_process___encoded_command.yml</h4>

<table><tr><td>name</td><td>Malicious PowerShell Process - Encoded Command</td></tr><tr><td>id</td><td>c4db14d9-7909-48b4-a054-aa14d89dbb19</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for PowerShell processes that have encoded the script within the command-line. Malware has been seen using this parameter, as it obfuscates the code and makes it relatively easy to pass a script on the command-line.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = powershell.exe (Processes.process=*-EncodedCommand* OR Processes.process=*-enc*) by Processes.user Processes.process_name Processes.process Processes.parent_process_name Processes.dest Processes.process_id | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `malicious_powershell_process___encoded_command_filter`</td></tr><tr><td>known_false_positives</td><td>System administrators may use this option, but it's not common.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Malicious PowerShell'], 'mitre_attack_id': ['T1027'], 'kill_chain_phases': ['Command and Control', 'Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 7', 'CIS 8'], 'nist': ['PR.PT', 'DE.CM', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>create_remote_thread_into_lsass.yml</h4>

<table><tr><td>name</td><td>Create Remote Thread into LSASS</td></tr><tr><td>id</td><td>67d4dbef-9564-4699-8da8-03a151529edc</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2019-12-06</td></tr><tr><td>description</td><td>Detect remote thread creation into LSASS consistent with credential dumping.</td></tr><tr><td>how_to_implement</td><td>This search needs Sysmon Logs with a Sysmon configuration, which includes EventCode 8 with lsass.exe. This search uses an input macro named `sysmon`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Sysmon logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://2017.zeronights.org/wp-content/uploads/materials/ZN17_Kheirkhabarov_Hunting_for_Credentials_Dumping_in_Windows_Environment.pdf']</td></tr><tr><td>author</td><td>Patrick Bareiss, Splunk</td></tr><tr><td>search</td><td>`sysmon` EventID=8 TargetImage=*lsass.exe | stats count min(_time) as firstTime max(_time) as lastTime by Computer, EventCode, TargetImage, TargetProcessId | rename Computer as dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `create_remote_thread_into_lsass_filter`</td></tr><tr><td>known_false_positives</td><td>Other tools can access LSASS for legitimate reasons and generate an event. In these cases, tweaking the search may help eliminate noise.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Credential Dumping'], 'mitre_attack_id': ['T1003.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8', 'CIS 16'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Windows'}</td></tr></table>
<h4>processes_launching_netsh.yml</h4>

<table><tr><td>name</td><td>Processes launching netsh</td></tr><tr><td>id</td><td>b89919ed-fe5f-492c-b139-95dbb162040e</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-10</td></tr><tr><td>description</td><td>This search looks for processes launching netsh.exe. Netsh is a command-line scripting utility that allows you to, either locally or remotely, display or modify the network configuration of a computer that is currently running. Netsh can be used as a persistence proxy technique to execute a helper DLL when netsh.exe is executed. In this search, we are looking for processes spawned by netsh.exe and executing commands via the command line.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Josef Kuepker, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process) AS Processes.process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=netsh.exe by Processes.parent_process_name Processes.parent_process Processes.process_name Processes.user Processes.dest |`drop_dm_object_name("Processes")` |`security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` |`processes_launching_netsh_filter`</td></tr><tr><td>known_false_positives</td><td>Some VPN applications are known to launch netsh.exe. Outside of these instances, it is unusual for an executable to launch netsh.exe and run commands.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Netsh Abuse', 'Disabling Security Tools', 'DHS Report TA18-074A'], 'mitre_attack_id': ['T1562.004'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>remote_process_instantiation_via_wmi.yml</h4>

<table><tr><td>name</td><td>Remote Process Instantiation via WMI</td></tr><tr><td>id</td><td>d25d2c3d-d9d8-40ec-8fdf-e86fe155a3da</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for wmic.exe being launched with parameters to spawn a process on a remote system.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = wmic.exe Processes.process="*/node*" Processes.process="*process*" Processes.process="*call*" Processes.process="*create*"   by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` | `remote_process_instantiation_via_wmi_filter`</td></tr><tr><td>known_false_positives</td><td>The wmic.exe utility is a benign Windows application. It may be used legitimately by Administrators with these parameters for remote system administration, but it's relatively uncommon.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Ransomware', 'Suspicious WMI Use'], 'mitre_attack_id': ['T1021.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 5'], 'nist': ['PR.PT', 'PR.AT', 'PR.AC', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>rundll_loading_dll_by_ordinal.yml</h4>

<table><tr><td>name</td><td>RunDLL Loading DLL By Ordinal</td></tr><tr><td>id</td><td>6c135f8d-5e60-454e-80b7-c56eed739833</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for DLLs under %AppData% being loaded by rundll32.exe that are calling the exported function at ordinal 2. Calling exported functions by ordinal is not as common as calling by exported name. There was a bug fixed in IDAPro on 2016-08-08 that would not display functions without names.  Calling functions by ordinal would overcome the lack of name and make it harder for analyst to reverse engineer.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = rundll32.exe Processes.process="*AppData*" Processes.process="*,#2" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `rundll_loading_dll_by_ordinal_filter`</td></tr><tr><td>known_false_positives</td><td>While not common, loading a DLL under %AppData% and calling a function by ordinal is possible by a legitimate process</td></tr><tr><td>tags</td><td>{'analytics_story': ['Unusual Processes'], 'mitre_attack_id': ['T1218.011'], 'kill_chain_phases': ['Installation'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>remote_registry_key_modifications.yml</h4>

<table><tr><td>name</td><td>Remote Registry Key modifications</td></tr><tr><td>id</td><td>c9f4b923-f8af-4155-b697-1354f5dcbc5e</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-03-02</td></tr><tr><td>description</td><td>This search monitors for remote modifications to registry keys.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must populate the `Endpoint` data model. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Registry.registry_key_name) as registry_key_name values(Registry.registry_path) as registry_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where  Registry.registry_path="\\\\*"  by Registry.dest , Registry.user | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name(Registry)` | `remote_registry_key_modifications_filter`</td></tr><tr><td>known_false_positives</td><td>This technique may be legitimately used by administrators to modify remote registries, so it's important to filter these events out.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Defense Evasion Tactics', 'Suspicious Windows Registry Activities', 'Windows Persistence Techniques'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>rare_parent_process_relationship_lolbas___ssa.yaml</h4>

<table><tr><td>name</td><td>Rare Parent/Child Process Relationship - SSA</td></tr><tr><td>id</td><td>e03aa905-6549-4e34-b304-7a922185b2c4</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-08-13</td></tr><tr><td>description</td><td>An attacker may use LOLBAS tools spawned from vulnerable applications not typically used by system administrators. This search leverages the Splunk Streaming ML DSP plugin to find rare parent/child relationships. The list of application has been extracted from https://github.com/LOLBAS-Project/LOLBAS/tree/master/yml/OSBinaries</td></tr><tr><td>how_to_implement</td><td>Collect endpoint data such as sysmon or 4688 events.</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>type</td><td>SSA</td></tr><tr><td>author</td><td>Ignacio Bermudez Corrales, Splunk</td></tr><tr><td>search</td><td>| from read_ssa_enriched_events() | eval timestamp=parse_long(ucast(map_get(input_event, "_time"), "string", null)) | eval parent_process=lower(ucast(map_get(input_event, "parent_process_name"), "string", null)), process_name=lower(ucast(map_get(input_event, "process_name"), "string", null)), dest_user_id=ucast(map_get(input_event, "dest_user_id"), "string", null), dest_device_id=ucast(map_get(input_event, "dest_device_id"), "string", null)
| where parent_process!=null | select parent_process, process_name, timestamp, dest_device_id, dest_user_id | conditional_anomaly conditional="parent_process" target="process_name" | rename output as input | adaptive_threshold algorithm="quantile" entity="parent_process" window=604800000L | where label AND quantile<0.1 AND (process_name="powershell.exe" OR process_name="regsvcs.exe" OR process_name="ftp.exe" OR process_name="dfsvc.exe" OR process_name="rasautou.exe" OR process_name="schtasks.exe" OR process_name="xwizard.exe" OR process_name="findstr.exe" OR process_name="esentutl.exe" OR process_name="cscript.exe" OR process_name="reg.exe" OR process_name="csc.exe" OR process_name="atbroker.exe" OR process_name="print.exe" OR process_name="pcwrun.exe" OR process_name="vbc.exe" OR process_name="rpcping.exe" OR process_name="wsreset.exe" OR process_name="ilasm.exe" OR process_name="certutil.exe" OR process_name="replace.exe" OR process_name="mshta.exe" OR process_name="bitsadmin.exe" OR process_name="wscript.exe" OR process_name="ieexec.exe" OR process_name="cmd.exe" OR process_name="microsoft.workflow.compiler.exe" OR process_name="runscripthelper.exe" OR process_name="makecab.exe" OR process_name="forfiles.exe" OR process_name="desktopimgdownldr.exe" OR process_name="control.exe" OR process_name="msbuild.exe" OR process_name="register-cimprovider.exe" OR process_name="tttracer.exe" OR process_name="ie4uinit.exe" OR process_name="sc.exe" OR process_name="bash.exe" OR process_name="hh.exe" OR process_name="cmstp.exe" OR process_name="mmc.exe" OR process_name="jsc.exe" OR process_name="scriptrunner.exe" OR process_name="odbcconf.exe" OR process_name="extexport.exe" OR process_name="msdt.exe" OR process_name="diskshadow.exe" OR process_name="extrac32.exe" OR process_name="eventvwr.exe" OR process_name="mavinject.exe" OR process_name="regasm.exe" OR process_name="gpscript.exe" OR process_name="rundll32.exe" OR process_name="regsvr32.exe" OR process_name="regedit.exe" OR process_name="msiexec.exe" OR process_name="gfxdownloadwrapper.exe" OR process_name="presentationhost.exe" OR process_name="regini.exe" OR process_name="wmic.exe" OR process_name="runonce.exe" OR process_name="syncappvpublishingserver.exe" OR process_name="verclsid.exe" OR process_name="psr.exe" OR process_name="infdefaultinstall.exe" OR process_name="explorer.exe" OR process_name="expand.exe" OR process_name="installutil.exe" OR process_name="netsh.exe" OR process_name="wab.exe" OR process_name="dnscmd.exe" OR process_name="at.exe" OR process_name="pcalua.exe" OR process_name="cmdkey.exe" OR process_name="msconfig.exe")
| eval start_time = timestamp, end_time = timestamp, entities = mvappend(dest_device_id, dest_user_id), body = "TBD" | into write_ssa_detected_events();</td></tr><tr><td>known_false_positives</td><td>Some custom tools used by admins could be used rarely to launch remotely applications. This might trigger false positives at the beginning when it hasn't collected yet enough data to construct the baseline.
</td></tr><tr><td>tags</td><td>{'mitre_technique_id': ['T1203', 'T1059', 'T1053', 'T1072'], 'kill_chain_phases': ['Exploitation'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'risk_severity': 'low', 'security_domain': 'endpoint'}</td></tr></table>
<h4>detect_rare_executables.yml</h4>

<table><tr><td>name</td><td>Detect Rare Executables</td></tr><tr><td>id</td><td>44fddcb2-8d3b-454c-874e-7c6de5a4f7ac</td></tr><tr><td>version</td><td>5</td></tr><tr><td>date</td><td>2020-03-16</td></tr><tr><td>description</td><td>This search will return a table of rare processes, the names of the systems running them, and the users who initiated each process.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must be ingesting data that records process activity from your hosts and populating the endpoint data model with the resultant dataset. The macro `filter_rare_process_whitelist` searches two lookup files to whitelist your processes.  These consist of `rare_process_whitelist_default.csv` and `rare_process_whitelist_local.csv`. To add your own processes to the whitelist, add them to `rare_process_whitelist_local.csv`. If you wish to remove an entry from the default lookup file, you will have to modify the macro itself to set the whitelist value for that process to false. You can modify the limit parameter and search scheduling to better suit your environment.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.dest) as dest values(Processes.user) as user min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.process_name  | rename Processes.process_name as process | rex field=user "(?<user_domain>.*)\\\\(?<user_name>.*)" | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| search [| tstats count from datamodel=Endpoint.Processes by Processes.process_name | rare Processes.process_name limit=30 | rename Processes.process_name as process| `filter_rare_process_whitelist`| table process ] | `detect_rare_executables_filter` </td></tr><tr><td>known_false_positives</td><td>Some legitimate processes may be only rarely executed in your environment. As these are identified, update `rare_process_whitelist_local.csv` to filter them out of your search results.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Emotet Malware  DHS Report TA18-201A ', 'Unusual Processes'], 'kill_chain_phases': ['Installation', 'Command and Control', 'Actions on Objectives'], 'cis20': ['CIS 2', 'CIS 8'], 'nist': ['ID.AM', 'PR.PT', 'PR.DS', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>batch_file_write_to_system32.yml</h4>

<table><tr><td>name</td><td>Batch File Write to System32</td></tr><tr><td>id</td><td>503d17cb-9eab-4cf8-a20e-01d5c6987ae3</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-12-14</td></tr><tr><td>description</td><td>The search looks for a batch file (.bat) written to the Windows system directory tree.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records the file-system activity from your hosts to populate the Endpoint file-system data-model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.dest) as dest values(Filesystem.file_name) as file_name values(Filesystem.user) as user from datamodel=Endpoint.Filesystem by Filesystem.file_path | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`| rex field=file_name "(?<file_extension>\.[^\.]+)$" | search file_path=*system32* AND file_extension=.bat | `batch_file_write_to_system32_filter`</td></tr><tr><td>known_false_positives</td><td>It is possible for this search to generate a notable event for a batch file write to a path that includes the string "system32", but is not the actual Windows system directory. As such, you should confirm the path of the batch file identified by the search. In addition, a false positive may be generated by an administrator copying a legitimate batch file in this directory tree. You should confirm that the activity is legitimate and modify the search to add exclusions, as necessary.</td></tr><tr><td>tags</td><td>{'analytics_story': ['SamSam Ransomware'], 'kill_chain_phases': ['Delivery'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>uncommon_processes_on_endpoint.yml</h4>

<table><tr><td>name</td><td>Uncommon Processes On Endpoint</td></tr><tr><td>id</td><td>29ccce64-a10c-4389-a45f-337cb29ba1f7</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-22</td></tr><tr><td>description</td><td>This search looks for applications on the endpoint that you have marked as uncommon.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model. This search uses a lookup file `uncommon_processes_default.csv` to track various features of process names that are usually uncommon in most environments. Please consider updating `uncommon_processes_local.csv` to hunt for processes that are uncommon in your environment.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest Processes.user Processes.process Processes.process_name | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)` | `uncommon_processes` |`uncommon_processes_on_endpoint_filter` </td></tr><tr><td>known_false_positives</td><td>None identified</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Privilege Escalation', 'Unusual Processes'], 'mitre_attack_id': ['T1204.002'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 2'], 'nist': ['ID.AM', 'PR.DS'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>unusually_long_command_line___ssa.yml</h4>

<table><tr><td>name</td><td>Unusually Long Command Line - SSA</td></tr><tr><td>id</td><td>58f43aba-1775-445e-b19c-be2b87d83ae3</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-10-06</td></tr><tr><td>description</td><td>Command lines that are extremely long may be indicative of malicious activity on your hosts. This search leverages the Splunk Streaming ML DSP plugin to help identify command lines with lengths that are unusual for a given user. This detection is inspired on Unusually Long Command Line authored by Rico Valdez.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting sysmon endpoint data that monitors command lines.</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>type</td><td>SSA</td></tr><tr><td>author</td><td>Ignacio Bermudez Corrales, Splunk</td></tr><tr><td>search</td><td> | from read_ssa_enriched_events() | eval timestamp=parse_long(ucast(map_get(input_event, "_time"), "string", null)) | eval cmd_line=ucast(map_get(input_event, "process"), "string", null), dest_user_id=ucast(map_get(input_event, "dest_user_id"), "string", null), dest_device_id=ucast(map_get(input_event, "dest_device_id"), "string", null), process_name=ucast(map_get(input_event, "process_name"), "string", null) | where cmd_line!=null and dest_user_id!=null | eval cmd_line_norm=replace(cast(cmd_line, "string"), /\s(--?\w+)|(\/\w+)/, " ARG"), cmd_line_norm=replace(cmd_line_norm, /\w:\\[^\s]+/, "PATH"), cmd_line_norm=replace(cmd_line_norm, /\d+/, "N"), input=parse_double(len(coalesce(cmd_line_norm, ""))) | adaptive_threshold algorithm="quantile" entity="process_name" window=60480000 | where label AND quantile>0.99 | first_time_event cache_partitions=1 input_columns="dest_device_id,cmd_line" | where first_time_dest_device_id_cmd_line | eval start_time = timestamp, end_time = timestamp, entities = mvappend(dest_device_id, dest_user_id), body = "TBD" | into write_ssa_detected_events();</td></tr><tr><td>known_false_positives</td><td>This detection may flag suspiciously long command lines when there is not sufficient evidence (samples) for a given process that this detection is tracking; or when there is high variability in the length of the command line for the tracked process. Also, some legitimate applications may use long command lines. Such is the case of Ansible, that encodes Powershell scripts using long base64. Attackers may use this technique to obfuscate their payloads.</td></tr><tr><td>tags</td><td>{'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'risk_severity': 'low', 'security_domain': 'endpoint'}</td></tr></table>
<h4>suspicious_changes_to_file_associations.yml</h4>

<table><tr><td>name</td><td>Suspicious Changes to File Associations</td></tr><tr><td>id</td><td>1b989a0e-0129-4446-a695-f193a5b746fc</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-22</td></tr><tr><td>description</td><td>This search looks for changes to registry values that control Windows file associations, executed by a process that is not typical for legitimate, routine changes to this area.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search you need to be ingesting information on registry changes that include the name of the process responsible for the changes from your endpoints into the `Endpoint` datamodel in the `Processes` and `Registry` nodes.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Processes.process_name) as process_name values(Processes.parent_process_name) as parent_process_name FROM datamodel=Endpoint.Processes where Processes.process_name!=Explorer.exe AND Processes.process_name!=OpenWith.exe by Processes.process_id Processes.dest | `drop_dm_object_name("Processes")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | join [| tstats `security_content_summariesonly` values(Registry.registry_path) as registry_path count  FROM datamodel=Endpoint.Registry where Registry.registry_path=*\\Explorer\\FileExts* by Registry.process_id Registry.dest | `drop_dm_object_name("Registry")` | table process_id dest registry_path]| `suspicious_changes_to_file_associations_filter` </td></tr><tr><td>known_false_positives</td><td>There may be other processes in your environment that users may legitimately use to modify file associations. If this is the case and you are finding false positives, you can modify the search to add those processes as exceptions.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious Windows Registry Activities', 'Windows File Extension and Association Abuse'], 'mitre_attack_id': ['T1546.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 8'], 'nist': ['DE.CM', 'PR.PT', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>wmi_temporary_event_subscription.yml</h4>

<table><tr><td>name</td><td>WMI Temporary Event Subscription</td></tr><tr><td>id</td><td>38cbd42c-1098-41bb-99cf-9d6d2b296d83</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-10-23</td></tr><tr><td>description</td><td>This search looks for the creation of WMI temporary event subscriptions.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must be ingesting the Windows WMI activity logs. This can be done by adding a stanza to inputs.conf on the system generating logs with a title of [WinEventLog://Microsoft-Windows-WMI-Activity/Operational].</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>`wmi` EventCode=5860 Temporary | rex field=Message "NotificationQuery =\s+(?<query>[^;|^$]+)" | search query!="SELECT * FROM Win32_ProcessStartTrace WHERE ProcessName = 'wsmprovhost.exe'" AND query!="SELECT * FROM __InstanceOperationEvent WHERE TargetInstance ISA 'AntiVirusProduct' OR TargetInstance ISA 'FirewallProduct' OR TargetInstance ISA 'AntiSpywareProduct'" | stats count min(_time) as firstTime max(_time) as lastTime by ComputerName, query  | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `wmi_temporary_event_subscription_filter`</td></tr><tr><td>known_false_positives</td><td>Some software may create WMI temporary event subscriptions for various purposes. The included search contains an exception for two of these that occur by default on Windows 10 systems. You may need to modify the search to create exceptions for other legitimate events.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious WMI Use'], 'mitre_attack_id': ['T1047'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 5'], 'nist': ['PR.PT', 'PR.AT', 'PR.AC', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>overwriting_accessibility_binaries.yml</h4>

<table><tr><td>name</td><td>Overwriting Accessibility Binaries</td></tr><tr><td>id</td><td>13c2f6c3-10c5-4deb-9ba1-7c4460ebe4ae</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>Microsoft Windows contains accessibility features that can be launched with a key combination before a user has logged in. An adversary can modify or replace these programs so they can get a command prompt or backdoor without logging in to the system. This search looks for modifications to these binaries.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records the filesystem activity from your hosts to populate the Endpoint file-system data model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem where (Filesystem.file_path=*\\Windows\\System32\\sethc.exe* OR Filesystem.file_path=*\\Windows\\System32\\utilman.exe* OR Filesystem.file_path=*\\Windows\\System32\\osk.exe* OR Filesystem.file_path=*\\Windows\\System32\\Magnify.exe* OR Filesystem.file_path=*\\Windows\\System32\\Narrator.exe* OR Filesystem.file_path=*\\Windows\\System32\\DisplaySwitch.exe* OR Filesystem.file_path=*\\Windows\\System32\\AtBroker.exe*) by Filesystem.file_name Filesystem.dest | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `overwriting_accessibility_binaries_filter`</td></tr><tr><td>known_false_positives</td><td>Microsoft may provide updates to these binaries. Verify that these changes do not correspond with your normal software update cycle.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Privilege Escalation'], 'mitre_attack_id': ['T1546.008'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>credential_dumping_via_copy_command_from_shadow_copy.yml</h4>

<table><tr><td>name</td><td>Credential Dumping via Copy Command from Shadow Copy</td></tr><tr><td>id</td><td>d8c406fe-23d2-45f3-a983-1abe7b83ff3b</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2019-12-10</td></tr><tr><td>description</td><td>This search detects credential dumping using copy command from a shadow copy.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://2017.zeronights.org/wp-content/uploads/materials/ZN17_Kheirkhabarov_Hunting_for_Credentials_Dumping_in_Windows_Environment.pdf']</td></tr><tr><td>author</td><td>Patrick Bareiss, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=cmd.exe (Processes.process=*\\system32\\config\\sam* OR Processes.process=*\\system32\\config\\security* OR Processes.process=*\\system32\\config\\system* OR Processes.process=*\\windows\\ntds\\ntds.dit*) by Processes.dest Processes.user Processes.process_name Processes.process  Processes.parent_process Processes.process_id Processes.parent_process_id | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `credential_dumping_via_copy_command_from_shadow_copy_filter` </td></tr><tr><td>known_false_positives</td><td>unknown</td></tr><tr><td>tags</td><td>{'analytics_story': ['Credential Dumping'], 'mitre_attack_id': ['T1003.003'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8', 'CIS 16'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>first_time_seen_cmd_line___ssa.yml</h4>

<table><tr><td>name</td><td>First time seen command line argument - SSA</td></tr><tr><td>id</td><td>fc0edc95-ff2b-48b0-9f6f-63da3789fd23</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-6-25</td></tr><tr><td>description</td><td>This search looks for command-line arguments that use a `/c` parameter to execute a command that has not previously been seen. This is an implementation on SPL2 of the rule `First time seen command line argument` by @bpatel.</td></tr><tr><td>how_to_implement</td><td>You must be populating the endpoint data model for SSA and specifically the process_name and the process fields</td></tr><tr><td>author</td><td>Ignacio Bermudez Corrales, Splunk</td></tr><tr><td>type</td><td>SSA</td></tr><tr><td>search</td><td>| from read_ssa_enriched_events() | eval timestamp=parse_long(ucast(map_get(input_event, "_time"), "string", null)) | eval dest_user_id=ucast(map_get(input_event, "dest_user_id"), "string", null), dest_device_id=ucast(map_get(input_event, "dest_device_id"), "string", null), process_name=ucast(map_get(input_event, "process_name"), "string", null), cmd_line=lower(ucast(map_get(input_event, "process"), "string", null)) | where process_name="cmd.exe" AND match_regex(ucast(cmd_line, "string", ""), /.* \/[cC] .*/)=true | first_time_event cache_partitions=5 input_columns="cmd_line" | where first_time_cmd_line | eval start_time = timestamp, end_time = timestamp, entities = mvappend(dest_device_id, dest_user_id), body = "TBD" | into write_ssa_detected_events();</td></tr><tr><td>eli5</td><td>The subsearch returns all events where `cmd.exe` was used with a `/c` parameter in the command-line arguments to execute other commands/programs. It appends the historical data to those results in the lookup file. Next, it recalculates the `firstTime` and `lastTime` field for command-line execution and outputs this data to the lookup file to update the local cache. It returns only those events that have first been seen in the past one hour. This is combined with the main search to return the time, user, destination, process, parent process, and value of the command-line argument.</td></tr><tr><td>known_false_positives</td><td>Legitimate programs can also use command-line arguments to execute. Please verify the command-line arguments to check what command/program is being executed. We recommend customizing the `first_time_seen_cmd_line_filter` macro to exclude legitimate parent_process_name</td></tr><tr><td>tags</td><td>{'cis20': ['CIS 3', 'CIS 8'], 'kill_chain_phases': ['Command and Control', 'Actions on Objectives'], 'mitre_attack': ['Execution', 'Scripting', 'Persistence', 'Command-Line Interface'], 'mitre_technique_id': ['T1059', 'T1117', 'T1202'], 'nist': ['PR.PT', 'DE.CM', 'PR.IP'], 'risk_severity': 'low', 'security_domain': 'endpoint'}</td></tr></table>
<h4>single_letter_process_on_endpoint.yml</h4>

<table><tr><td>name</td><td>Single Letter Process On Endpoint</td></tr><tr><td>id</td><td>a4214f0b-e01c-41bc-8cc4-d2b71e3056b4</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2019-04-01</td></tr><tr><td>description</td><td>This search looks for process names that consist only of a single letter.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest, Processes.user, Processes.process, Processes.process_name | `drop_dm_object_name(Processes)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | eval process_name_length = len(process_name), endExe = if(substr(process_name, -4) == ".exe", 1, 0) | search process_name_length=5 AND endExe=1 | table count, firstTime, lastTime, dest, user, process, process_name | `single_letter_process_on_endpoint_filter`</td></tr><tr><td>known_false_positives</td><td>Single-letter executables are not always malicious. Investigate this activity with your normal incident-response process.</td></tr><tr><td>tags</td><td>{'analytics_story': ['DHS Report TA18-074A'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 2'], 'nist': ['ID.AM', 'PR.DS'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>suspicious_wevtutil_usage.yml</h4>

<table><tr><td>name</td><td>Suspicious wevtutil Usage</td></tr><tr><td>id</td><td>2827c0fd-e1be-4868-ae25-59d28e0f9d4f</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-22</td></tr><tr><td>description</td><td>The wevtutil.exe application is the windows event log utility. This searches for wevtutil.exe with parameters for clearing the application, security, setup, or system event logs.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = wevtutil.exe Processes.process="*cl*" (Processes.process="*System*" OR Processes.process="*Security*" OR Processes.process="*Setup*" OR Processes.process="*Application*") by Processes.process_name Processes.parent_process_name Processes.dest Processes.user| `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` | `suspicious_wevtutil_usage_filter`</td></tr><tr><td>known_false_positives</td><td>The wevtutil.exe application is a legitimate Windows event log utility. Administrators may use it to manage Windows event logs.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Log Manipulation', 'Ransomware'], 'mitre_attack_id': ['T1070.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 5', 'CIS 6'], 'nist': ['DE.DP', 'PR.IP', 'PR.PT', 'PR.AC', 'PR.AT', 'DE.AE'], 'security_domain': 'endpoint', 'asset_type': ''}</td></tr></table>
<h4>unusually_long_content_type_length.yml</h4>

<table><tr><td>name</td><td>Unusually Long Content-Type Length</td></tr><tr><td>id</td><td>57a0a2bf-353f-40c1-84dc-29293f3c35b7</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-10-13</td></tr><tr><td>description</td><td>This search looks for unusually long strings in the Content-Type http header that the client sends the server.</td></tr><tr><td>how_to_implement</td><td>This particular search leverages data extracted from Stream:HTTP. You must configure the http stream using the Splunk Stream App on your Splunk Stream deployment server to extract the cs_content_type field.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`stream_http` | eval cs_content_type_length = len(cs_content_type) | where cs_content_type_length > 100 | table endtime src_ip dest_ip cs_content_type_length cs_content_type url | `unusually_long_content_type_length_filter`</td></tr><tr><td>known_false_positives</td><td>Very few legitimate Content-Type fields will have a length greater than 100 characters.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Apache Struts Vulnerability'], 'kill_chain_phases': ['Delivery'], 'cis20': ['CIS 3', 'CIS 4', 'CIS 18', 'CIS 12'], 'nist': ['ID.RA', 'RS.MI', 'PR.PT', 'PR.IP', 'DE.AE', 'PR.MA', 'DE.CM'], 'security_domain': 'network', 'asset_type': 'Web Server'}</td></tr></table>
<h4>reg_exe_used_to_hide_files_directories_via_registry_keys.yml</h4>

<table><tr><td>name</td><td>Reg exe used to hide files directories via registry keys</td></tr><tr><td>id</td><td>c77162d3-f93c-45cc-80c8-22f6b5264x9f</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2019-02-27</td></tr><tr><td>description</td><td>The search looks for command-line arguments used to hide a file or directory using the reg add command.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = reg.exe Processes.process="*add*" Processes.process="*Hidden*" Processes.process="*REG_DWORD*" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user| `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` |`security_content_ctime(lastTime)`| regex process = "(/d\s+2)" | `reg_exe_used_to_hide_files_directories_via_registry_keys_filter`</td></tr><tr><td>known_false_positives</td><td>None at the moment</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Defense Evasion Tactics', 'Suspicious Windows Registry Activities', 'Windows Persistence Techniques'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': ''}</td></tr></table>
<h4>creation_of_shadow_copy_with_wmic_and_powershell.yml</h4>

<table><tr><td>name</td><td>Creation of Shadow Copy with wmic and powershell</td></tr><tr><td>id</td><td>2ed8b538-d284-449a-be1d-82ad1dbd186b</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2019-12-10</td></tr><tr><td>description</td><td>This search detects the use of wmic and Powershell to create a shadow copy.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://2017.zeronights.org/wp-content/uploads/materials/ZN17_Kheirkhabarov_Hunting_for_Credentials_Dumping_in_Windows_Environment.pdf']</td></tr><tr><td>author</td><td>Patrick Bareiss, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=wmic* OR Processes.process_name=powershell* Processes.process=*shadowcopy* Processes.process=*create* by Processes.user Processes.process_name Processes.process Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `creation_of_shadow_copy_with_wmic_and_powershell_filter`</td></tr><tr><td>known_false_positives</td><td>Legtimate administrator usage of wmic to create a shadow copy.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Credential Dumping'], 'mitre_attack_id': ['T1003.003'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8', 'CIS 16'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>scheduled_task_name_used_by_dragonfly_threat_actors.yml</h4>

<table><tr><td>name</td><td>Scheduled Task Name Used by Dragonfly Threat Actors</td></tr><tr><td>id</td><td>d5af132c-7c17-439c-9d31-13d55340f36c</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for flags passed to schtasks.exe on the command-line that indicate a task name associated with the Dragonfly threat actor was created or deleted.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=schtasks.exe  by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | search (process=*delete* OR process=*create*) process=*reset* | `scheduled_task_name_used_by_dragonfly_threat_actors_filter` </td></tr><tr><td>known_false_positives</td><td>No known false positives</td></tr><tr><td>tags</td><td>{'analytics_story': ['DHS Report TA18-074A'], 'mitre_attack_id': ['T1053.005'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3'], 'nist': ['PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_oulook_exe_writing_a__zip_file.yml</h4>

<table><tr><td>name</td><td>Detect Oulook exe writing a  zip file</td></tr><tr><td>id</td><td>a51bfe1a-94f0-4822-b1e4-16ae10145893</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for execution of process `outlook.exe` where the process is writing a `.zip` file to the disk.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records filesystem and process activity from your hosts to populate the Endpoint data model. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly`  min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.process_name=outlook.exe OR Processes.process_name=explorer.exe by _time span=5m Processes.parent_process_id Processes.process_id Processes.dest Processes.process_name Processes.parent_process_name Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename process_id as malicious_id| rename parent_process_id as outlook_id| join malicious_id type=inner[| tstats `security_content_summariesonly` count values(Filesystem.file_path) as file_path values(Filesystem.file_name) as file_name  FROM datamodel=Endpoint.Filesystem where (Filesystem.file_path=*zip*   OR Filesystem.file_name=*.lnk ) AND (Filesystem.file_path=C:\\Users* OR Filesystem.file_path=*Local\\Temp*) by  _time span=5m Filesystem.process_id Filesystem.file_hash Filesystem.dest  | `drop_dm_object_name(Filesystem)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename process_id as malicious_id| fields malicious_id outlook_id dest file_path file_name file_hash count file_id] | table firstTime lastTime user malicious_id outlook_id process_name parent_process_name file_name  file_path | where file_name != "" | `detect_oulook_exe_writing_a__zip_file_filter` </td></tr><tr><td>known_false_positives</td><td>It is not uncommon for outlook to write legitimate zip files to the disk.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Phishing Payloads'], 'mitre_attack_id': ['T1566.001'], 'kill_chain_phases': ['Installation', 'Actions on Objectives'], 'cis20': ['CIS 7', 'CIS 8'], 'nist': ['ID.AM', 'PR.DS'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_windows_dns_sigred_via_zeek.yml</h4>

<table><tr><td>name</td><td>Detect Windows DNS SIGRed via Zeek</td></tr><tr><td>id</td><td>c5c622e4-d073-11ea-87d0-0242ac130003</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-07-28</td></tr><tr><td>description</td><td>This search detects SIGRed via Zeek DNS and Zeek Conn data.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting Zeek DNS and Zeek Conn data into Splunk. Zeek data should also be getting ingested in JSON format.  We are detecting SIG and KEY records via bro:dns:json and TCP payload over 65KB in size via bro:conn:json.  The Network Resolution and Network Traffic datamodels are in use for this search.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://research.checkpoint.com/2020/resolving-your-way-into-domain-admin-exploiting-a-17-year-old-bug-in-windows-dns-servers/']</td></tr><tr><td>author</td><td>Shannon Davis, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count from datamodel=Network_Resolution where DNS.query_type IN (SIG,KEY) by DNS.flow_id | rename DNS.flow_id as flow_id | append [| tstats  `security_content_summariesonly` count from datamodel=Network_Traffic where All_Traffic.bytes_in>65000 by All_Traffic.flow_id | rename All_Traffic.flow_id as flow_id] | `detect_windows_dns_sigred_via_zeek_filter` | stats count by flow_id | where count>1 | fields - count </td></tr><tr><td>known_false_positives</td><td>unknown</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows DNS SIGRed CVE-2020-1350'], 'mitre_attack_id': ['T1203'], 'kill_chain_phases': ['Exploitation'], 'cis20': ['CIS 8', 'CIS 16'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>schtasks_used_for_forcing_a_reboot.yml</h4>

<table><tr><td>name</td><td>Schtasks used for forcing a reboot</td></tr><tr><td>id</td><td>1297fb80-f42a-4b4a-9c8a-88c066437cf6</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for flags passed to schtasks.exe on the command-line that indicate that a forced reboot of system is scheduled.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search you need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = schtasks.exe Processes.process="*shutdown*" Processes.process="*/r*" Processes.process="*/f*" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `schtasks_used_for_forcing_a_reboot_filter`</td></tr><tr><td>known_false_positives</td><td>Administrators may create jobs on systems forcing reboots to perform updates, maintenance, etc.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Persistence Techniques', 'Ransomware'], 'mitre_attack_id': ['T1053.005'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3'], 'nist': ['PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>unusual_lolbas_in_short_period_of_time___ssa.yml</h4>

<table><tr><td>name</td><td>More than usual number of LOLBAS applications in short time period - SSA</td></tr><tr><td>id</td><td>59c0dd70-169c-4900-9a1f-bfcf13302f93</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-08-25</td></tr><tr><td>description</td><td>Attacker activity may compromise executing several LOLBAS applications in conjunction to accomplish their objectives. We are looking for more than usual LOLBAS applications over a window of time, by building profiles per machine.</td></tr><tr><td>how_to_implement</td><td>Collect endpoint data such as sysmon or 4688 events.</td></tr><tr><td>references</td><td>['https://github.com/LOLBAS-Project/LOLBAS/tree/master/yml/OSBinaries']</td></tr><tr><td>type</td><td>SSA</td></tr><tr><td>author</td><td>Ignacio Bermudez Corrales, Splunk</td></tr><tr><td>search</td><td> | from read_ssa_enriched_events() | eval device=ucast(map_get(input_event, "dest_device_id"), "string", null), process_name=lower(ucast(map_get(input_event, "process_name"), "string", null)), timestamp=parse_long(ucast(map_get(input_event, "_time"), "string", null)) | where process_name=="regsvcs.exe" OR process_name=="ftp.exe" OR process_name=="dfsvc.exe" OR process_name=="rasautou.exe" OR process_name=="schtasks.exe" OR process_name=="xwizard.exe" OR process_name=="findstr.exe" OR process_name=="esentutl.exe" OR process_name=="cscript.exe" OR process_name=="reg.exe" OR process_name=="csc.exe" OR process_name=="atbroker.exe" OR process_name=="print.exe" OR process_name=="pcwrun.exe" OR process_name=="vbc.exe" OR process_name=="rpcping.exe" OR process_name=="wsreset.exe" OR process_name=="ilasm.exe" OR process_name=="certutil.exe" OR process_name=="replace.exe" OR process_name=="mshta.exe" OR process_name=="bitsadmin.exe" OR process_name=="wscript.exe" OR process_name=="ieexec.exe" OR process_name=="cmd.exe" OR process_name=="microsoft.workflow.compiler.exe" OR process_name=="runscripthelper.exe" OR process_name=="makecab.exe" OR process_name=="forfiles.exe" OR process_name=="desktopimgdownldr.exe" OR process_name=="control.exe" OR process_name=="msbuild.exe" OR process_name=="register-cimprovider.exe" OR process_name=="tttracer.exe" OR process_name=="ie4uinit.exe" OR process_name=="sc.exe" OR process_name=="bash.exe" OR process_name=="hh.exe" OR process_name=="cmstp.exe" OR process_name=="mmc.exe" OR process_name=="jsc.exe" OR process_name=="scriptrunner.exe" OR process_name=="odbcconf.exe" OR process_name=="extexport.exe" OR process_name=="msdt.exe" OR process_name=="diskshadow.exe" OR process_name=="extrac32.exe" OR process_name=="eventvwr.exe" OR process_name=="mavinject.exe" OR process_name=="regasm.exe" OR process_name=="gpscript.exe" OR process_name=="rundll32.exe" OR process_name=="regsvr32.exe" OR process_name=="regedit.exe" OR process_name=="msiexec.exe" OR process_name=="gfxdownloadwrapper.exe" OR process_name=="presentationhost.exe" OR process_name=="regini.exe" OR process_name=="wmic.exe" OR process_name=="runonce.exe" OR process_name=="syncappvpublishingserver.exe" OR process_name=="verclsid.exe" OR process_name=="psr.exe" OR process_name=="infdefaultinstall.exe" OR process_name=="explorer.exe" OR process_name=="expand.exe" OR process_name=="installutil.exe" OR process_name=="netsh.exe" OR process_name=="wab.exe" OR process_name=="dnscmd.exe" OR process_name=="at.exe" OR process_name=="pcalua.exe" OR process_name=="cmdkey.exe" OR process_name=="msconfig.exe" | stats count(process_name) as lolbas_counter by device,span(timestamp, 300s) | eval lolbas_counter=lolbas_counter*1.0 | rename window_end as timestamp | adaptive_threshold algorithm="quantile" value="lolbas_counter" entity="device" window=2419200000L | where label AND quantile>0.99 | eval start_time = timestamp, end_time = timestamp, entities = mvappend(device), body = "TBD" | into write_ssa_detected_events();</td></tr><tr><td>known_false_positives</td><td>Some administrative tasks may involve multiple use of LOLBAS applications in a short period of time. This might trigger false positives at the beginning when it hasn't collected yet enough data to construct the baseline.
</td></tr><tr><td>tags</td><td>{'mitre_technique_id': ['T1059', 'T1053'], 'kill_chain_phases': ['Exploitation'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'risk_severity': 'low', 'security_domain': 'endpoint'}</td></tr></table>
<h4>detection_of_tools_built_by_nirsoft.yml</h4>

<table><tr><td>name</td><td>Detection of tools built by NirSoft</td></tr><tr><td>id</td><td>1297fb80-f42a-4q4a-9c8b-78c061417cf6</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for specific command-line arguments that may indicate the execution of tools made by Nirsoft, which are legitimate, but may be abused by attackers.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) values(Processes.process) as process max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process="* /stext *" OR Processes.process="* /scomma *" ) by Processes.parent_process Processes.process_name Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` | `detection_of_tools_built_by_nirsoft_filter`</td></tr><tr><td>known_false_positives</td><td>While legitimate, these NirSoft tools are prone to abuse. You should verfiy that the tool was used for a legitimate purpose.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Emotet Malware  DHS Report TA18-201A '], 'mitre_attack_id': ['T1072'], 'kill_chain_phases': ['Installation', 'Actions on Objectives'], 'cis20': ['CIS 3'], 'nist': ['PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_windows_dns_sigred_via_splunk_stream.yml</h4>

<table><tr><td>name</td><td>Detect Windows DNS SIGRed via Splunk Stream</td></tr><tr><td>id</td><td>babd8d10-d073-11ea-87d0-0242ac130003</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-07-28</td></tr><tr><td>description</td><td>This search detects SIGRed via Splunk Stream.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting Splunk Stream DNS and Splunk Stream TCP. We are detecting SIG and KEY records via stream:dns and TCP payload over 65KB in size via stream:tcp.  Replace the macro definitions ('stream:dns' and 'stream:tcp') with configurations for your Splunk environment.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://research.checkpoint.com/2020/resolving-your-way-into-domain-admin-exploiting-a-17-year-old-bug-in-windows-dns-servers/']</td></tr><tr><td>author</td><td>Shannon Davis, Splunk</td></tr><tr><td>search</td><td>`stream_dns` | spath "query_type{}" | search "query_type{}" IN (SIG,KEY) | spath protocol_stack | search protocol_stack="ip:tcp:dns" | append [search `stream_tcp` bytes_out>65000] | `detect_windows_dns_sigred_via_splunk_stream_filter` | stats count by flow_id | where count>1 | fields - count</td></tr><tr><td>known_false_positives</td><td>unknown</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows DNS SIGRed CVE-2020-1350'], 'mitre_attack_id': ['T1203'], 'kill_chain_phases': ['Exploitation'], 'cis20': ['CIS 8', 'CIS 12'], 'nist': ['DE.CM'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>suspicious_writes_to_system_volume_information.yml</h4>

<table><tr><td>name</td><td>Suspicious writes to System Volume Information</td></tr><tr><td>id</td><td>cd6297cd-2bdd-4aa1-84aa-5d2f84228fac</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-22</td></tr><tr><td>description</td><td>This search detects writes to the 'System Volume Information' folder by something other than the System process.</td></tr><tr><td>how_to_implement</td><td>You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>(`sysmon` OR tag=process) EventCode=11 process_id!=4 file_path=*System\ Volume\ Information* | stats count min(_time) as firstTime max(_time) as lastTime by dest, Image, file_path | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `suspicious_writes_to_system_volume_information_filter`</td></tr><tr><td>known_false_positives</td><td>It is possible that other utilities or system processes may legitimately write to this folder. Investigate and modify the search to include exceptions as appropriate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Collection and Staging'], 'mitre_attack_id': ['T1036'], 'cis20': ['CIS 8'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Windows'}</td></tr></table>
<h4>malicious_powershell_process___execution_policy_bypass.yml</h4>

<table><tr><td>name</td><td>Malicious PowerShell Process - Execution Policy Bypass</td></tr><tr><td>id</td><td>9be56c82-b1cc-4318-87eb-d138afaaca39</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for PowerShell processes started with parameters used to bypass the local execution policy for scripts. These parameters are often observed in attacks leveraging PowerShell scripts as they override the default PowerShell execution policy.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` values(Processes.process_id) as process_id, values(Processes.parent_process_id) as parent_process_id values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe AND (Processes.process="* -ex*" OR Processes.process="* bypass *") by Processes.process_id, Processes.user, Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `malicious_powershell_process___execution_policy_bypass_filter`</td></tr><tr><td>known_false_positives</td><td>There may be legitimate reasons to bypass the PowerShell execution policy. The PowerShell script being run with this parameter should be validated to ensure that it is legitimate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['DHS Report TA18-074A'], 'mitre_attack_id': ['T1059.001'], 'kill_chain_phases': ['Command and Control', 'Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 7', 'CIS 8'], 'nist': ['PR.PT', 'DE.CM', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>dump_lsass_via_comsvcs_dll.yml</h4>

<table><tr><td>name</td><td>Dump LSASS via comsvcs DLL</td></tr><tr><td>id</td><td>8943b567-f14d-4ee8-a0bb-2121d4ce3184</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-02-21</td></tr><tr><td>description</td><td>Detect the usage of comsvcs.dll for dumping the lsass process.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints, to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://modexp.wordpress.com/2019/08/30/minidumpwritedump-via-com-services-dll/', 'https://twitter.com/SBousseaden/status/1167417096374050817']</td></tr><tr><td>author</td><td>Patrick Bareiss, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=rundll32.exe Processes.process=*comsvcs.dll* Processes.process=*MiniDump* by Processes.user Processes.process_name Processes.process Processes.dest | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `dump_lsass_via_comsvcs_dll_filter`</td></tr><tr><td>known_false_positives</td><td>None identified.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Credential Dumping'], 'mitre_attack_id': ['T1003.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 5', 'CIS 16'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_mshta_exe_running_scripts_in_command_line_arguments.yml</h4>

<table><tr><td>name</td><td>Detect mshta exe running scripts in command-line arguments</td></tr><tr><td>id</td><td>b89919ed-fe5f-492c-b139-95dqb161039e</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for the execution of "mshta.exe" with command-line arguments that launch a script. The search will return the first time and last time these command-line arguments were used for these executions, as well as the target system, the user, process "mshta.exe" and its parent process.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you need to be ingesting logs with the process name, parent process, and command-line executions from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=mshta.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| search (process=*vbscript* OR process=*javascript*) | `detect_mshta_exe_running_scripts_in_command_line_arguments_filter`</td></tr><tr><td>known_false_positives</td><td>Although unlikely, some legitimate applications may exhibit this behavior, triggering a false positive.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious MSHTA Activity'], 'mitre_attack_id': ['T1059.003'], 'kill_chain_phases': ['Exploitation'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_path_interception_by_creation_of_program_exe.yml</h4>

<table><tr><td>name</td><td>Detect Path Interception By Creation Of program exe</td></tr><tr><td>id</td><td>c77162d3-f93c-45cc-80c8-22f6v5264g9f</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-03</td></tr><tr><td>description</td><td>The detection Detect Path Interception By Creation Of program exe is detecting the abuse of unquoted service paths, which is a popular technique for privilege escalation. </td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>['https://medium.com/@SumitVerma101/windows-privilege-escalation-part-1-unquoted-service-path-c7a011a8d8ae']</td></tr><tr><td>author</td><td>Patrick Bareiss, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.parent_process_name=services.exe by Processes.user Processes.process_name Processes.process Processes.dest | `drop_dm_object_name(Processes)` | rex field=process "^.*\\\\(?<service_process>.*\.(?:exe|bat|com|ps1))" | eval process_name = lower(process_name) | eval service_process = lower(service_process)| where process_name != service_process | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_path_interception_by_creation_of_program_exe_filter`</td></tr><tr><td>known_false_positives</td><td>unknown</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Persistence Techniques'], 'mitre_attack_id': ['T1574.009'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>unusually_long_command_line___mltk.yml</h4>

<table><tr><td>name</td><td>Unusually Long Command Line - MLTK</td></tr><tr><td>id</td><td>57edaefa-a73b-45e5-bbae-f39c1473f941</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2019-05-08</td></tr><tr><td>description</td><td>Command lines that are extremely long may be indicative of malicious activity on your hosts. This search leverages the Machine Learning Toolkit (MLTK) to help identify command lines with lengths that are unusual for a given user.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting endpoint data that monitors command lines and populates the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model. In addition, MLTK version >= 4.2 must be installed on your search heads, along with any required dependencies. Finally, the support search "Baseline of Command Line Length - MLTK" must be executed before this detection search, as it builds an ML model over the historical data used by this search. It is important that this search is run in the same app context as the associated support search, so that the model created by the support search is available for use. You should periodically re-run the support search to rebuild the model with the latest data available in your environment.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes by Processes.user Processes.dest Processes.process_name Processes.process | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| eval processlen=len(process) | search user!=unknown | apply cmdline_pdfmodel threshold=0.01 | rename "IsOutlier(processlen)" as isOutlier | search isOutlier > 0 | table firstTime lastTime user dest process_name process processlen count | `unusually_long_command_line___mltk_filter`</td></tr><tr><td>known_false_positives</td><td>Some legitimate applications use long command lines for installs or updates. You should review identified command lines for legitimacy. You may modify the first part of the search to omit legitimate command lines from consideration. If you are seeing more results than desired, you may consider changing the value of threshold in the search to a smaller value. You should also periodically re-run the support search to re-build the ML model on the latest data. You may get unexpected results if the user identified in the results is not present in the data used to build the associated model.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious Command-Line Executions', 'Unusual Processes', 'Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns', 'Ransomware'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': ''}</td></tr></table>
<h4>shim_database_file_creation.yml</h4>

<table><tr><td>name</td><td>Shim Database File Creation</td></tr><tr><td>id</td><td>6e4c4588-ba2f-42fa-97e6-9f6f548eaa33</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-22</td></tr><tr><td>description</td><td>This search looks for shim database files being written to default directories. The sdbinst.exe application is used to install shim database files (.sdb). According to Microsoft, a shim is a small library that transparently intercepts an API, changes the parameters passed, handles the operation itself, or redirects the operation elsewhere.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records the filesystem activity from your hosts to populate the Endpoint file-system data model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Filesystem.action) values(Filesystem.file_hash) as file_hash values(Filesystem.file_path) as file_path  min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Filesystem where Filesystem.file_path=*Windows\AppPatch\Custom* by Filesystem.file_name Filesystem.dest | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` |`drop_dm_object_name(Filesystem)` | `shim_database_file_creation_filter`</td></tr><tr><td>known_false_positives</td><td>Because legitimate shim files are created and used all the time, this event, in itself, is not suspicious. However, if there are other correlating events, it may warrant further investigation.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Persistence Techniques'], 'mitre_attack_id': ['T1546.011'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>attempt_to_set_default_powershell_execution_policy_to_unrestricted_or_bypass.yml</h4>

<table><tr><td>name</td><td>Attempt To Set Default PowerShell Execution Policy To Unrestricted or Bypass</td></tr><tr><td>id</td><td>c2590137-0b08-4985-9ec5-6ae23d92f63d</td></tr><tr><td>version</td><td>5</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>Monitor for changes of the ExecutionPolicy in the registry to the values "unrestricted" or "bypass," which allows the execution of malicious scripts.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Registry node. You must also be ingesting logs with the fields registry_path, registry_key_name, and registry_value_name from your endpoints.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Patrick Bareiss, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Registry where Registry.registry_path=*Software\\Microsoft\\Powershell\\1\\ShellIds\\Microsoft.PowerShell* Registry.registry_key_name=ExecutionPolicy (Registry.registry_value_name=Unrestricted OR Registry.registry_value_name=Bypass) by Registry.registry_path Registry.registry_key_name Registry.registry_value_name Registry.dest | `drop_dm_object_name(Registry)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `attempt_to_set_default_powershell_execution_policy_to_unrestricted_or_bypass_filter` </td></tr><tr><td>known_false_positives</td><td>Administrators may attempt to change the default execution policy on a system for a variety of reasons. However, setting the policy to "unrestricted" or "bypass" as this search is designed to identify, would be unusual. Hits should be reviewed and investigated as appropriate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Malicious PowerShell', 'Credential Dumping'], 'mitre_attack_id': ['T1059.001'], 'kill_chain_phases': ['Installation', 'Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 8'], 'nist': ['DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_psexec_with_accepteula_flag.yml</h4>

<table><tr><td>name</td><td>Detect PsExec With accepteula Flag</td></tr><tr><td>id</td><td>b89919ed-fe5f-492c-b139-151xb162040e</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2019-02-26</td></tr><tr><td>description</td><td>This search looks for events where `PsExec.exe` is run with the `accepteula` flag in the command line. PsExec is a built-in Windows utility that enables you to execute processes on other systems. It is fully interactive for console applications. This tool is widely used for launching interactive command prompts on remote systems. Threat actors leverage this extensively for executing code on compromised systems. If an attacker is running PsExec for the first time, they will be prompted to accept the end-user license agreement (EULA), which can be passed as the argument `accepteula` within the command line.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = PsExec.exe Processes.process = "*accepteula*" by Processes.process_name Processes.dest  Processes.parent_process_name | `drop_dm_object_name(Processes)`| `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_psexec_with_accepteula_flag_filter`</td></tr><tr><td>known_false_positives</td><td>Administrators can leverage PsExec for accessing remote systems and might pass `accepteula` as an argument if they are running this tool for the first time. However, it is not likely that you'd see multiple occurrences of this event on a machine</td></tr><tr><td>tags</td><td>{'analytics_story': ['SamSam Ransomware', 'DHS Report TA18-074A'], 'mitre_attack_id': ['T1059.003', 'T1059.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>remote_desktop_process_running_on_system.yml</h4>

<table><tr><td>name</td><td>Remote Desktop Process Running On System</td></tr><tr><td>id</td><td>f5939373-8054-40ad-8c64-cec478a22a4a</td></tr><tr><td>version</td><td>5</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for the remote desktop process mstsc.exe running on systems upon which it doesn't typically run. This is accomplished by filtering out all systems that are noted in the `common_rdp_source category` in the Assets and Identity framework.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node. The search requires you to identify systems that do not commonly use remote desktop. You can use the included support search "Identify Systems Using Remote Desktop" to identify these systems. After identifying them, you will need to add the "common_rdp_source" category to that system using the Enterprise Security Assets and Identities framework. This can be done by adding an entry in the assets.csv file located in `SA-IdentityManagement/lookups`.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process=*mstsc.exe AND Processes.dest_category!=common_rdp_source by Processes.dest Processes.user Processes.process | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `drop_dm_object_name(Processes)` | `remote_desktop_process_running_on_system_filter` </td></tr><tr><td>known_false_positives</td><td>Remote Desktop may be used legitimately by users on the network.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Hidden Cobra Malware', 'Lateral Movement'], 'mitre_attack_id': ['T1021.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 9', 'CIS 16'], 'nist': ['DE.AE', 'PR.AC', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>attempt_to_stop_security_service.yml</h4>

<table><tr><td>name</td><td>Attempt To Stop Security Service</td></tr><tr><td>id</td><td>c8e349c6-b97c-486e-8949-bd7bcd1f3910</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for attempts to stop security-related services on the endpoint.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records the file-system activity from your hosts to populate the Endpoint file-system data-model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data. The search is shipped with a lookup file, `security_services.csv`, that can be edited to update the list of services to monitor. This lookup file can be edited directly where it lives in `$SPLUNK_HOME/etc/apps/DA-ESS-ContentUpdate/lookups`, or via the Splunk console. You should add the names of services an attacker might use on the command line and surround with asterisks (*****), so that they work properly when searching the command line. The file should be updated with the names of any services you would like to monitor for attempts to stop the service.,</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process_name = net.exe OR  Processes.process_name = sc.exe) Processes.process="* stop *" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` |lookup security_services_lookup service as process OUTPUTNEW category, description | search category=security | `attempt_to_stop_security_service_filter`</td></tr><tr><td>known_false_positives</td><td>None identified. Attempts to disable security-related services should be identified and understood.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Disabling Security Tools'], 'mitre_attack_id': ['T1562.001'], 'kill_chain_phases': ['Installation', 'Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 5', 'CIS 8'], 'nist': ['PR.PT', 'DE.CM', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>schtasks_scheduling_job_on_remote_system.yml</h4>

<table><tr><td>name</td><td>Schtasks scheduling job on remote system</td></tr><tr><td>id</td><td>1297fb80-f42a-4b4a-9c8a-88c066237cf6</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for flags passed to schtasks.exe on the command-line that indicate a job is being scheduled on a remote system.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = schtasks.exe Processes.process="*/create*" Processes.process="* /s *" by Processes.process_name Processes.process Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `schtasks_scheduling_job_on_remote_system_filter`</td></tr><tr><td>known_false_positives</td><td>Administrators may create jobs on remote systems, but this activity is usually limited to a small set of hosts or users. It is important to validate and investigate as appropriate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Lateral Movement'], 'mitre_attack_id': ['T1053.005'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3'], 'nist': ['PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_excessive_user_account_lockouts.yml</h4>

<table><tr><td>name</td><td>Detect Excessive User Account Lockouts</td></tr><tr><td>id</td><td>95a7f9a5-6096-437e-a19e-86f42ac609bd</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search detects user accounts that have been locked out a relatively high number of times in a short period.</td></tr><tr><td>how_to_implement</td><td>ou must ingest your Windows security event logs in the `Change` datamodel under the nodename is `Account_Management`, for this search to execute successfully. Please consider updating the cron schedule and the count of lockouts you want to monitor, according to your environment.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Change.All_Changes where nodename=All_Changes.Account_Management All_Changes.result="lockout" by All_Changes.user All_Changes.result |`drop_dm_object_name("All_Changes")` |`drop_dm_object_name("Account_Management")`| `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | search count > 5 | `detect_excessive_user_account_lockouts_filter`</td></tr><tr><td>known_false_positives</td><td>It is possible that a legitimate user is experiencing an issue causing multiple account login failures leading to lockouts.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Account Monitoring and Controls'], 'mitre_attack_id': ['T1078.003'], 'cis20': ['CIS 16'], 'nist': ['PR.IP'], 'security_domain': 'access', 'asset_type': 'Windows'}</td></tr></table>
<h4>detect_dump_lsass_memory_using_comsvcs___ssa.yml</h4>

<table><tr><td>name</td><td>Detect Dump LSASS Memory using comsvcs - SSA</td></tr><tr><td>id</td><td>76bb9e35-f314-4c3d-a385-83c72a13ce4e</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-09-15</td></tr><tr><td>description</td><td>This search detects the memory of lsass.exe being dumped for offline credential theft attack.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting endpoint data that tracks process activity, including Windows command line logging. You can see how we test this with [Event Code 4688](https://www.ultimatewindowssecurity.com/securitylog/encyclopedia/event.aspx?eventID=4688a) on the [attack_range](https://github.com/splunk/attack_range/blob/develop/ansible/roles/windows_common/tasks/windows-enable-4688-cmd-line-audit.yml).</td></tr><tr><td>type</td><td>SSA</td></tr><tr><td>references</td><td>['https://2017.zeronights.org/wp-content/uploads/materials/ZN17_Kheirkhabarov_Hunting_for_Credentials_Dumping_in_Windows_Environment.pdf']</td></tr><tr><td>author</td><td>Jose Hernandez, Splunk</td></tr><tr><td>search</td><td>| from read_ssa_enriched_events() | select from_json_object(value) as input_event | eval tenant=ucast(map_get(input_event, "_tenant"), "string", null), machine=ucast(map_get(input_event, "dest_device_id"), "string", null), process_name=lower(ucast(map_get(input_event, "process_name"), "string", null)), timestamp=parse_long(ucast(map_get(input_event, "_time"), "string", null)), process=lower(ucast(map_get(input_event, "process"), "string", null)) | where process_name LIKE "%rundll32.exe%" AND match_regex(process, /(?i)comsvcs.dll[,\s]+MiniDump/)=true | eval start_time = timestamp, end_time = timestamp, entities = mvappend(machine), body = "TBD" | into write_ssa_detected_events();</td></tr><tr><td>known_false_positives</td><td>None identified.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Credential Dumping'], 'mitre_attack_id': ['T1003.003'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8', 'CIS 16'], 'nist': ['DE.CM'], 'risk_severity': 'low', 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>registry_keys_used_for_persistence.yml</h4>

<table><tr><td>name</td><td>Registry Keys Used For Persistence</td></tr><tr><td>id</td><td>f5f6af30-7aa7-4295-bfe9-07fe87c01a4b</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>The search looks for modifications to registry keys that can be used to launch an application or service at system startup.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must be ingesting data that records registry activity from your hosts to populate the endpoint data model in the registry node. This is typically populated via endpoint detection-and-response products, such as Carbon Black or endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Registry.registry_key_name) as registry_key_name values(Registry.registry_path) as registry_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where (Registry.registry_path=*currentversion\\run* OR Registry.registry_path=*currentVersion\\Windows\\Appinit_Dlls* OR Registry.registry_path=CurrentVersion\\Winlogon\\Shell* OR Registry.registry_path=*CurrentVersion\\Winlogon\\Userinit* OR Registry.registry_path=*CurrentVersion\\Winlogon\\VmApplet* OR Registry.registry_path=*currentversion\\policies\\explorer\\run* OR Registry.registry_path=*currentversion\\runservices* OR Registry.registry_path=*\\CurrentControlSet\\Control\\Lsa\\* OR Registry.registry_path="*Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options*" OR Registry.registry_path=HKLM\\SOFTWARE\\Microsoft\\Netsh\\*) by Registry.dest , Registry.status, Registry.user | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name(Registry)` | `registry_keys_used_for_persistence_filter`</td></tr><tr><td>known_false_positives</td><td>There are many legitimate applications that must execute on system startup and will use these registry keys to accomplish that task.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious Windows Registry Activities', 'Suspicious MSHTA Activity', 'DHS Report TA18-074A', 'Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns', 'Ransomware', 'Windows Persistence Techniques', 'Emotet Malware  DHS Report TA18-201A '], 'mitre_attack_id': ['T1547.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM', 'DE.AE'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>prohibited_apps_spawning_cmdprompt___ssa.yml</h4>

<table><tr><td>name</td><td>Detect Prohibited Applications Spawning cmd exe - SSA</td></tr><tr><td>id</td><td>c10a18cb-fd80-4ffa-a844-25026e0a0c94</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-7-13</td></tr><tr><td>description</td><td>This search looks for executions of cmd.exe spawned by a process that is often abused by attackers and that does not typically launch cmd.exe. This is a SPL2 implementation of the rule `Detect Prohibited Applications Spawning cmd.exe` by @bpatel.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting sysmon logs. This search has been modified to process raw sysmon data from attack_range's nxlogs on DSP.</td></tr><tr><td>author</td><td>Ignacio Bermudez Corrales, Splunk</td></tr><tr><td>type</td><td>SSA</td></tr><tr><td>search</td><td>| from read_ssa_enriched_events()
| eval timestamp=parse_long(ucast(map_get(input_event, "_time"), "string", null)) | eval process_name=ucast(map_get(input_event, "process_name"), "string", null), parent_process=lower(ucast(map_get(input_event, "parent_process_name"), "string", null)), dest_user_id=ucast(map_get(input_event, "dest_user_id"), "string", null), dest_device_id=ucast(map_get(input_event, "dest_device_id"), "string", null)
| where process_name="cmd.exe" | rex field=parent_process "(?<field0>[^\\\\]+)$" | where field0="winword.exe" OR field0="excel.exe" OR field0="outlook.exe" OR field0="powerpnt.exe" OR field0="visio.exe" OR field0="mspub.exe" OR field0="acrobat.exe" OR field0="acrord32.exe" OR field0="chrome.exe" OR field0="iexplore.exe" OR field0="opera.exe" OR field0="firefox.exe" OR field0="java.exe" OR field0="powershell.exe"
| eval start_time=timestamp, end_time=timestamp, entities=mvappend(dest_device_id, dest_user_id), body="TBD" | into write_ssa_detected_events();</td></tr><tr><td>eli5</td><td>Obtaining access to the Command-Line Interface (CLI) is typically a primary attacker goal. Once an attacker has obtained the ability to execute code on a target system, they will often further manipulate the system via commands passed to the CLI. It is also unusual for many applications to spawn a command shell during normal operation, while it is often observed if an application has been compromised in some way. As such, it is often beneficial to look for cmd.exe being executed by processes that are often targeted for exploitation, or that would not spawn cmd.exe in any other circumstances. A lookup file is provided to easily modify the processes that are being watched for execution of cmd.exe.</td></tr><tr><td>known_false_positives</td><td>There are circumstances where an application may legitimately execute and interact with the Windows command-line interface. Investigate and modify the lookup file, as appropriate.</td></tr><tr><td>tags</td><td>{'cis20': ['CIS 8'], 'kill_chain_phases': ['Exploitation'], 'mitre_technique_id': ['T1059'], 'nist': ['PR.PT', 'DE.CM'], 'risk_severity': 'low', 'security_domain': 'endpoint'}</td></tr></table>
<h4>windows_event_log_cleared.yml</h4>

<table><tr><td>name</td><td>Windows Event Log Cleared</td></tr><tr><td>id</td><td>ad517544-aff9-4c96-bd99-d6eb43bfbb6a</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-06</td></tr><tr><td>description</td><td>This search looks for Windows events that indicate one of the Windows event logs has been purged.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you need to be ingesting Windows event logs from your hosts.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>(`wineventlog_security` (EventCode=1102 OR EventCode=1100)) OR (`wineventlog_system` EventCode=104) | stats count min(_time) as firstTime max(_time) as lastTime by EventCode dest | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `windows_event_log_cleared_filter`</td></tr><tr><td>known_false_positives</td><td>It is possible that these logs may be legitimately cleared by Administrators.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Log Manipulation', 'Ransomware'], 'mitre_attack_id': ['T1070.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 5', 'CIS 6'], 'nist': ['DE.DP', 'PR.IP', 'PR.AC', 'PR.AT', 'DE.AE'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>web_servers_executing_suspicious_processes.yml</h4>

<table><tr><td>name</td><td>Web Servers Executing Suspicious Processes</td></tr><tr><td>id</td><td>ec3b7601-689a-4463-94e0-c9f45638efb9</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2019-04-01</td></tr><tr><td>description</td><td>This search looks for suspicious processes on all systems labeled as web servers.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model. In addition, web servers will need to be identified in the Assets and Identity Framework of Enterprise Security.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.dest_category="web_server" AND (Processes.process="*whoami*" OR Processes.process="*ping*" OR Processes.process="*iptables*" OR Processes.process="*wget*" OR Processes.process="*service*" OR Processes.process="*curl*") by Processes.process Processes.process_name, Processes.dest Processes.user| `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `web_servers_executing_suspicious_processes_filter`</td></tr><tr><td>known_false_positives</td><td>Some of these processes may be used legitimately on web servers during maintenance or other administrative tasks.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Apache Struts Vulnerability'], 'mitre_attack_id': ['T1082'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3'], 'nist': ['PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Web Server'}</td></tr></table>
<h4>common_ransomware_notes.yml</h4>

<table><tr><td>name</td><td>Common Ransomware Notes</td></tr><tr><td>id</td><td>ada0f478-84a8-4641-a3f1-d82362d6bd71</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-03-16</td></tr><tr><td>description</td><td>The search looks for files created with names matching those typically used in ransomware notes that tell the victim how to get their data back.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records file-system activity from your hosts to populate the Endpoint Filesystem data-model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or via other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file-system reads and writes.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem by Filesystem.file_name | `drop_dm_object_name(Filesystem)` | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `ransomware_notes` | `common_ransomware_notes_filter`</td></tr><tr><td>known_false_positives</td><td>It's possible that a legitimate file could be created with the same name used by ransomware note files.</td></tr><tr><td>tags</td><td>{'analytics_story': ['SamSam Ransomware', 'Ransomware'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>first_time_seen_running_windows_service.yml</h4>

<table><tr><td>name</td><td>First Time Seen Running Windows Service</td></tr><tr><td>id</td><td>823136f2-d755-4b6d-ae04-372b486a5808</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for the first and last time a Windows service is seen running in your environment. This table is then cached.</td></tr><tr><td>how_to_implement</td><td>While this search does not require you to adhere to Splunk CIM, you must be ingesting your Windows system event logs in order for this search to execute successfully. You should run the baseline search `Previously Seen Running Windows Services - Initial` to build the initial table of child processes and hostnames for this search to work. You should also schedule at the same interval as this search the second baseline search `Previously Seen Running Windows Services - Update` to keep this table up to date and to age out old Windows Services. Please update the `previously_seen_windows_service_window` macro to adjust the time window. Please ensure that the Splunk Add-on for Microsoft Windows is version 8.0.0 or above.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>`wineventlog_system` EventCode=7036 | rex field=Message "The (?<service>[-\(\)\s\w]+) service entered the (?<state>\w+) state" | where state="running" | lookup previously_seen_running_windows_services service as service OUTPUT firstTimeSeen | where isnull(firstTimeSeen) OR firstTimeSeen > relative_time(now(), "`previously_seen_windows_service_window`") | table _time dest service | `first_time_seen_running_windows_service_filter`</td></tr><tr><td>known_false_positives</td><td>A previously unseen service is not necessarily malicious. Verify that the service is legitimate and that was installed by a legitimate process.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Windows Service Abuse', 'Orangeworm Attack Group'], 'mitre_attack_id': ['T1569.002'], 'kill_chain_phases': ['Installation', 'Actions on Objectives'], 'cis20': ['CIS 2', 'CIS 9'], 'nist': ['ID.AM', 'PR.DS', 'PR.AC', 'DE.AE'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>malicious_powershell_process___connect_to_internet_with_hidden_window.yml</h4>

<table><tr><td>name</td><td>Malicious PowerShell Process - Connect To Internet With Hidden Window</td></tr><tr><td>id</td><td>ee18ed37-0802-4268-9435-b3b91aaa18db</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for PowerShell processes started with parameters to modify the execution policy of the run, run in a hidden window, and connect to the Internet. This combination of command-line options is suspicious because it's overriding the default PowerShell execution policy, attempts to hide its activity from the user, and connects to the Internet.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | search process="*-Exec*" process="*-WindowStyle*" process="*hidden*" process="*New-Object*" process="*System.Net.WebClient*" | `malicious_powershell_process___connect_to_internet_with_hidden_window_filter`</td></tr><tr><td>known_false_positives</td><td>Legitimate process can have this combination of command-line options, but it's not common.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Malicious PowerShell', 'Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns'], 'mitre_attack_id': ['T1059.001'], 'kill_chain_phases': ['Command and Control', 'Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 7', 'CIS 8'], 'nist': ['PR.PT', 'DE.CM', 'PR.IP'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>detect_credential_dumping_through_lsass_access.yml</h4>

<table><tr><td>name</td><td>Detect Credential Dumping through LSASS access</td></tr><tr><td>id</td><td>2c365e57-4414-4540-8dc0-73ab10729996</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2019-12-03</td></tr><tr><td>description</td><td>This search looks for reading lsass memory consistent with credential dumping.</td></tr><tr><td>how_to_implement</td><td>This search needs Sysmon Logs and a sysmon configuration, which includes EventCode 10 with lsass.exe. This search uses an input macro named `sysmon`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Sysmon logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Patrick Bareiss, Splunk</td></tr><tr><td>search</td><td>`sysmon` EventCode=10 TargetImage=*lsass.exe (GrantedAccess=0x1010 OR GrantedAccess=0x1410) | stats count min(_time) as firstTime max(_time) as lastTime by Computer, SourceImage, SourceProcessId, TargetImage, TargetProcessId, EventCode, GrantedAccess | rename Computer as dest | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_credential_dumping_through_lsass_access_filter` </td></tr><tr><td>known_false_positives</td><td>The activity may be legitimate. Other tools can access lsass for legitimate reasons, and it's possible this event could be generated in those cases. In these cases, false positives should be fairly obvious and you may need to tweak the search to eliminate noise.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Credential Dumping', 'Detect Zerologon Attack'], 'mitre_attack_id': ['T1003.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 3', 'CIS 5', 'CIS 16'], 'nist': ['PR.IP', 'PR.AC', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Windows'}</td></tr></table>

<h2>cloud</h2>


<h4>abnormally_high_aws_instances_launched_by_user___mltk.yml</h4>

<table><tr><td>name</td><td>Abnormally High AWS Instances Launched by User - MLTK</td></tr><tr><td>id</td><td>dec41ad5-d579-42cb-b4c6-f5dbb778bbe5</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for CloudTrail events where a user successfully launches an abnormally high number of instances.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. The threshold value should be tuned to your environment.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Jason Brewer, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` eventName=RunInstances errorCode=success `abnormally_high_aws_instances_launched_by_user___mltk_filter` | bucket span=10m _time  | stats count as instances_launched by _time src_user  | apply ec2_excessive_runinstances_v1  | rename "IsOutlier(instances_launched)" as isOutlier  | where isOutlier=1</td></tr><tr><td>known_false_positives</td><td>Many service accounts configured within an AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify if this search alerted on a human user.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Cloud Cryptomining', 'Suspicious AWS EC2 Activities'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1078.004'], 'cis20': ['CIS 13'], 'nist': ['DE.DP', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>kubernetes_aws_detect_sensitive_role_access.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-06-23</td></tr><tr><td>description</td><td>This search provides information on Kubernetes accounts accessing sensitve objects such as configmpas or secrets</td></tr><tr><td>how_to_implement</td><td>You must install splunk AWS add on and Splunk App for AWS. This search works with cloudwatch logs.</td></tr><tr><td>id</td><td>b6013a7b-85e0-4a45-b051-10b252d69569</td></tr><tr><td>known_false_positives</td><td>Sensitive role resource access is necessary for cluster operation, however source IP, namespace and user group may indicate possible malicious use. </td></tr><tr><td>name</td><td>Kubernetes AWS detect sensitive role access</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`aws_cloudwatchlogs_eks` objectRef.resource=clusterroles OR clusterrolebindings sourceIPs{}!=::1 sourceIPs{}!=127.0.0.1  | table sourceIPs{} user.username user.groups{} objectRef.namespace requestURI annotations.authorization.k8s.io/reason | dedup user.username user.groups{} |`kubernetes_aws_detect_sensitive_role_access_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Role Activity'], 'asset_type': 'AWS EKS Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>kubernetes_azure_detect_sensitive_role_access.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-05-20</td></tr><tr><td>description</td><td>This search provides information on Kubernetes accounts accessing sensitve objects such as configmpas or secrets</td></tr><tr><td>how_to_implement</td><td>You must install the Add-on for Microsoft Cloud Services and Configure Kube-Audit data diagnostics</td></tr><tr><td>id</td><td>f27349e5-1641-4f6a-9e68-30402be0ad4c</td></tr><tr><td>known_false_positives</td><td>Sensitive role resource access is necessary for cluster operation, however source IP, namespace and user group may indicate possible malicious use. </td></tr><tr><td>name</td><td>Kubernetes Azure detect sensitive role access</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`kubernetes_azure` category=kube-audit | spath input=properties.log| search objectRef.resource=clusterroles OR clusterrolebindings | table sourceIPs{} user.username user.groups{} objectRef.namespace requestURI annotations.authorization.k8s.io/reason | dedup user.username user.groups{} |`kubernetes_azure_detect_sensitive_role_access_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Role Activity'], 'asset_type': 'Azure AKS Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>abnormally_high_aws_instances_terminated_by_user___mltk.yml</h4>

<table><tr><td>name</td><td>Abnormally High AWS Instances Terminated by User - MLTK</td></tr><tr><td>id</td><td>1c02b86a-cd85-473e-a50b-014a9ac8fe3e</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for CloudTrail events where a user successfully terminates an abnormally high number of instances.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. The threshold value should be tuned to your environment.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Jason Brewer, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` eventName=TerminateInstances errorCode=success `abnormally_high_aws_instances_terminated_by_user___mltk_filter` | bucket span=10m _time  | stats count as instances_terminated by _time src_user  | apply ec2_excessive_terminateinstances_v1  | rename "IsOutlier(instances_terminated)" as isOutlier  | where isOutlier=1</td></tr><tr><td>known_false_positives</td><td>Many service accounts configured within an AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify if this search alerted on a human user.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious AWS EC2 Activities'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1078.004'], 'cis20': ['CIS 13'], 'nist': ['DE.DP', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>detect_spike_in_security_hub_alerts_for_user.yml</h4>

<table><tr><td>name</td><td>Detect Spike in AWS Security Hub Alerts for User</td></tr><tr><td>id</td><td>2a9b80d3-6220-4345-b5ad-290bf5d0d222</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for a spike in number of of AWS security Hub alerts for an AWS IAM User in 4 hours intervals.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your Security Hub inputs. The threshold_value should be tuned to your environment and schedule these searches according to the bucket span interval.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`aws_securityhub_firehose` "findings{}.Resources{}.Type"= AwsIamUser | rename findings{}.Resources{}.Id as user | bucket span=4h _time | stats count AS alerts by _time user | eventstats avg(alerts) as total_launched_avg, stdev(alerts) as total_launched_stdev | eval threshold_value = 2 | eval isOutlier=if(alerts > total_launched_avg+(total_launched_stdev * threshold_value), 1, 0) | search isOutlier=1 | table _time user alerts |`detect_spike_in_aws_security_hub_alerts_for_user_filter`</td></tr><tr><td>known_false_positives</td><td>None</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Security Hub Alerts'], 'cis20': ['CIS 13'], 'nist': ['DE.DP', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>ec2_instance_started_with_previously_unseen_instance_type.yml</h4>

<table><tr><td>name</td><td>EC2 Instance Started With Previously Unseen Instance Type</td></tr><tr><td>id</td><td>65541c80-03c7-4e05-83c8-1dcd57a2e1ad</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-02-07</td></tr><tr><td>description</td><td>This search looks for EC2 instances being created with previously unseen instance types.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 Instance Types" support search once to create a history of previously seen instance types.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` eventName=RunInstances [search `cloudtrail` eventName=RunInstances errorCode=success | fillnull value="m1.small" requestParameters.instanceType | stats earliest(_time) as earliest latest(_time) as latest by requestParameters.instanceType | rename requestParameters.instanceType as instanceType | inputlookup append=t previously_seen_ec2_instance_types.csv | stats min(earliest) as earliest max(latest) as latest by instanceType | outputlookup previously_seen_ec2_instance_types.csv | eval newType=if(earliest >= relative_time(now(), "-70m@m"), 1, 0) | `security_content_ctime(earliest)` | `security_content_ctime(latest)` | where newType=1 | rename instanceType as requestParameters.instanceType | table requestParameters.instanceType] | spath output=user userIdentity.arn | rename requestParameters.instanceType as instanceType, responseElements.instancesSet.items{}.instanceId as dest | table _time, user, dest, instanceType | `ec2_instance_started_with_previously_unseen_instance_type_filter`</td></tr><tr><td>known_false_positives</td><td>It is possible that an admin will create a new system using a new instance type never used before. Verify with the creator that they intended to create the system with the new instance type.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Cryptomining'], 'cis20': ['CIS 1'], 'nist': ['ID.AM'], 'security_domain': 'endpoint', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>kubernetes_azure_pod_scan_fingerprint.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-05-20</td></tr><tr><td>description</td><td>This search provides information of unauthenticated requests via source IP user agent, request URI and response status data against Kubernetes cluster pod in Azure</td></tr><tr><td>how_to_implement</td><td>You must install the Add-on for Microsoft Cloud Services and Configure Kube-Audit data diagnostics</td></tr><tr><td>id</td><td>86aad3e0-732f-4f66-bbbc-70df448e461d</td></tr><tr><td>known_false_positives</td><td>Not all unauthenticated requests are malicious, but source IPs, userAgent, verb, request URI and response status will provide context.</td></tr><tr><td>name</td><td>Kubernetes Azure pod scan fingerprint</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`kubernetes_azure` category=kube-audit | spath input=properties.log | search responseStatus.code=401 | table  sourceIPs{} userAgent verb requestURI responseStatus.reason properties.pod |`kubernetes_azure_pod_scan_fingerprint_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Scanning Activity'], 'asset_type': 'Azure AKS Kubernetes cluster', 'kill_chain_phases': ['Reconnaissance'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>ec2_instance_started_with_previously_unseen_user.yml</h4>

<table><tr><td>name</td><td>EC2 Instance Started With Previously Unseen User</td></tr><tr><td>id</td><td>22773e84-bac0-4595-b086-20d3f735b4f1</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for EC2 instances being created by users who have not created them before.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 Launches By User" support search once to create a history of previously seen ARNs.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` eventName=RunInstances [search `cloudtrail` eventName=RunInstances errorCode=success | stats earliest(_time) as firstTime latest(_time) as lastTime by userIdentity.arn | rename userIdentity.arn as arn | inputlookup append=t previously_seen_ec2_launches_by_user.csv | stats min(firstTime) as firstTime, max(lastTime) as lastTime by arn | outputlookup previously_seen_ec2_launches_by_user.csv | eval newUser=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newUser=1 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename arn as userIdentity.arn | table userIdentity.arn] | rename requestParameters.instanceType as instanceType, responseElements.instancesSet.items{}.instanceId as dest, userIdentity.arn as user | table _time, user, dest, instanceType | `ec2_instance_started_with_previously_unseen_user_filter`</td></tr><tr><td>known_false_positives</td><td>It's possible that a user will start to create EC2 instances when they haven't before for any number of reasons. Verify with the user that is launching instances that this is the intended behavior.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Cryptomining', 'Suspicious AWS EC2 Activities'], 'mitre_attack_id': ['T1078.004'], 'cis20': ['CIS 1'], 'nist': ['ID.AM'], 'security_domain': 'endpoint', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>detect_new_open_gcp_storage_buckets.yml</h4>

<table><tr><td>name</td><td>Detect New Open GCP Storage Buckets</td></tr><tr><td>id</td><td>f6ea3466-d6bb-11ea-87d0-0242ac130003</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-08-05</td></tr><tr><td>description</td><td>This search looks for GCP PubSub events where a user has created an open/public GCP Storage bucket.</td></tr><tr><td>how_to_implement</td><td>This search relies on the Splunk Add-on for Google Cloud Platform, setting up a Cloud Pub/Sub input, along with the relevant GCP PubSub topics and logging sink to capture GCP Storage Bucket events (https://cloud.google.com/logging/docs/routing/overview).</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Shannon Davis, Splunk</td></tr><tr><td>search</td><td>`google_gcp_pubsub_message` data.resource.type=gcs_bucket data.protoPayload.methodName=storage.setIamPermissions | spath output=action path=data.protoPayload.serviceData.policyDelta.bindingDeltas{}.action | spath output=user path=data.protoPayload.authenticationInfo.principalEmail | spath output=location path=data.protoPayload.resourceLocation.currentLocations{} | spath output=src path=data.protoPayload.requestMetadata.callerIp | spath output=bucketName path=data.protoPayload.resourceName | spath output=role path=data.protoPayload.serviceData.policyDelta.bindingDeltas{}.role | spath output=member path=data.protoPayload.serviceData.policyDelta.bindingDeltas{}.member | search (member=allUsers AND action=ADD) | table  _time, bucketName, src, user, location, action, role, member | search `detect_new_open_gcp_storage_buckets_filter`</td></tr><tr><td>known_false_positives</td><td>While this search has no known false positives, it is possible that a GCP admin has legitimately created a public bucket for a specific purpose. That said, GCP strongly advises against granting full control to the "allUsers" group.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious GCP Storage Activities'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1530'], 'cis20': ['CIS 13'], 'nist': ['PR.DS', 'PR.AC', 'DE.CM'], 'security_domain': 'network', 'asset_type': 'GCP Storage Bucket'}</td></tr></table>
<h4>kubernetes_aws_detect_suspicious_kubectl_calls.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-06-23</td></tr><tr><td>description</td><td>This search provides information on anonymous Kubectl calls with IP, verb namespace and object access context</td></tr><tr><td>how_to_implement</td><td>You must install splunk AWS add on and Splunk App for AWS. This search works with cloudwatch logs.</td></tr><tr><td>id</td><td>042a3d32-8318-4763-9679-09db2644a8f2</td></tr><tr><td>known_false_positives</td><td>Kubectl calls are not malicious by nature. However source IP, verb and Object can reveal potential malicious activity, specially anonymous suspicious IPs and sensitive objects such as configmaps or secrets</td></tr><tr><td>name</td><td>Kubernetes AWS detect suspicious kubectl calls</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`aws_cloudwatchlogs_eks` userAgent=kubectl* sourceIPs{}!=127.0.0.1 sourceIPs{}!=::1 src_user=system:anonymous  | table  src_ip src_user verb userAgent requestURI  | stats  count by src_ip src_user verb userAgent requestURI |`kubernetes_aws_detect_suspicious_kubectl_calls_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Object Access Activity'], 'asset_type': 'AWS EKS Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>kubernetes_gcp_detect_suspicious_kubectl_calls.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-07-11</td></tr><tr><td>description</td><td>This search provides information on anonymous Kubectl calls with IP, verb namespace and object access context</td></tr><tr><td>how_to_implement</td><td>You must install splunk add on for GCP. This search works with pubsub messaging logs.</td></tr><tr><td>id</td><td>a5bed417-070a-41f2-a1e4-82b6aa281557</td></tr><tr><td>known_false_positives</td><td>Kubectl calls are not malicious by nature. However source IP, source user, user agent, object path, and authorization context can reveal potential malicious activity, specially anonymous suspicious IPs and sensitive objects such as configmaps or secrets</td></tr><tr><td>name</td><td>Kubernetes GCP detect suspicious kubectl calls</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`google_gcp_pubsub_message` data.protoPayload.requestMetadata.callerSuppliedUserAgent=kubectl* src_user=system:unsecured OR src_user=system:anonymous | table src_ip src_user data.protoPayload.requestMetadata.callerSuppliedUserAgent data.protoPayload.authorizationInfo{}.granted object_path |dedup src_ip src_user |`kubernetes_gcp_detect_suspicious_kubectl_calls_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Object Access Activity'], 'asset_type': 'GCP GKE Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>detect_aws_console_login_by_user_from_new_country.yml</h4>

<table><tr><td>name</td><td>Detect AWS Console Login by User from New Country</td></tr><tr><td>id</td><td>67bd3def-c41c-4bf6-837b-ae196b4257c6</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-04-30</td></tr><tr><td>description</td><td>This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen users in CloudTrail" support search only once to create a baseline of previously seen IAM users within the last 30 days. Run "Update previously seen users in CloudTrail" hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>Jason Brewer, Splunk</td></tr><tr><td>search</td><td>| inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by user Country | join user type=outer [| inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) AS earliestseen by user | fields earliestseen user] | eval userStatus=if(firstTime >= relative_time(now(), "@d"), "New Country","Previously Seen Country") | eval UserData=if(earliestseen >= relative_time(now(), "@d") OR isnull(earliestseen), "New User","Old User") | where userStatus="New Country" AND UserData="Old User" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`|`security_content_ctime(earliestseen)` | table user Country userStatus firstTime lastTime earliestseen | `detect_aws_console_login_by_user_from_new_country_filter`</td></tr><tr><td>known_false_positives</td><td>When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious AWS Login Activities', 'Suspicious Cloud Authentication Activities'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1535'], 'cis20': ['CIS 16'], 'nist': ['DE.DP', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>detect_api_activity_from_users_without_mfa.yml</h4>

<table><tr><td>name</td><td>Detect API activity from users without MFA</td></tr><tr><td>id</td><td>2a9b80d3-6340-4345-w5ad-212bf5d1dac4</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-05-17</td></tr><tr><td>description</td><td>This search looks for CloudTrail events where a user logged into the AWS account, is making API calls and has not enabled Multi Factor authentication. Multi factor authentication adds a layer of security by forcing the users to type a unique authentication code from an approved authentication device when they access AWS websites or services. AWS Best Practices recommend that you enable MFA for privileged IAM users.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Leverage the support search `Create a list of approved AWS service accounts`: run it once every 30 days to create a list of service accounts and validate them.\
This search produces fields (`eventName`,`userIdentity.type`,`userIdentity.arn`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** AWS Event Name, **Field:** eventName\
1. \
1. **Label:** AWS User ARN, **Field:** userIdentity.arn\
1. \
1. **Label:** AWS User Type, **Field:** userIdentity.type\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` userIdentity.sessionContext.attributes.mfaAuthenticated=false | search NOT [| inputlookup aws_service_accounts | fields identity | rename identity as user]| stats  count min(_time) as firstTime max(_time) as lastTime values(eventName) as eventName by userIdentity.arn userIdentity.type user | `security_content_ctime(firstTime)`  | `security_content_ctime(lastTime)` | `detect_api_activity_from_users_without_mfa_filter`</td></tr><tr><td>known_false_positives</td><td>Many service accounts configured within an AWS infrastructure do not have multi factor authentication enabled. Please ignore the service accounts, if triggered and instead add them to the aws_service_accounts.csv file to fine tune the detection. It is also possible that the search detects users in your environment using Single Sign-On systems, since the MFA is not handled by AWS.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS User Monitoring'], 'cis20': ['CIS 16'], 'nist': ['DE.DP', 'PR.AC'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>aws_cloud_provisioning_from_previously_unseen_country.yml</h4>

<table><tr><td>name</td><td>AWS Cloud Provisioning From Previously Unseen Country</td></tr><tr><td>id</td><td>ceb8d3d8-06cb-49eb-beaf-829526e33ff0</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-03-16</td></tr><tr><td>description</td><td>This search looks for AWS provisioning activities from previously unseen countries. Provisioning activities are defined broadly as any event that begins with "Run" or "Create." </td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* [search `cloudtrail` (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by Country | eval newCountry=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newCountry=1 | table Country] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, Country, eventName, errorCode | `aws_cloud_provisioning_from_previously_unseen_country_filter`</td></tr><tr><td>known_false_positives</td><td>This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching over plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new country is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Suspicious Provisioning Activities'], 'mitre_attack_id': ['T1535'], 'cis20': ['CIS 1'], 'nist': ['ID.AM'], 'security_domain': 'endpoint', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>detect_spike_in_network_acl_activity.yml</h4>

<table><tr><td>name</td><td>Detect Spike in Network ACL Activity</td></tr><tr><td>id</td><td>ada0f478-84a8-4641-a1f1-e32372d4bd53</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-05-21</td></tr><tr><td>description</td><td>This search will detect users creating spikes in API activity related to network access-control lists (ACLs)in your AWS environment.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the minimum number of data points required to have a statistically significant amount of data to determine. The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike. This search works best when you run the "Baseline of Network ACL Activity by ARN" support search once to create a lookup file of previously seen Network ACL Activity. To add or remove API event names related to network ACLs, edit the macro `network_acl_events`.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` `network_acl_events` [search `cloudtrail` `network_acl_events` | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup network_acl_activity_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup network_acl_activity_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | stats values(eventName) as eventNames, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user | `detect_spike_in_network_acl_activity_filter`</td></tr><tr><td>known_false_positives</td><td>The false-positive rate may vary based on the values of`dataPointThreshold` and `deviationThreshold`. Please modify this according the your environment.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Network ACL Activity'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 12', 'CIS 11'], 'nist': ['DE.DP', 'DE.CM', 'PR.AC'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>aws_cross_account_activity_from_previously_unseen_account.yml</h4>

<table><tr><td>name</td><td>AWS Cross Account Activity From Previously Unseen Account</td></tr><tr><td>id</td><td>64fbbddf-fabf-4edf-80b3-0cc36ef37727</td></tr><tr><td>version</td><td>4</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for AssumeRole events where an IAM role in a different account is requested for the first time.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the `Previously Seen AWS Cross Account Activity` support search only once to create the baseline of previously seen cross account activity. Thanks to Pablo Vega at Recurly for suggesting improvements to the search.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` eventName=AssumeRole | spath output=requestingAccountId path=userIdentity.accountId | spath output=requestedAccountId path=resources{}.accountId | search requestingAccountId=* | where requestingAccountId != requestedAccountId | inputlookup append=t previously_seen_aws_cross_account_activity | multireport [| stats min(eval(coalesce(firstTime, _time))) as firstTime max(eval(coalesce(lastTime, _time))) as lastTime by requestingAccountId, requestedAccountId | outputlookup previously_seen_aws_cross_account_activity | where fact=fiction] [| eventstats min(eval(coalesce(firstTime, _time))) as firstTime, max(eval(coalesce(lastTime, _time))) as lastTime by requestingAccountId, requestedAccountId | where firstTime >= relative_time(now(), "-70m@m") AND isnotnull(_time) | spath output=accessKeyId path=responseElements.credentials.accessKeyId | spath output=requestingARN path=resources{}.ARN | stats values(awsRegion) as awsRegion values(firstTime) as firstTime values(lastTime) as lastTime values(sharedEventID) as sharedEventID, values(requestingARN) as src_user, values(responseElements.assumedRoleUser.arn) as dest_user by _time, requestingAccountId, requestedAccountId, accessKeyId] | table _time, firstTime, lastTime, src_user, requestingAccountId, dest_user, requestedAccountId, awsRegion, accessKeyId, sharedEventID | `aws_cross_account_activity_from_previously_unseen_account_filter`</td></tr><tr><td>known_false_positives</td><td>Using multiple AWS accounts and roles is perfectly valid behavior. It's suspicious when an account requests privileges of an account it hasn't before. You should validate with the account owner that this is a legitimate request.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Cross Account Activity'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1078.004'], 'cis20': ['CIS 16'], 'nist': ['PR.AC', 'PR.DS', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>aws_cloud_provisioning_from_previously_unseen_region.yml</h4>

<table><tr><td>name</td><td>AWS Cloud Provisioning From Previously Unseen Region</td></tr><tr><td>id</td><td>7971d3df-da82-4648-a6e5-b5637bea5253</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-03-16</td></tr><tr><td>description</td><td>This search looks for AWS provisioning activities from previously unseen regions. Region in this context is similar to a state in the United States. Provisioning activities are defined broadly as any event that begins with "Run" or "Create."</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Region=* [search `cloudtrail` (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Region=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by Region | eval newRegion=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newRegion=1 | table Region] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, Region, eventName, errorCode | `aws_cloud_provisioning_from_previously_unseen_region_filter`</td></tr><tr><td>known_false_positives</td><td>This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new region is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your region, there should be few false positives. If you are located in regions where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Suspicious Provisioning Activities'], 'mitre_attack_id': ['T1535'], 'cis20': ['CIS 1'], 'nist': ['ID.AM'], 'security_domain': 'endpoint', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>cloud_compute_instance_started_in_previously_unused_region.yml</h4>

<table><tr><td>name</td><td>Cloud Compute Instance Started In Previously Unused Region</td></tr><tr><td>id</td><td>fa4089e2-50e3-40f7-8469-d2cc1564ca59</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2019-10-02</td></tr><tr><td>description</td><td>This search looks at cloud-infrastructure events where an instance is created in any region within the last hour and then compares it to a lookup file of previously seen regions where instances have been created.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting the appropriate cloud-infrastructure logs and have the Security Research cloud data model (https://github.com/splunk/cloud-datamodel-security-research/) installed. Run the \"Previously Seen Cloud Compute Instance Types\" support search to create a baseline of previously seen regions.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats earliest(_time) as firstTime, latest(_time) as lastTime values(Compute.dest) as dest from datamodel=Cloud_Infrastructure.Compute where Compute.event_name=RunInstances `cloud_compute_instance_started_in_previously_unused_region_filter` by Compute.region, Compute.src_user | `drop_dm_object_name("Compute")` | inputlookup append=t previously_seen_cloud_regions | stats min(firstTime) as firstTime max(lastTime) as lastTime, values(dest) as dest by region, src_user | multireport [| table region, firstTime, lastTime | outputlookup previously_seen_cloud_regions | where fact=fiction][| eval new_region=if(firstTime >= relative_time(now(), `previously_seen_cloud_regions_search_window_begin_offset`), 1, 0) | where new_region=1 | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`] | table region, dest, src_user, firstTime, lastTime</td></tr><tr><td>known_false_positives</td><td>It's possible that a user has unknowingly started an instance in a new region. Please verify that this activity is legitimate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Cloud Cryptomining'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1535'], 'cis20': ['CIS 12'], 'nist': ['DE.DP', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'Cloud Compute Instance'}</td></tr></table>
<h4>amazon_eks_kubernetes_pod_scan_detection.yml</h4>

<table><tr><td>name</td><td>Amazon EKS Kubernetes Pod scan detection</td></tr><tr><td>id</td><td>dbfca1dd-b8e5-4ba4-be0e-e565e5d62002</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-04-15</td></tr><tr><td>description</td><td>This search provides detection information on unauthenticated requests against Kubernetes' Pods API</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on forAWS (version 4.4.0 or later), then configure your AWS CloudWatch EKS Logs.Please also customize the `kubernetes_pods_aws_scan_fingerprint_detection` macro to filter out the false positives.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>search</td><td>`aws_cloudwatchlogs_eks` "user.username"="system:anonymous" verb=list objectRef.resource=pods requestURI="/api/v1/pods" | rename source as cluster_name sourceIPs{} as src_ip | stats count min(_time) as firstTime max(_time) as lastTime values(responseStatus.reason) values(responseStatus.code) values(userAgent) values(verb) values(requestURI) by src_ip cluster_name user.username user.groups{} | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `amazon_eks_kubernetes_pod_scan_detection_filter` </td></tr><tr><td>known_false_positives</td><td>Not all unauthenticated requests are malicious, but frequency, UA and source IPs and direct request to API provide context.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Scanning Activity'], 'kill_chain_phases': ['Reconnaissance'], 'mitre_attack_id': ['T1526'], 'security_domain': 'threat', 'asset_type': 'Amazon EKS Kubernetes cluster Pod'}</td></tr></table>
<h4>gcp_detect_high_risk_permissions_by_resource_and_account.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-10-09</td></tr><tr><td>description</td><td>This search provides detection of high risk permissions by resource and accounts. These are permissions that can allow attackers with compromised accounts to move laterally and escalate privileges.</td></tr><tr><td>how_to_implement</td><td>You must install splunk GCP add-on. This search works with gcp:pubsub:message logs</td></tr><tr><td>id</td><td>2e70ef35-2187-431f-aedc-4503dc9b06ba</td></tr><tr><td>known_false_positives</td><td>High risk permissions are part of any GCP environment, however it is important to track resource and accounts usage, this search may produce false positives.</td></tr><tr><td>name</td><td>GCP Detect high risk permissions by resource and account</td></tr><tr><td>references</td><td>['https://github.com/dxa4481/gcploit', 'https://www.youtube.com/watch?v=Ml09R38jpok', 'https://cloud.google.com/iam/docs/permissions-reference']</td></tr><tr><td>search</td><td>`google_gcp_pubsub_message` data.protoPayload.authorizationInfo{}.permission=iam.serviceAccounts.getaccesstoken OR iam.serviceAccounts.setIamPolicy OR iam.serviceAccounts.actas OR dataflow.jobs.create OR composer.environments.create OR dataproc.clusters.create |table data.protoPayload.requestMetadata.callerIp data.protoPayload.authenticationInfo.principalEmail data.protoPayload.authorizationInfo{}.permission data.protoPayload.response.bindings{}.members{} data.resource.labels.project_id | `gcp_detect_high_risk_permissions_by_resource_and_account_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['GCP Cross Account Activity'], 'asset_type': 'GCP Account', 'kill_chain_phases': ['Lateral Movement'], 'mitre_attack_id': ['T1078'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>detect_aws_console_login_by_user_from_new_region.yml</h4>

<table><tr><td>name</td><td>Detect AWS Console Login by User from New Region</td></tr><tr><td>id</td><td>9f31aa8e-e37c-46bc-bce1-8b3be646d026</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-04-30</td></tr><tr><td>description</td><td>This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen users in CloudTrail" support search only once to create a baseline of previously seen IAM users within the last 30 days. Run "Update previously seen users in CloudTrail" hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>Jason Brewer, Splunk</td></tr><tr><td>search</td><td>| inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by user Region | join user type=outer [| inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) AS earliestseen by user | fields earliestseen user] | eval userStatus=if(firstTime >= relative_time(now(), "@d"), "New Region","Previously Seen Region") | eval UserData=if(earliestseen >= relative_time(now(), "@d") OR isnull(earliestseen), "New User","Old User") | where userStatus="New Region" AND UserData="Old User" | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `security_content_ctime(earliestseen)` | table user Region userStatus firstTime lastTime earliestseen | `detect_aws_console_login_by_user_from_new_region_filter`</td></tr><tr><td>known_false_positives</td><td>When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious AWS Login Activities', 'Suspicious Cloud Authentication Activities'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1535'], 'cis20': ['CIS 16'], 'nist': ['DE.DP', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>detect_s3_access_from_a_new_ip.yml</h4>

<table><tr><td>name</td><td>Detect S3 access from a new IP</td></tr><tr><td>id</td><td>2a9b80d3-6340-4345-b5ad-291bq3d0daq4</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-06-28</td></tr><tr><td>description</td><td>This search looks at S3 bucket-access logs and detects new or previously unseen remote IP addresses that have successfully accessed an S3 bucket.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your S3 access logs' inputs. This search works best when you run the "Previously Seen S3 Bucket Access by Remote IP" support search once to create a history of previously seen remote IPs and bucket names.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`aws_s3_accesslogs` http_status=200  [search `aws_s3_accesslogs` http_status=200 | stats earliest(_time) as firstTime latest(_time) as lastTime by bucket_name remote_ip | inputlookup append=t previously_seen_S3_access_from_remote_ip.csv | stats min(firstTime) as firstTime, max(lastTime) as lastTime by bucket_name remote_ip | outputlookup previously_seen_S3_access_from_remote_ip.csv | eval newIP=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newIP=1 | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | table bucket_name remote_ip]| iplocation remote_ip |rename remote_ip as src_ip | table _time bucket_name src_ip City Country operation request_uri | `detect_s3_access_from_a_new_ip_filter`</td></tr><tr><td>known_false_positives</td><td>S3 buckets can be accessed from any IP, as long as it can make a successful connection. This will be a false postive, since the search is looking for a new IP within the past hour</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious AWS S3 Activities'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1530'], 'cis20': ['CIS 13', 'CIS 14'], 'nist': ['PR.DS', 'PR.AC', 'DE.CM'], 'security_domain': 'network', 'asset_type': 'S3 Bucket'}</td></tr></table>
<h4>kubernetes_azure_detect_service_accounts_forbidden_failure_access.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-05-20</td></tr><tr><td>description</td><td>This search provides information on Kubernetes service accounts with failure or forbidden access status</td></tr><tr><td>how_to_implement</td><td>You must install the Add-on for Microsoft Cloud Services and Configure Kube-Audit data diagnostics</td></tr><tr><td>id</td><td>019690d7-420f-4da0-b320-f27b09961514</td></tr><tr><td>known_false_positives</td><td>This search can give false positives as there might be inherent issues with authentications and permissions at cluster.</td></tr><tr><td>name</td><td>Kubernetes Azure detect service accounts forbidden failure access</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`kubernetes_azure` category=kube-audit | spath input=properties.log | search user.groups{}=system:serviceaccounts*  responseStatus.reason=Forbidden | table  sourceIPs{} user.username userAgent verb responseStatus.reason responseStatus.status properties.pod objectRef.namespace  |`kubernetes_azure_detect_service_accounts_forbidden_failure_access_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Object Access Activity'], 'asset_type': 'Azure AKS Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>detect_spike_in_aws_api_activity.yml</h4>

<table><tr><td>name</td><td>Detect Spike in AWS API Activity</td></tr><tr><td>id</td><td>ada0f478-84a8-4641-a3f1-d32362d4bd55</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search will detect users creating spikes of API activity in your AWS environment.  It will also update the cache file that factors in the latest data.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the minimum number of data points required to have a statistically significant amount of data to determine. The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike.\
This search produces fields (`eventName`,`numberOfApiCalls`,`uniqueApisCalled`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** AWS Event Name, **Field:** eventName\
1. \
1. **Label:** Number of API Calls, **Field:** numberOfApiCalls\
1. \
1. **Label:** Unique API Calls, **Field:** uniqueApisCalled\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` eventType=AwsApiCall [search `cloudtrail` eventType=AwsApiCall | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup api_call_by_user_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup api_call_by_user_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | stats values(eventName) as eventName, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user | `detect_spike_in_aws_api_activity_filter`</td></tr><tr><td>known_false_positives</td><td></td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS User Monitoring'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1078.004'], 'cis20': ['CIS 16'], 'nist': ['DE.DP', 'DE.CM', 'PR.AC'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>detect_aws_console_login_by_user_from_new_city.yml</h4>

<table><tr><td>name</td><td>Detect AWS Console Login by User from New City</td></tr><tr><td>id</td><td>121b0b11-f8ac-4ed6-a132-3800ca4fc07a</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-04-30</td></tr><tr><td>description</td><td>This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen users in CloudTrail" support search only once to create a baseline of previously seen IAM users within the last 30 days. Run "Update previously seen users in CloudTrail" hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>Jason Brewer, Splunk</td></tr><tr><td>search</td><td>| inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by user City | join user type=outer [| inputlookup previously_seen_users_console_logins.csv | stats min(firstTime) AS earliestseen by user | fields earliestseen user] | eval userStatus=if(firstTime >= relative_time(now(), "@d"), "New City","Previously Seen City") | eval UserData=if(earliestseen >= relative_time(now(), "@d") OR isnull(earliestseen), "New User","Old User") | where userStatus="New City" AND UserData="Old User" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`| `security_content_ctime(earliestseen)` | table user City userStatus firstTime lastTime earliestseen | `detect_aws_console_login_by_user_from_new_city_filter`</td></tr><tr><td>known_false_positives</td><td>When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious AWS Login Activities', 'Suspicious Cloud Authentication Activities'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1535'], 'cis20': ['CIS 16'], 'nist': ['DE.DP', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>detect_spike_in_s3_bucket_deletion.yml</h4>

<table><tr><td>name</td><td>Detect Spike in S3 Bucket deletion</td></tr><tr><td>id</td><td>ad12w478-84a8-4641-a3w1-e32372q4bd53</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-11-27</td></tr><tr><td>description</td><td>This search detects users creating spikes in API activity related to deletion of S3 buckets in your AWS environment. It will also update the cache file that factors in the latest data.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the minimum number of data points required to have a statistically significant amount of data to determine. The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike. This search works best when you run the "Baseline of S3 Bucket deletion activity by ARN" support search once to create a baseline of previously seen S3 bucket-deletion activity.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` eventName=DeleteBucket [search `cloudtrail` eventName=DeleteBucket | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup s3_deletion_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup s3_deletion_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | spath output=bucketName path=requestParameters.bucketName | stats values(bucketName) as bucketName, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user | `detect_spike_in_s3_bucket_deletion_filter`</td></tr><tr><td>known_false_positives</td><td>Based on the values of`dataPointThreshold` and `deviationThreshold`, the false positive rate may vary. Please modify this according the your environment.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious AWS S3 Activities'], 'mitre_attack_id': ['T1530'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 13'], 'nist': ['DE.DP', 'DE.CM', 'PR.AC'], 'security_domain': 'network', 'asset_type': 'S3 Bucket'}</td></tr></table>
<h4>kubernetes_gcp_detect_sensitive_object_access.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-07-11</td></tr><tr><td>description</td><td>This search provides information on Kubernetes accounts accessing sensitve objects such as configmaps or secrets</td></tr><tr><td>how_to_implement</td><td>You must install splunk add on for GCP . This search works with pubsub messaging service logs.</td></tr><tr><td>id</td><td>bdb6d596-86a0-4aba-8369-418ae8b9963a</td></tr><tr><td>known_false_positives</td><td>Sensitive object access is not necessarily malicious but user and object context can provide guidance for detection.</td></tr><tr><td>name</td><td>Kubernetes GCP detect sensitive object access</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`google_gcp_pubsub_message` data.protoPayload.authorizationInfo{}.resource=configmaps OR secrets  | table data.protoPayload.requestMetadata.callerIp src_user data.resource.labels.cluster_name data.protoPayload.request.metadata.namespace data.labels.authorization.k8s.io/decision | dedup data.protoPayload.requestMetadata.callerIp src_user data.resource.labels.cluster_name |`kubernetes_gcp_detect_sensitive_object_access_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Object Access Activity'], 'asset_type': 'GCP GKE Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>detect_new_user_aws_console_login___dm.yml</h4>

<table><tr><td>name</td><td>Detect new user AWS Console Login - DM</td></tr><tr><td>id</td><td>bc91a8cd-35e7-4bb2-6140-e756cc46fd71</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-05-28</td></tr><tr><td>description</td><td>This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour</td></tr><tr><td>how_to_implement</td><td>You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Run the "Previously seen users in CloudTrail" support search only once to create a baseline of previously seen IAM users within the last 30 days. Run "Update previously seen users in CloudTrail" hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Authentication where Authentication.signature=ConsoleLogin by Authentication.user | `drop_dm_object_name(Authentication)` | inputlookup append=t previously_seen_users_console_logins.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by user | eval userStatus=if(firstTime >=relative_time(now(), '-70m@m'), 'First Time Logging into AWS Console','Previously Seen User')| `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`| `detect_new_user_aws_console_login___dm_filter`</td></tr><tr><td>known_false_positives</td><td>When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious Cloud Authentication Activities'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 16'], 'nist': ['DE.DP', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>kubernetes_azure_detect_sensitive_object_access.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-05-20</td></tr><tr><td>description</td><td>This search provides information on Kubernetes accounts accessing sensitve objects such as configmpas or secrets</td></tr><tr><td>how_to_implement</td><td>You must install the Add-on for Microsoft Cloud Services and Configure Kube-Audit data diagnostics</td></tr><tr><td>id</td><td>1bba382b-07fd-4ffa-b390-8002739b76e8</td></tr><tr><td>known_false_positives</td><td>Sensitive object access is not necessarily malicious but user and object context can provide guidance for detection.</td></tr><tr><td>name</td><td>Kubernetes Azure detect sensitive object access</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`kubernetes_azure` category=kube-audit | spath input=properties.log| search objectRef.resource=secrets OR configmaps user.username=system.anonymous OR annotations.authorization.k8s.io/decision=allow  |table user.username user.groups{} objectRef.resource objectRef.namespace objectRef.name annotations.authorization.k8s.io/reason |dedup user.username user.groups{} |`kubernetes_azure_detect_sensitive_object_access_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Object Access Activity'], 'asset_type': 'Azure AKS Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>kubernetes_aws_detect_rbac_authorizations_by_account.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-06-23</td></tr><tr><td>description</td><td>This search provides information on Kubernetes RBAC authorizations by accounts, this search can be modified by adding top to see both extremes of RBAC by accounts occurrences</td></tr><tr><td>how_to_implement</td><td>You must install splunk AWS add on and Splunk App for AWS. This search works with cloudwatch logs</td></tr><tr><td>id</td><td>de7264ed-3ed9-4fef-bb01-6eefc87cefe8</td></tr><tr><td>known_false_positives</td><td>Not all RBAC Authorications are malicious. RBAC authorizations can uncover malicious activity specially if sensitive Roles have been granted.</td></tr><tr><td>name</td><td>Kubernetes AWS detect RBAC authorization by account</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`aws_cloudwatchlogs_eks` annotations.authorization.k8s.io/reason=* | table sourceIPs{} user.username userAgent annotations.authorization.k8s.io/reason | stats count by user.username annotations.authorization.k8s.io/reason | rare user.username annotations.authorization.k8s.io/reason |`kubernetes_aws_detect_rbac_authorization_by_account_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Role Activity'], 'asset_type': 'AWS EKS Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>ec2_instance_started_with_previously_unseen_ami.yml</h4>

<table><tr><td>name</td><td>EC2 Instance Started With Previously Unseen AMI</td></tr><tr><td>id</td><td>347ec301-601b-48b9-81aa-9ddf9c829dd3</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-03-12</td></tr><tr><td>description</td><td>This search looks for EC2 instances being created with previously unseen AMIs.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 AMIs" support search once to create a history of previously seen AMIs.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` eventName=RunInstances [search `cloudtrail` eventName=RunInstances errorCode=success | stats earliest(_time) as firstTime latest(_time) as lastTime by requestParameters.instancesSet.items{}.imageId | rename requestParameters.instancesSet.items{}.imageId as amiID | inputlookup append=t previously_seen_ec2_amis.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by amiID | outputlookup previously_seen_ec2_amis.csv | eval newAMI=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)` | where newAMI=1 | rename amiID as requestParameters.instancesSet.items{}.imageId | table requestParameters.instancesSet.items{}.imageId] | rename requestParameters.instanceType as instanceType, responseElements.instancesSet.items{}.instanceId as dest, userIdentity.arn as arn, requestParameters.instancesSet.items{}.imageId as amiID | table firstTime, lastTime, arn, amiID, dest, instanceType | `ec2_instance_started_with_previously_unseen_ami_filter`</td></tr><tr><td>known_false_positives</td><td>After a new AMI is created, the first systems created with that AMI will cause this alert to fire.  Verify that the AMI being used was created by a legitimate user.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Cryptomining'], 'cis20': ['CIS 1'], 'nist': ['ID.AM'], 'security_domain': 'endpoint', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>abnormally_high_aws_instances_launched_by_user.yml</h4>

<table><tr><td>name</td><td>Abnormally High AWS Instances Launched by User</td></tr><tr><td>id</td><td>2a9b80d3-6340-4345-b5ad-290bf5d0dac4</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for CloudTrail events where a user successfully launches an abnormally high number of instances.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. The threshold value should be tuned to your environment.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` eventName=RunInstances errorCode=success | bucket span=10m _time | stats count AS instances_launched by _time userName | eventstats avg(instances_launched) as total_launched_avg, stdev(instances_launched) as total_launched_stdev | eval threshold_value = 4 | eval isOutlier=if(instances_launched > total_launched_avg+(total_launched_stdev * threshold_value), 1, 0) | search isOutlier=1 AND _time >= relative_time(now(), "-10m@m") | eval num_standard_deviations_away = round(abs(instances_launched - total_launched_avg) / total_launched_stdev, 2) | table _time, userName, instances_launched, num_standard_deviations_away, total_launched_avg, total_launched_stdev | `abnormally_high_aws_instances_launched_by_user_filter`</td></tr><tr><td>known_false_positives</td><td>Many service accounts configured within an AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify if this search alerted on a human user.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Cryptomining', 'Suspicious AWS EC2 Activities'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1078.004'], 'cis20': ['CIS 13'], 'nist': ['DE.DP', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'AWS Instance', 'risk_score': 40, 'risk_object_type': 'user', 'risk_object': 'userName'}</td></tr></table>
<h4>cloud_compute_instance_created_with_previously_unseen_image.yml</h4>

<table><tr><td>name</td><td>Cloud Compute Instance Created With Previously Unseen Image</td></tr><tr><td>id</td><td>bc24922d-987c-4645-b288-f8c73ec194c4</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-10-12</td></tr><tr><td>description</td><td>This search looks for cloud compute instances being created with previously unseen image IDs.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting the appropriate cloud-infrastructure logs and have the Security Research cloud data model (https://github.com/splunk/cloud-datamodel-security-research/) installed. Run the "Previously Seen Cloud Compute Images" support search to create a baseline of previously seen images.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats earliest(_time) as firstTime, latest(_time) as lastTime values(Compute.dest) as dest from datamodel=Cloud_Infrastructure.Compute where Compute.action=run `cloud_compute_instance_created_with_previously_unseen_image_filter` by Compute.image_id, Compute.src_user | `drop_dm_object_name("Compute")` | inputlookup append=t previously_seen_cloud_compute_images | stats min(firstTime) as firstTime max(lastTime) as lastTime, values(dest) as dest by image_id, src_user | multireport [| table image_id, firstTime, lastTime | outputlookup previously_seen_cloud_compute_images | where fact=fiction][| eval new_image=if(firstTime >= relative_time(now(), `previously_seen_cloud_compute_image_search_window_begin_offset`), 1, 0) | where new_image=1 | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`] | table image_id, dest, src_user, firstTime, lastTime</td></tr><tr><td>known_false_positives</td><td>After a new image is created, the first systems created with that image will cause this alert to fire.  Verify that the image being used was created by a legitimate user.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Cloud Cryptomining'], 'cis20': ['CIS 1'], 'nist': ['ID.AM'], 'security_domain': 'endpoint', 'asset_type': 'Cloud Compute Instance'}</td></tr></table>
<h4>gcp_detect_accounts_with_high_risk_roles_by_project.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-10-09</td></tr><tr><td>description</td><td>This search provides detection of accounts with high risk roles by projects. Compromised accounts with high risk roles can move laterally or even scalate privileges at different projects depending on organization schema.</td></tr><tr><td>how_to_implement</td><td>You must install splunk GCP add-on. This search works with gcp:pubsub:message logs</td></tr><tr><td>id</td><td>27af8c15-38b0-4408-b339-920170724adb</td></tr><tr><td>known_false_positives</td><td>Accounts with high risk roles should be reduced to the minimum number needed, however specific tasks and setups may be simply expected behavior within organization</td></tr><tr><td>name</td><td>GCP Detect accounts with high risk roles by project</td></tr><tr><td>references</td><td>['https://github.com/dxa4481/gcploit', 'https://www.youtube.com/watch?v=Ml09R38jpok', 'https://cloud.google.com/iam/docs/understanding-roles']</td></tr><tr><td>search</td><td>`google_gcp_pubsub_message` data.protoPayload.request.policy.bindings{}.role=roles/owner OR roles/editor OR roles/iam.serviceAccountUser OR roles/iam.serviceAccountAdmin OR roles/iam.serviceAccountTokenCreator OR roles/dataflow.developer OR roles/dataflow.admin OR roles/composer.admin OR roles/dataproc.admin OR roles/dataproc.editor | table data.resource.type data.protoPayload.authenticationInfo.principalEmail data.protoPayload.authorizationInfo{}.permission data.protoPayload.authorizationInfo{}.resource data.protoPayload.response.bindings{}.role data.protoPayload.response.bindings{}.members{} | `gcp_detect_accounts_with_high_risk_roles_by_project_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['GCP Cross Account Activity'], 'asset_type': 'GCP Account', 'kill_chain_phases': ['Lateral Movement'], 'mitre_attack_id': ['T1078'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>kubernetes_aws_detect_sensitive_object_access.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-06-23</td></tr><tr><td>description</td><td>This search provides information on Kubernetes accounts accessing sensitve objects such as configmaps or secrets</td></tr><tr><td>how_to_implement</td><td>You must install Splunk Add-on for Amazon Web Services and Splunk App for AWS. This search works with cloudwatch logs.</td></tr><tr><td>id</td><td>7f227943-2196-4d4d-8d6a-ac8cb308e61c</td></tr><tr><td>known_false_positives</td><td>Sensitive object access is not necessarily malicious but user and object context can provide guidance for detection.</td></tr><tr><td>name</td><td>AWS EKS Kubernetes cluster sensitive object access</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`aws_cloudwatchlogs_eks` objectRef.resource=secrets OR configmaps sourceIPs{}!=::1 sourceIPs{}!=127.0.0.1  |table sourceIPs{} user.username user.groups{} objectRef.resource objectRef.namespace objectRef.name annotations.authorization.k8s.io/reason |dedup user.username user.groups{} |`aws_eks_kubernetes_cluster_sensitive_object_access_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Object Access Activity'], 'asset_type': 'AWS EKS Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>detect_spike_in_security_group_activity.yml</h4>

<table><tr><td>name</td><td>Detect Spike in Security Group Activity</td></tr><tr><td>id</td><td>ada0f478-84a8-4641-a3f1-e32372d4bd53</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-04-18</td></tr><tr><td>description</td><td>This search will detect users creating spikes in API activity related to security groups in your AWS environment.  It will also update the cache file that factors in the latest data.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the minimum number of data points required to have a statistically significant amount of data to determine. The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike.This search works best when you run the "Baseline of Security Group Activity by ARN" support search once to create a history of previously seen Security Group Activity. To add or remove API event names for security groups, edit the macro `security_group_api_calls`.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` `security_group_api_calls` [search `cloudtrail` `security_group_api_calls` | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup security_group_activity_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup security_group_activity_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | stats values(eventName) as eventNames, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user | `detect_spike_in_security_group_activity_filter`</td></tr><tr><td>known_false_positives</td><td>Based on the values of`dataPointThreshold` and `deviationThreshold`, the false positive rate may vary. Please modify this according the your environment.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS User Monitoring'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1078.004'], 'cis20': ['CIS 16'], 'nist': ['DE.DP', 'DE.CM', 'PR.AC'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>aws_detect_sts_get_session_token_abuse.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-07-27</td></tr><tr><td>description</td><td>This search provides detection of suspicious use of sts:GetSessionToken. These tokens can be created on the go and used by attackers to move laterally and escalate privileges.</td></tr><tr><td>how_to_implement</td><td>You must install splunk AWS add-on and Splunk App for AWS. This search works with cloudwatch logs</td></tr><tr><td>id</td><td>85d7b35f-b8b5-4b01-916f-29b81e7a0551</td></tr><tr><td>known_false_positives</td><td>Sts:GetSessionToken can be very noisy as in certain environments numerous calls of this type can be executed. This search can be adjusted to provide specific values to identify cases of abuse. In specific environments the use of field requestParameters.serialNumber will need to be used.</td></tr><tr><td>name</td><td>aws detect sts get session token abuse</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`aws_cloudwatchlogs_eks` ASIA  userIdentity.type=IAMUser| spath eventName | search eventName=GetSessionToken | table sourceIPAddress eventTime userIdentity.arn userName userAgent user_type status region | `aws_detect_sts_get_session_token_abuse_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Cross Account Activity'], 'asset_type': 'AWS Account', 'kill_chain_phases': ['Lateral Movement'], 'mitre_attack_id': ['T1550'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>kubernetes_aws_detect_service_accounts_forbidden_failure_access.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-06-23</td></tr><tr><td>description</td><td>This search provides information on Kubernetes service accounts with failure or forbidden access status, this search can be extended by using top or rare operators to find trends or rarities in failure status, user agents, source IPs and request URI</td></tr><tr><td>how_to_implement</td><td>You must install splunk AWS add on and Splunk App for AWS. This search works with cloudwatch logs.</td></tr><tr><td>id</td><td>a6959c57-fa8f-4277-bb86-7c32fba579d5</td></tr><tr><td>known_false_positives</td><td>This search can give false positives as there might be inherent issues with authentications and permissions at cluster.</td></tr><tr><td>name</td><td>Kubernetes AWS detect service accounts forbidden failure access</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`aws_cloudwatchlogs_eks` user.groups{}=system:serviceaccounts responseStatus.status = Failure | table sourceIPs{} user.username userAgent verb responseStatus.status requestURI | `kubernetes_aws_detect_service_accounts_forbidden_failure_access_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Object Access Activity'], 'asset_type': 'AWS EKS Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>aws_network_access_control_list_deleted.yml</h4>

<table><tr><td>name</td><td>AWS Network Access Control List Deleted</td></tr><tr><td>id</td><td>ada0f478-84a8-4641-a3f1-d82362d6fd75</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-01-10</td></tr><tr><td>description</td><td>Enforcing network-access controls is one of the defensive mechanisms used by cloud administrators to restrict access to a cloud instance. After the attacker has gained control of the AWS console by compromising an admin account, they can delete a network ACL and gain access to the instance from anywhere. This search will query the CloudTrail logs to detect users deleting network ACLs.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` eventName=DeleteNetworkAcl|rename userIdentity.arn as arn  | stats count min(_time) as firstTime max(_time) as lastTime values(errorMessage) values(errorCode) values(userAgent) values(userIdentity.*) by src userName arn eventName | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `aws_network_access_control_list_deleted_filter`</td></tr><tr><td>known_false_positives</td><td>It's possible that a user has legitimately deleted a network ACL.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Network ACL Activity'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 11'], 'nist': ['DE.DP', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>abnormally_high_aws_instances_terminated_by_user.yml</h4>

<table><tr><td>name</td><td>Abnormally High AWS Instances Terminated by User</td></tr><tr><td>id</td><td>ada0f478-84a8-4641-s3f3-d82362dffd75</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for CloudTrail events where an abnormally high number of instances were successfully terminated by a user in a 10-minute window</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` eventName=TerminateInstances errorCode=success | bucket span=10m _time | stats count AS instances_terminated by _time userName | eventstats avg(instances_terminated) as total_terminations_avg, stdev(instances_terminated) as total_terminations_stdev | eval threshold_value = 4 | eval isOutlier=if(instances_terminated > total_terminations_avg+(total_terminations_stdev * threshold_value), 1, 0) | search isOutlier=1 AND _time >= relative_time(now(), "-10m@m")| eval num_standard_deviations_away = round(abs(instances_terminated - total_terminations_avg) / total_terminations_stdev, 2) |table _time, userName, instances_terminated, num_standard_deviations_away, total_terminations_avg, total_terminations_stdev | `abnormally_high_aws_instances_terminated_by_user_filter`</td></tr><tr><td>known_false_positives</td><td>Many service accounts configured with your AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify whether this search alerted on a human user.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious AWS EC2 Activities'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1078.004'], 'cis20': ['CIS 13'], 'nist': ['DE.DP', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>detect_gcp_storage_access_from_a_new_ip.yml</h4>

<table><tr><td>name</td><td>Detect GCP Storage access from a new IP</td></tr><tr><td>id</td><td>ccc3246a-daa1-11ea-87d0-0242ac130022</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-08-10</td></tr><tr><td>description</td><td>This search looks at GCP Storage bucket-access logs and detects new or previously unseen remote IP addresses that have successfully accessed a GCP Storage bucket.</td></tr><tr><td>how_to_implement</td><td>This search relies on the Splunk Add-on for Google Cloud Platform, setting up a Cloud Pub/Sub input, along with the relevant GCP PubSub topics and logging sink to capture GCP Storage Bucket events (https://cloud.google.com/logging/docs/routing/overview). In order to capture public GCP Storage Bucket access logs, you must also enable storage bucket logging to your PubSub Topic as per https://cloud.google.com/storage/docs/access-logs.  These logs are deposited into the nominated Storage Bucket on an hourly basis and typically show up by 15 minutes past the hour.  It is recommended to configure any saved searches or correlation searches in Enterprise Security to run on an hourly basis at 30 minutes past the hour (cron definition of 30 * * * *).  A lookup table (previously_seen_gcp_storage_access_from_remote_ip.csv) stores the previously seen access requests, and is used by this search to determine any newly seen IP addresses accessing the Storage Buckets.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Shannon Davis, Splunk</td></tr><tr><td>search</td><td>`google_gcp_pubsub_message` | multikv | rename sc_status_ as status | rename cs_object_ as bucket_name | rename c_ip_ as remote_ip | rename cs_uri_ as request_uri | rename cs_method_ as operation | search status="\"200\"" | stats earliest(_time) as firstTime latest(_time) as lastTime by bucket_name remote_ip operation request_uri | table firstTime, lastTime, bucket_name, remote_ip, operation, request_uri | inputlookup append=t previously_seen_gcp_storage_access_from_remote_ip.csv | stats min(firstTime) as firstTime, max(lastTime) as lastTime by bucket_name remote_ip operation request_uri | outputlookup previously_seen_gcp_storage_access_from_remote_ip.csv | eval newIP=if(firstTime >= relative_time(now(),"-70m@m"), 1, 0) | where newIP=1 | eval first_time=strftime(firstTime,"%m/%d/%y %H:%M:%S") | eval last_time=strftime(lastTime,"%m/%d/%y %H:%M:%S") | table  first_time last_time bucket_name remote_ip operation request_uri | `detect_gcp_storage_access_from_a_new_ip_filter`</td></tr><tr><td>known_false_positives</td><td>GCP Storage buckets can be accessed from any IP (if the ACLs are open to allow it), as long as it can make a successful connection. This will be a false postive, since the search is looking for a new IP within the past two hours.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious GCP Storage Activities'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1530'], 'cis20': ['CIS 13', 'CIS 14'], 'nist': ['PR.DS', 'PR.AC', 'DE.CM'], 'security_domain': 'network', 'asset_type': 'GCP Storage Bucket'}</td></tr></table>
<h4>gcp_kubernetes_cluster_scan_detection.yml</h4>

<table><tr><td>name</td><td>GCP Kubernetes cluster scan detection</td></tr><tr><td>id</td><td>db5957ec-0144-4c56-b512-9dccbe7a2d26</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-04-15</td></tr><tr><td>description</td><td>This search provides information of unauthenticated requests via user agent, and authentication data against Kubernetes cluster</td></tr><tr><td>how_to_implement</td><td>You must install the GCP App for Splunk (version 2.0.0 or later), then configure stackdriver and set a Pub/Sub subscription to be imported to Splunk. You must also install Cloud Infrastructure data model.Customize the macro kubernetes_gcp_scan_fingerprint_attack_detection to filter out FPs.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>search</td><td>`google_gcp_pubsub_message` data.protoPayload.requestMetadata.callerIp!=127.0.0.1 data.protoPayload.requestMetadata.callerIp!=::1 "data.labels.authorization.k8s.io/decision"=forbid "data.protoPayload.status.message"=PERMISSION_DENIED data.protoPayload.authenticationInfo.principalEmail="system:anonymous" | rename data.protoPayload.requestMetadata.callerIp as src_ip | stats count min(_time) as firstTime max(_time) as lastTime values(data.protoPayload.methodName) as method_name values(data.protoPayload.resourceName) as resource_name values(data.protoPayload.requestMetadata.callerSuppliedUserAgent) as http_user_agent by src_ip data.resource.labels.cluster_name | rename data.resource.labels.cluster_name as cluster_name| `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`  | `gcp_kubernetes_cluster_scan_detection_filter` </td></tr><tr><td>known_false_positives</td><td>Not all unauthenticated requests are malicious, but frequency, User Agent and source IPs will provide context.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Scanning Activity'], 'kill_chain_phases': ['Reconnaissance'], 'mitre_attack_id': ['T1526'], 'security_domain': 'threat', 'asset_type': 'GCP Kubernetes cluster'}</td></tr></table>
<h4>aws_detect_attach_to_role_policy.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-07-27</td></tr><tr><td>description</td><td>This search provides detection of an user attaching itself to a different role trust policy. This can be used for lateral movement and escalation of privileges.</td></tr><tr><td>how_to_implement</td><td>You must install splunk AWS add-on and Splunk App for AWS. This search works with cloudwatch logs</td></tr><tr><td>id</td><td>88fc31dd-f331-448c-9856-d3d51dd5d3a1</td></tr><tr><td>known_false_positives</td><td>Attach to policy can create a lot of noise. This search can be adjusted to provide specific values to identify cases of abuse (i.e status=failure). The search can provide context for common users attaching themselves to higher privilege policies or even newly created policies.</td></tr><tr><td>name</td><td>aws detect attach to role policy</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`aws_cloudwatchlogs_eks` attach policy| spath requestParameters.policyArn | table sourceIPAddress user_access_key userIdentity.arn userIdentity.sessionContext.sessionIssuer.arn eventName errorCode errorMessage status action requestParameters.policyArn userIdentity.sessionContext.attributes.mfaAuthenticated userIdentity.sessionContext.attributes.creationDate  | `aws_detect_attach_to_role_policy_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Cross Account Activity'], 'asset_type': 'AWS Account', 'kill_chain_phases': ['Lateral Movement'], 'mitre_attack_id': ['T1078'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>detect_spike_in_aws_security_hub_alerts_for_ec2_instance.yml</h4>

<table><tr><td>name</td><td>Detect Spike in AWS Security Hub Alerts for EC2 Instance</td></tr><tr><td>id</td><td>2a9b80d3-6340-4345-b5ad-290bf5d0d222</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for a spike in number of of AWS security Hub alerts for an EC2 instance in 4 hours intervals</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your Security Hub inputs. The threshold_value should be tuned to your environment and schedule these searches according to the bucket span interval.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`aws_securityhub_firehose` "findings{}.Resources{}.Type"=AWSEC2Instance | rex field=findings{}.Resources{}.Id .*instance/(?<instance>.*) | rename instance as dest | bucket span=4h _time | stats count AS alerts by _time dest | eventstats avg(alerts) as total_launched_avg, stdev(alerts) as total_launched_stdev | eval threshold_value = 4 | eval isOutlier=if(alerts > total_launched_avg+(total_launched_stdev * threshold_value), 1, 0) | search isOutlier=1 | table _time dest alerts|`detect_spike_in_aws_security_hub_alerts_for_ec2_instance_filter`</td></tr><tr><td>known_false_positives</td><td>None</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Security Hub Alerts'], 'cis20': ['CIS 13'], 'nist': ['DE.DP', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>gcp_detect_gcploit_framework.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-10-08</td></tr><tr><td>description</td><td>This search provides detection of GCPloit exploitation framework. This framework can be used to escalate privileges and move laterally from compromised high privilege accounts.</td></tr><tr><td>how_to_implement</td><td>You must install splunk GCP add-on. This search works with gcp:pubsub:message logs</td></tr><tr><td>id</td><td>a1c5a85e-a162-410c-a5d9-99ff639e5a52</td></tr><tr><td>known_false_positives</td><td>Payload.request.function.timeout value can possibly be match with other functions or requests however the source user and target request account may indicate an attempt to move laterally accross acounts or projects</td></tr><tr><td>name</td><td>GCP Detect gcploit framework</td></tr><tr><td>references</td><td>['https://github.com/dxa4481/gcploit', 'https://www.youtube.com/watch?v=Ml09R38jpok']</td></tr><tr><td>search</td><td>`google_gcp_pubsub_message` data.protoPayload.request.function.timeout=539s | table src src_user data.resource.labels.project_id data.protoPayload.request.function.serviceAccountEmail data.protoPayload.authorizationInfo{}.permission data.protoPayload.request.location http_user_agent | `gcp_detect_gcploit_framework_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['GCP Cross Account Activity'], 'asset_type': 'GCP Account', 'kill_chain_phases': ['Lateral Movement'], 'mitre_attack_id': ['T1078'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>cloud_compute_instance_created_by_previously_unseen_user.yml</h4>

<table><tr><td>name</td><td>Cloud Compute Instance Created By Previously Unseen User</td></tr><tr><td>id</td><td>76988f6a-3935-48f6-a9e5-6fca8b3ed843</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for cloud compute instances created by users who have not created them before.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting the appropriate cloud-infrastructure logs and have the Security Research cloud data model (https://github.com/splunk/cloud-datamodel-security-research/) installed. Run the "Previously Seen Cloud Compute Creations By User" support search to create of baseline of previously seen users.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` earliest(_time) as firstTime, latest(_time) as lastTime values(Compute.dest) as dest from datamodel=Cloud_Infrastructure.Compute where Compute.action=run by Compute.src_user | `drop_dm_object_name("Compute")` | inputlookup append=t previously_seen_cloud_compute_creations_by_user  | stats min(firstTime) as firstTime max(lastTime) as lastTime, values(dest) as dest by src_user | multireport [| table src_user, firstTime, lastTime | outputlookup previously_seen_cloud_compute_creations_by_user | where fact=fiction][| eval new_user=if(firstTime >= relative_time(now(), `previously_seen_cloud_compute_creations_by_user_search_window_begin_offset`), 1, 0) | where new_user=1 | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`] | table src_user, dest, firstTime, lastTime | `cloud_compute_instance_created_by_previously_unseen_user_filter`</td></tr><tr><td>known_false_positives</td><td>It's possible that a user will start to create compute instances for the first time, for any number of reasons. Verify with the user launching instances that this is the intended behavior.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Cloud Cryptomining'], 'cis20': ['CIS 1'], 'mitre_attack_id': ['T1078.004'], 'nist': ['ID.AM'], 'security_domain': 'endpoint', 'asset_type': 'Cloud Compute Instance'}</td></tr></table>
<h4>ec2_instance_modified_with_previously_unseen_user.yml</h4>

<table><tr><td>name</td><td>EC2 Instance Modified With Previously Unseen User</td></tr><tr><td>id</td><td>56f91724-cf3f-4666-84e1-e3712fb41e76</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for EC2 instances being modified by users who have not previously modified them.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 Launches By User" support search once to create a history of previously seen ARNs. To add or remove APIs that modify an EC2 instance, edit the macro `ec2_modification_api_calls`.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` `ec2_modification_api_calls` [search `cloudtrail` `ec2_modification_api_calls` errorCode=success | stats earliest(_time) as firstTime latest(_time) as lastTime by userIdentity.arn | rename userIdentity.arn as arn | inputlookup append=t previously_seen_ec2_modifications_by_user | stats min(firstTime) as firstTime, max(lastTime) as lastTime by arn | outputlookup previously_seen_ec2_modifications_by_user | eval newUser=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newUser=1 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=dest responseElements.instancesSet.items{}.instanceId | spath output=user userIdentity.arn | table _time, user, dest | `ec2_instance_modified_with_previously_unseen_user_filter`</td></tr><tr><td>known_false_positives</td><td>It's possible that a new user will start to modify EC2 instances when they haven't before for any number of reasons. Verify with the user that is modifying instances that this is the intended behavior.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Unusual AWS EC2 Modifications'], 'mitre_attack_id': ['T1078.004'], 'cis20': ['CIS 1'], 'nist': ['ID.AM'], 'security_domain': 'endpoint', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>kubernetes_gcp_detect_most_active_service_accounts_by_pod.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-07-10</td></tr><tr><td>description</td><td>This search provides information on Kubernetes service accounts,accessing pods by IP address, verb and decision</td></tr><tr><td>how_to_implement</td><td>You must install splunk GCP add on. This search works with pubsub messaging service logs</td></tr><tr><td>id</td><td>7f5c2779-88a0-4824-9caa-0f606c8f260f</td></tr><tr><td>known_false_positives</td><td>Not all service accounts interactions are malicious. Analyst must consider IP, verb and decision context when trying to detect maliciousness.</td></tr><tr><td>name</td><td>Kubernetes GCP detect most active service accounts by pod</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`google_gcp_pubsub_message  data.protoPayload.request.spec.group{}=system:serviceaccounts | table src_ip src_user http_user_agent data.protoPayload.request.spec.nonResourceAttributes.verb data.labels.authorization.k8s.io/decision data.protoPayload.response.spec.resourceAttributes.resource | top src_ip src_user http_user_agent data.labels.authorization.k8s.io/decision data.protoPayload.response.spec.resourceAttributes.resource |`kubernetes_gcp_detect_most_active_service_accounts_by_pod_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Role Activity'], 'asset_type': 'GCP GKE Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>detect_aws_api_activities_from_unapproved_accounts.yml</h4>

<table><tr><td>name</td><td>Detect AWS API Activities From Unapproved Accounts</td></tr><tr><td>id</td><td>ada0f478-84a8-4641-a3f1-d82362d4bd55</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for successful CloudTrail activity by user accounts that are not listed in the identity table or `aws_service_accounts.csv`. It returns event names and count, as well as the first and last time a specific user or service is detected, grouped by users.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You must also populate the `identity_lookup_expanded` lookup shipped with the Asset and Identity framework to be able to look up users in your identity table in Enterprise Security (ES). Leverage the support search called "Create a list of approved AWS service accounts": run it once every 30 days to create and validate a list of service accounts.\
This search produces fields (`eventName`,`firstTime`,`lastTime`) that are not yet supported by ES Incident Review and therefore cannot be viewed when a notable event is raised. These fields contribute additional context to the notable. To see the additional metadata, add the following fields, if not already present, to Incident Review - Event Attributes (Configure > Incident Management > Incident Review Settings > Add New Entry):\\n1. **Label:** AWS Event Name, **Field:** eventName\
1. \
1. **Label:** First Time, **Field:** firstTime\
1. \
1. **Label:** Last Time, **Field:** lastTime\
Detailed documentation on how to create a new field within Incident Review may be found here: `https://docs.splunk.com/Documentation/ES/5.3.0/Admin/Customizenotables#Add_a_field_to_the_notable_event_details`</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` errorCode=success | rename userName as identity | search NOT [| inputlookup identity_lookup_expanded | fields identity] | search NOT [| inputlookup aws_service_accounts | fields identity] | rename identity as user | stats count min(_time) as firstTime max(_time) as lastTime values(eventName) as eventName by user | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `detect_aws_api_activities_from_unapproved_accounts_filter`</td></tr><tr><td>known_false_positives</td><td>It's likely that you'll find activity detected by users/service accounts that are not listed in the `identity_lookup_expanded` or ` aws_service_accounts.csv` file. If the user is a legitimate service account, update the `aws_service_accounts.csv` table with that entry.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS User Monitoring'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 16'], 'mitre_attack_id': ['T1078.004'], 'nist': ['DE.DP', 'DE.CM', 'PR.AC', 'ID.AM'], 'security_domain': 'access', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>amazon_eks_kubernetes_cluster_scan_detection.yml</h4>

<table><tr><td>name</td><td>Amazon EKS Kubernetes cluster scan detection</td></tr><tr><td>id</td><td>294c4686-63dd-4fe6-93a2-ca807626704a</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-04-15</td></tr><tr><td>description</td><td>This search provides information of unauthenticated requests via user agent, and authentication data against Kubernetes cluster in AWS</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudWatch EKS Logs inputs.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>search</td><td>`aws_cloudwatchlogs_eks` "user.username"="system:anonymous" userAgent!="AWS Security Scanner" | rename sourceIPs{} as src_ip | stats count min(_time) as firstTime max(_time) as lastTime values(responseStatus.reason) values(source) as cluster_name values(responseStatus.code) values(userAgent) as http_user_agent values(verb) values(requestURI) by src_ip user.username user.groups{} | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` |`amazon_eks_kubernetes_cluster_scan_detection_filter` </td></tr><tr><td>known_false_positives</td><td>Not all unauthenticated requests are malicious, but frequency, UA and source IPs will provide context.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Scanning Activity'], 'kill_chain_phases': ['Reconnaissance'], 'mitre_attack_id': ['T1526'], 'security_domain': 'threat', 'asset_type': 'Amazon EKS Kubernetes cluster'}</td></tr></table>
<h4>cloud_compute_instance_created_with_previously_unseen_instance_type.yml</h4>

<table><tr><td>name</td><td>Cloud Compute Instance Created With Previously Unseen Instance Type</td></tr><tr><td>id</td><td>c6ddbf53-9715-49f3-bb4c-fb2e8a309cda</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-03-12</td></tr><tr><td>description</td><td>Find EC2 instances being created with previously unseen instance types.</td></tr><tr><td>how_to_implement</td><td>You must be ingesting the appropriate cloud-infrastructure logs and have the Security Research cloud data model (https://github.com/splunk/cloud-datamodel-security-research/) installed. Run the " Previously Seen Cloud Compute Instance Types" support search to create a baseline of previously seen regions.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats earliest(_time) as firstTime, latest(_time) as lastTime values(Compute.dest) as dest from datamodel=Cloud_Infrastructure.Compute where Compute.event_name=RunInstances `cloud_compute_instance_created_with_previously_unseen_instance_type_filter` by Compute.instance_type, Compute.src_user | `drop_dm_object_name("Compute")` | inputlookup append=t previously_seen_cloud_compute_instance_types | stats min(firstTime) as firstTime max(lastTime) as lastTime, values(dest) as dest by instance_type, src_user | multireport [| table instance_type, firstTime, lastTime | outputlookup previously_seen_cloud_compute_instance_types | where fact=fiction][| eval new_type=if(firstTime >= relative_time(now(), `previously_seen_cloud_compute_instance_types_search_window_begin_offset`), 1, 0) | where new_type=1 | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`] | table instance_type, dest, src_user, firstTime, lastTime</td></tr><tr><td>known_false_positives</td><td>It is possible that an admin will create a new system using a new instance type that has never been used before. Verify with the creator that they intended to create the system with the new instance type.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Cloud Cryptomining'], 'cis20': ['CIS 1'], 'nist': ['ID.AM'], 'security_domain': 'endpoint', 'asset_type': 'Cloud Compute Instance'}</td></tr></table>
<h4>detect_spike_in_blocked_outbound_traffic_from_your_aws.yml</h4>

<table><tr><td>name</td><td>Detect Spike in blocked Outbound Traffic from your AWS</td></tr><tr><td>id</td><td>ada0f278-84a8-46w1-a3f1-w32372d4bd53</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-05-07</td></tr><tr><td>description</td><td>This search will detect spike in blocked outbound network connections originating from within your AWS environment.  It will also update the cache file that factors in the latest data.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your VPC Flow logs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the number of data points required to meet the definition of "spike." The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike. This search works best when you run the "Baseline of Blocked Outbound Connection" support search once to create a history of previously seen blocked outbound connections.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`cloudwatchlogs_vpcflow` action=blocked (src_ip=10.0.0.0/8 OR src_ip=172.16.0.0/12 OR src_ip=192.168.0.0/16) ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16)  [search  `cloudwatchlogs_vpcflow` action=blocked (src_ip=10.0.0.0/8 OR src_ip=172.16.0.0/12 OR src_ip=192.168.0.0/16) ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16)  | stats count as numberOfBlockedConnections by src_ip | inputlookup baseline_blocked_outbound_connections append=t | fields - latestCount | stats values(*) as * by src_ip | rename numberOfBlockedConnections as latestCount | eval newAvgBlockedConnections=avgBlockedConnections + (latestCount-avgBlockedConnections)/720 | eval newStdevBlockedConnections=sqrt(((pow(stdevBlockedConnections, 2)*719 + (latestCount-newAvgBlockedConnections)*(latestCount-avgBlockedConnections))/720)) | eval avgBlockedConnections=coalesce(newAvgBlockedConnections, avgBlockedConnections), stdevBlockedConnections=coalesce(newStdevBlockedConnections, stdevBlockedConnections), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table src_ip, latestCount, numDataPoints, avgBlockedConnections, stdevBlockedConnections | outputlookup baseline_blocked_outbound_connections | eval dataPointThreshold = 5, deviationThreshold = 3 | eval isSpike=if((latestCount > avgBlockedConnections+deviationThreshold*stdevBlockedConnections) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | table src_ip] | stats values(dest_ip) as "Blocked Destination IPs", values(interface_id) as "resourceId" count as numberOfBlockedConnections, dc(dest_ip) as uniqueDestConnections by src_ip | `detect_spike_in_blocked_outbound_traffic_from_your_aws_filter`</td></tr><tr><td>known_false_positives</td><td>The false-positive rate may vary based on the values of`dataPointThreshold` and `deviationThreshold`. Additionally, false positives may result when AWS administrators roll out policies enforcing network blocks, causing sudden increases in the number of blocked outbound connections.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Network ACL Activity', 'Suspicious AWS Traffic', 'Command and Control'], 'kill_chain_phases': ['Actions on Objectives', 'Command and Control'], 'cis20': ['CIS 11'], 'nist': ['DE.AE', 'DE.CM', 'PR.AC'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>aws_cloud_provisioning_from_previously_unseen_ip_address.yml</h4>

<table><tr><td>name</td><td>AWS Cloud Provisioning From Previously Unseen IP Address</td></tr><tr><td>id</td><td>42e15012-ac14-4801-94f4-f1acbe64880b</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-03-16</td></tr><tr><td>description</td><td>This search looks for AWS provisioning activities from previously unseen IP addresses. Provisioning activities are defined broadly as any event that begins with "Run" or "Create." </td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` (eventName=Run* OR eventName=Create*) [search `cloudtrail` (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress | eval newIP=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newIP=1 | table sourceIPAddress] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, eventName, errorCode | `aws_cloud_provisioning_from_previously_unseen_ip_address_filter`</td></tr><tr><td>known_false_positives</td><td>This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new IP address is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Suspicious Provisioning Activities'], 'cis20': ['CIS 1'], 'nist': ['ID.AM'], 'security_domain': 'endpoint', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>aws_cloud_provisioning_from_previously_unseen_city.yml</h4>

<table><tr><td>name</td><td>AWS Cloud Provisioning From Previously Unseen City</td></tr><tr><td>id</td><td>344a1778-0b25-490c-adb1-de8beddf59cd</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-03-16</td></tr><tr><td>description</td><td>This search looks for AWS provisioning activities from previously unseen cities.  Provisioning activities are defined broadly as any event that begins with "Run" or "Create." </td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search City=* [search `cloudtrail` (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search City=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by City | eval newCity=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newCity=1 | table City] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, City, eventName, errorCode | `aws_cloud_provisioning_from_previously_unseen_city_filter`</td></tr><tr><td>known_false_positives</td><td>This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new city is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your city, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Suspicious Provisioning Activities'], 'mitre_attack_id': ['T1535'], 'cis20': ['CIS 1'], 'nist': ['ID.AM'], 'security_domain': 'endpoint', 'asset_type': 'AWS Instance', 'risk_score': 25, 'risk_object_type': 'user', 'risk_object': 'user'}</td></tr></table>
<h4>kubernetes_azure_detect_most_active_service_accounts_by_pod_namespace.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-05-26</td></tr><tr><td>description</td><td>This search provides information on Kubernetes service accounts,accessing pods and namespaces by IP address and verb</td></tr><tr><td>how_to_implement</td><td>You must install the Add-on for Microsoft Cloud Services and Configure Kube-Audit data diagnostics</td></tr><tr><td>id</td><td>55a2264a-b7f0-45e5-addd-1e5ab3415c72</td></tr><tr><td>known_false_positives</td><td>Not all service accounts interactions are malicious. Analyst must consider IP and verb context when trying to detect maliciousness.</td></tr><tr><td>name</td><td>Kubernetes Azure detect most active service accounts by pod namespace</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`kubernetes_azure` category=kube-audit | spath input=properties.log | search user.groups{}=system:serviceaccounts* OR user.username=system.anonymous OR annotations.authorization.k8s.io/decision=allow  | table  sourceIPs{} user.username userAgent verb responseStatus.reason responseStatus.status properties.pod objectRef.namespace | top sourceIPs{} user.username verb responseStatus.status properties.pod objectRef.namespace |`kubernetes_azure_detect_most_active_service_accounts_by_pod_namespace_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Role Activity'], 'asset_type': 'Azure AKS Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>detect_new_open_s3_buckets.yml</h4>

<table><tr><td>name</td><td>Detect New Open S3 buckets</td></tr><tr><td>id</td><td>2a9b80d3-6340-4345-b5ad-290bf3d0dac4</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-07-25</td></tr><tr><td>description</td><td>This search looks for CloudTrail events where a user has created an open/public S3 bucket.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), and then configure your CloudTrail inputs. The threshold value should be tuned to your environment.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` AllUsers eventName=PutBucketAcl | spath output=userIdentityArn path=userIdentity.arn | spath output=bucketName path=requestParameters.bucketName | spath output=aclControlList path=requestParameters.AccessControlPolicy.AccessControlList | spath input=aclControlList output=grantee path=Grant{} | mvexpand grantee | spath input=grantee | search Grantee.URI=*AllUsers | rename userIdentityArn as user| table _time, src,awsRegion Permission, Grantee.URI, bucketName, user | `detect_new_open_s3_buckets_filter`</td></tr><tr><td>known_false_positives</td><td>While this search has no known false positives, it is possible that an AWS admin has legitimately created a public bucket for a specific purpose. That said, AWS strongly advises against granting full control to the "All Users" group.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious AWS S3 Activities'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1530'], 'cis20': ['CIS 13'], 'nist': ['PR.DS', 'PR.AC', 'DE.CM'], 'security_domain': 'network', 'asset_type': 'S3 Bucket'}</td></tr></table>
<h4>gcp_detect_oauth_token_abuse.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-09-01</td></tr><tr><td>description</td><td>This search provides detection of possible GCP Oauth token abuse. GCP Oauth token without time limit can be exfiltrated and reused for keeping access sessions alive without further control of authentication, allowing attackers to access and move laterally.</td></tr><tr><td>how_to_implement</td><td>You must install splunk GCP add-on. This search works with gcp:pubsub:message logs</td></tr><tr><td>id</td><td>a7e9f7bb-8901-4ad0-8d88-0a4ab07b1972</td></tr><tr><td>known_false_positives</td><td>GCP Oauth token abuse detection will only work if there are access policies in place along with audit logs.</td></tr><tr><td>name</td><td>gcp detect oauth token abuse</td></tr><tr><td>references</td><td>['https://www.netskope.com/blog/gcp-oauth-token-hijacking-in-google-cloud-part-1', 'https://www.netskope.com/blog/gcp-oauth-token-hijacking-in-google-cloud-part-2']</td></tr><tr><td>search</td><td>`google_gcp_pubsub_message` type.googleapis.com/google.cloud.audit.AuditLog |table protoPayload.@type protoPayload.status.details{}.@type protoPayload.status.details{}.violations{}.callerIp protoPayload.status.details{}.violations{}.type protoPayload.status.message  | `gcp_detect_oauth_token_abuse_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['GCP Cross Account Activity'], 'asset_type': 'GCP Account', 'kill_chain_phases': ['Lateral Movement'], 'mitre_attack_id': ['T1078'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>detect_new_user_aws_console_login.yml</h4>

<table><tr><td>name</td><td>Detect new user AWS Console Login</td></tr><tr><td>id</td><td>ada0f478-84a8-4641-a3f3-d82362dffd75</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen users in CloudTrail" support search only once to create a baseline of previously seen IAM users within the last 30 days. Run "Update previously seen users in CloudTrail" hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` eventName=ConsoleLogin | rename userIdentity.arn as user | stats earliest(_time) as firstTime latest(_time) as lastTime by user | inputlookup append=t previously_seen_users_console_logins.csv  | stats min(firstTime) as firstTime max(lastTime) as lastTime by user | eval userStatus=if(firstTime >= relative_time(now(), "-70m@m"), "First Time Logging into AWS Console","Previously Seen User") | `security_content_ctime(firstTime)`|`security_content_ctime(lastTime)`| where userStatus ="First Time Logging into AWS Console"  | `detect_new_user_aws_console_login_filter`</td></tr><tr><td>known_false_positives</td><td>When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious AWS Login Activities'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1078.004'], 'cis20': ['CIS 16'], 'nist': ['DE.DP', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>kubernetes_azure_scan_fingerprint.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-05-19</td></tr><tr><td>description</td><td>This search provides information of unauthenticated requests via source IP user agent, request URI and response status data against Kubernetes cluster in Azure</td></tr><tr><td>how_to_implement</td><td>You must install the Add-on for Microsoft Cloud Services and Configure Kube-Audit data diagnostics</td></tr><tr><td>id</td><td>c5e5bd5c-1013-4841-8b23-e7b3253c840a</td></tr><tr><td>known_false_positives</td><td>Not all unauthenticated requests are malicious, but source IPs, userAgent, verb, request URI and response status will provide context.</td></tr><tr><td>name</td><td>Kubernetes Azure scan fingerprint</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`kubernetes_azure` category=kube-audit | spath input=properties.log | search responseStatus.code=401 | table  sourceIPs{} userAgent verb requestURI responseStatus.reason |`kubernetes_azure_scan_fingerprint_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Scanning Activity'], 'asset_type': 'Azure AKS Kubernetes cluster', 'kill_chain_phases': ['Reconnaissance'], 'mitre_attack_id': ['T1526'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>detect_new_api_calls_from_user_roles.yml</h4>

<table><tr><td>name</td><td>Detect new API calls from user roles</td></tr><tr><td>id</td><td>22773e84-bac0-4595-b086-20d3f335b4f1</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-04-16</td></tr><tr><td>description</td><td>This search detects new API calls that have either never been seen before or that have not been seen in the previous hour, where the identity type is `AssumedRole`.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously seen API call per user roles in CloudTrail" support search once to create a history of previously seen user roles.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` eventType=AwsApiCall errorCode=success userIdentity.type=AssumedRole [search `cloudtrail` eventType=AwsApiCall errorCode=success  userIdentity.type=AssumedRole | stats earliest(_time) as earliest latest(_time) as latest by userName eventName |  inputlookup append=t previously_seen_api_calls_from_user_roles | stats min(earliest) as earliest, max(latest) as latest by userName eventName | outputlookup previously_seen_api_calls_from_user_roles| eval newApiCallfromUserRole=if(earliest>=relative_time(now(), "-70m@m"), 1, 0) | where newApiCallfromUserRole=1 | `security_content_ctime(earliest)` | `security_content_ctime(latest)` | table eventName userName]  |rename userName as user| stats values(eventName) earliest(_time) as earliest latest(_time) as latest by user | `security_content_ctime(earliest)` | `security_content_ctime(latest)` | `detect_new_api_calls_from_user_roles_filter`</td></tr><tr><td>known_false_positives</td><td>It is possible that there are legitimate user roles making new or infrequently used API calls in your infrastructure, causing the search to trigger.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS User Monitoring'], 'mitre_attack_id': ['T1078.004'], 'cis20': ['CIS 1'], 'nist': ['ID.AM'], 'security_domain': 'endpoint', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>aws_network_access_control_list_created_with_all_open_ports.yml</h4>

<table><tr><td>name</td><td>AWS Network Access Control List Created with All Open Ports</td></tr><tr><td>id</td><td>ada0f478-84a8-4641-a3f1-d82362d6bd75</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-01-10</td></tr><tr><td>description</td><td>The search looks for CloudTrail events to detect if any network ACLs were created with all the ports open to a specified CIDR.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS, version 4.4.0 or later, and configure your CloudTrail inputs.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` eventName=CreateNetworkAclEntry | mvexpand requestParameters | mvexpand responseElements | search requestParameters.portRange.from=1024 requestParameters.portRange.to=65535 requestParameters.ruleAction=allow | rename userIdentity.arn as arn | rename requestParameters.networkAclId as networkAclId | table _time aws_account_id src userName arn networkAclId requestParameters.* responseElements.* | `aws_network_access_control_list_created_with_all_open_ports_filter`</td></tr><tr><td>known_false_positives</td><td>It's possible that an admin has created this ACL with all ports open for some legitimate purpose however, this should be scoped and not allowed in production environment.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Network ACL Activity'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 11'], 'nist': ['DE.DP', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>aws_detect_sts_assume_role_abuse.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-07-27</td></tr><tr><td>description</td><td>This search provides detection of suspicious use of sts:AssumeRole. These tokens can be created on the go and used by attackers to move laterally and escalate privileges.</td></tr><tr><td>how_to_implement</td><td>You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs</td></tr><tr><td>id</td><td>8e565314-b6a2-46d8-9f05-1a34a176a662</td></tr><tr><td>known_false_positives</td><td>Sts:AssumeRole can be very noisy as it is a standard mechanism to provide cross account and cross resources access. This search can be adjusted to provide specific values to identify cases of abuse.</td></tr><tr><td>name</td><td>aws detect sts assume role abuse</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`cloudtrail` user_type=AssumedRole userIdentity.sessionContext.sessionIssuer.type=Role | table sourceIPAddress userIdentity.arn user_agent user_access_key status action requestParameters.roleName responseElements.role.roleName responseElements.role.createDate | `aws_detect_sts_assume_role_abuse_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Cross Account Activity'], 'asset_type': 'AWS Account', 'kill_chain_phases': ['Lateral Movement'], 'mitre_attack_id': ['T1078'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>kubernetes_gcp_detect_RBAC_authorizations_by_account.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-07-11</td></tr><tr><td>description</td><td>This search provides information on Kubernetes RBAC authorizations by accounts, this search can be modified by adding top to see both extremes of RBAC by accounts occurrences</td></tr><tr><td>how_to_implement</td><td>You must install splunk AWS add on for GCP. This search works with pubsub messaging service logs</td></tr><tr><td>id</td><td>99487de3-7192-4b41-939d-fbe9acfb1340</td></tr><tr><td>known_false_positives</td><td>Not all RBAC Authorications are malicious. RBAC authorizations can uncover malicious activity specially if sensitive Roles have been granted.</td></tr><tr><td>name</td><td>Kubernetes GCP detect RBAC authorizations by account</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`google_gcp_pubsub_message` data.labels.authorization.k8s.io/reason=ClusterRoleBinding OR Clusterrole  | table src_ip src_user data.labels.authorization.k8s.io/decision data.labels.authorization.k8s.io/reason | rare src_user data.labels.authorization.k8s.io/reason |`kubernetes_gcp_detect_rbac_authorizations_by_account_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Role Activity'], 'asset_type': 'GCP GKE Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>aws_detect_permanent_key_creation.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-07-27</td></tr><tr><td>description</td><td>This search provides detection of accounts creating permanent keys. Permanent keys are not created by default and they are only needed for programmatic calls. Creation of Permanent key is an important event to monitor.</td></tr><tr><td>how_to_implement</td><td>You must install splunk AWS add on and Splunk App for AWS. This search works with cloudwatch logs</td></tr><tr><td>id</td><td>12d6d713-3cb4-4ffc-a064-1dca3d1cca01</td></tr><tr><td>known_false_positives</td><td>Not all permanent key creations are malicious. If there is a policy of rotating keys this search can be adjusted to provide better context.</td></tr><tr><td>name</td><td>aws detect permanent key creation</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`aws_cloudwatchlogs_eks` CreateAccessKey | spath eventName | search eventName=CreateAccessKey "userIdentity.type"=IAMUser | table sourceIPAddress userName userIdentity.type userAgent action status responseElements.accessKey.createDate responseElements.accessKey.status responseElements.accessKey.accessKeyId |`aws_detect_permanent_key_creation_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Cross Account Activity'], 'asset_type': 'AWS Account', 'kill_chain_phases': ['Lateral Movement'], 'mitre_attack_id': ['T1078'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>kubernetes_azure_detect_rbac_authorization_by_account.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-05-26</td></tr><tr><td>description</td><td>This search provides information on Kubernetes RBAC authorizations by accounts, this search can be modified by adding rare or top to see both extremes of RBAC by accounts occurrences</td></tr><tr><td>how_to_implement</td><td>You must install the Add-on for Microsoft Cloud Services and Configure Kube-Audit data diagnostics</td></tr><tr><td>id</td><td>47af7d20-0607-4079-97d7-7a29af58b54e</td></tr><tr><td>known_false_positives</td><td>Not all RBAC Authorications are malicious. RBAC authorizations can uncover malicious activity specially if sensitive Roles have been granted.</td></tr><tr><td>name</td><td>Kubernetes Azure detect RBAC authorization by account</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>sourcetype:mscs:storage:blob:json category=kube-audit | spath input=properties.log | search annotations.authorization.k8s.io/reason=* | table sourceIPs{} user.username userAgent annotations.authorization.k8s.io/reason |stats count by user.username annotations.authorization.k8s.io/reason | rare user.username annotations.authorization.k8s.io/reason |`kubernetes_azure_detect_rbac_authorization_by_account_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Role Activity'], 'asset_type': 'Azure AKS Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>kubernetes_gcp_detect_service_accounts_forbidden_failure_access.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-06-23</td></tr><tr><td>description</td><td>This search provides information on Kubernetes service accounts with failure or forbidden access status, this search can be extended by using top or rare operators to find trends or rarities in failure status, user agents, source IPs and request URI</td></tr><tr><td>how_to_implement</td><td>You must install splunk add on for GCP. This search works with pubsub messaging service logs.</td></tr><tr><td>id</td><td>7094808d-432a-48e7-bb3c-77e96c894f3b</td></tr><tr><td>known_false_positives</td><td>This search can give false positives as there might be inherent issues with authentications and permissions at cluster.</td></tr><tr><td>name</td><td>Kubernetes GCP detect service accounts forbidden failure access</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`google_gcp_pubsub_message` system:serviceaccounts data.protoPayload.response.status.allowed!=* | table src_ip src_user http_user_agent data.protoPayload.response.spec.resourceAttributes.namespace data.resource.labels.cluster_name data.protoPayload.response.spec.resourceAttributes.verb  data.protoPayload.request.status.allowed data.protoPayload.response.status.reason data.labels.authorization.k8s.io/decision | dedup src_ip src_user | `kubernetes_gcp_detect_service_accounts_forbidden_failure_access_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Object Access Activity'], 'asset_type': 'GCP GKE Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>ec2_instance_started_in_previously_unseen_region.yml</h4>

<table><tr><td>name</td><td>EC2 Instance Started In Previously Unseen Region</td></tr><tr><td>id</td><td>ada0f478-84a8-4641-a3f3-d82362d6fd75</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-02-23</td></tr><tr><td>description</td><td>This search looks for CloudTrail events where an instance is started in a particular region in the last one hour and then compares it to a lookup file of previously seen regions where an instance was started</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen AWS Regions" support search only once to create of baseline of previously seen regions.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>`cloudtrail` earliest=-1h StartInstances | stats earliest(_time) as earliest latest(_time) as latest by awsRegion | inputlookup append=t previously_seen_aws_regions.csv | stats min(earliest) as earliest max(latest) as latest by awsRegion | outputlookup previously_seen_aws_regions.csv | eval regionStatus=if(earliest >= relative_time(now(),"-1d@d"), "Instance Started in a New Region","Previously Seen Region") | `security_content_ctime(earliest)` | `security_content_ctime(latest)` | where regionStatus="Instance Started in a New Region" | `ec2_instance_started_in_previously_unseen_region_filter`</td></tr><tr><td>known_false_positives</td><td>It's possible that a user has unknowingly started an instance in a new region. Please verify that this activity is legitimate.</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Cryptomining', 'Suspicious AWS EC2 Activities'], 'kill_chain_phases': ['Actions on Objectives'], 'mitre_attack_id': ['T1535'], 'cis20': ['CIS 12'], 'nist': ['DE.DP', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'AWS Instance'}</td></tr></table>
<h4>kubernetes_azure_detect_suspicious_kubectl_calls.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-05-26</td></tr><tr><td>description</td><td>This search provides information on rare Kubectl calls with IP, verb namespace and object access context</td></tr><tr><td>how_to_implement</td><td>You must install the Add-on for Microsoft Cloud Services and Configure Kube-Audit data diagnostics</td></tr><tr><td>id</td><td>4b6d1ba8-0000-4cec-87e6-6cbbd71651b5</td></tr><tr><td>known_false_positives</td><td>Kubectl calls are not malicious by nature. However source IP, verb and Object can reveal potential malicious activity, specially suspicious IPs and sensitive objects such as configmaps or secrets</td></tr><tr><td>name</td><td>Kubernetes Azure detect suspicious kubectl calls</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`kubernetes_azure` category=kube-audit | spath input=properties.log | spath input=responseObject.metadata.annotations.kubectl.kubernetes.io/last-applied-configuration | search userAgent=kubectl* sourceIPs{}!=127.0.0.1 sourceIPs{}!=::1 | table sourceIPs{} verb userAgent user.groups{} objectRef.resource objectRef.namespace requestURI | rare sourceIPs{} verb userAgent user.groups{} objectRef.resource objectRef.namespace requestURI|`kubernetes_azure_detect_suspicious_kubectl_calls_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Object Access Activity'], 'asset_type': 'Azure AKS Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>kubernetes_gcp_detect_sensitive_role_access.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-07-11</td></tr><tr><td>description</td><td>This search provides information on Kubernetes accounts accessing sensitve objects such as configmpas or secrets</td></tr><tr><td>how_to_implement</td><td>You must install splunk add on for GCP. This search works with pubsub messaging servicelogs.</td></tr><tr><td>id</td><td>a46923f6-36b9-4806-a681-31f314907c30</td></tr><tr><td>known_false_positives</td><td>Sensitive role resource access is necessary for cluster operation, however source IP, user agent, decision and reason may indicate possible malicious use. </td></tr><tr><td>name</td><td>Kubernetes GCP detect sensitive role access</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`google_gcp_pubsub_message` data.labels.authorization.k8s.io/reason=ClusterRoleBinding OR Clusterrole dest=apis/rbac.authorization.k8s.io/v1 src_ip!=::1  | table src_ip src_user http_user_agent data.labels.authorization.k8s.io/decision data.labels.authorization.k8s.io/reason | dedup src_ip src_user |`kubernetes_gcp_detect_sensitive_role_access_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Role Activity'], 'asset_type': 'GCP GKE EKS Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>gcp_gcr_container_uploaded.yml</h4>

<table><tr><td>name</td><td>GCP GCR container uploaded</td></tr><tr><td>id</td><td>4f00ca88-e766-4605-ac65-ae51c9fd185b</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-02-20</td></tr><tr><td>description</td><td>This search show information on uploaded containers including source user, account, action, bucket name event name, http user agent, message and destination path.</td></tr><tr><td>how_to_implement</td><td>You must install the GCP App for Splunk (version 2.0.0 or later), then configure stackdriver and set a subpub subscription to be imported to Splunk. You must also install Cloud Infrastructure data model. Please also customize the `container_implant_gcp_detection_filter` macro to filter out the false positives.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rod Soto, Rico Valdez, Splunk</td></tr><tr><td>search</td><td>|tstats count min(_time) as firstTime max(_time) as lastTime  FROM datamodel=Cloud_Infrastructure.Storage where Storage.event_name=storage.objects.create by Storage.src_user Storage.account Storage.action Storage.bucket_name Storage.event_name Storage.http_user_agent Storage.msg Storage.object_path | `drop_dm_object_name("Storage")`  | `gcp_gcr_container_uploaded_filter` </td></tr><tr><td>known_false_positives</td><td>Uploading container is a normal behavior from developers or users with access to container registry. GCP GCR registers container upload as a Storage event, this search must be considered under the context of CONTAINER upload creation which automatically generates a bucket entry for destination path.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Container Implantation Monitoring and Investigation'], 'security_domain': 'threat', 'asset_type': 'GCP GCR Container', 'mitre_attack_id': ['T1525']}</td></tr></table>
<h4>new_container_uploaded_to_aws_ecr.yml</h4>

<table><tr><td>name</td><td>New container uploaded to AWS ECR</td></tr><tr><td>id</td><td>f0f70b40-f7ad-489d-9905-23d149da8099</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-02-20</td></tr><tr><td>description</td><td>This searches show information on uploaded containers including source user, image id, source IP user type, http user agent, region, first time, last time of operation (PutImage). These searches are based on Cloud Infrastructure Data Model.</td></tr><tr><td>how_to_implement</td><td>You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You must also install Cloud Infrastructure data model. Please also customize the `container_implant_aws_detection_filter` macro to filter out the false positives.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rod Soto, Rico Valdez, Splunk</td></tr><tr><td>search</td><td>| tstats count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Cloud_Infrastructure.Compute where Compute.user_type!="AssumeRole" AND Compute.http_user_agent="AWS Internal" AND Compute.event_name="PutImage" by Compute.image_id Compute.src_user Compute.src Compute.region Compute.msg Compute.user_type | `drop_dm_object_name("Compute")` | `new_container_uploaded_to_aws_ecr_filter` </td></tr><tr><td>known_false_positives</td><td>Uploading container is a normal behavior from developers or users with access to container registry.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Container Implantation Monitoring and Investigation'], 'security_domain': 'threat', 'asset_type': 'AWS ECR container', 'mitre_attack_id': ['T1525']}</td></tr></table>
<h4>gcp_kubernetes_cluster_pod_scan_detection.yml</h4>

<table><tr><td>name</td><td>GCP Kubernetes cluster pod scan detection</td></tr><tr><td>id</td><td>19b53215-4a16-405b-8087-9e6acf619842</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-07-17</td></tr><tr><td>description</td><td>This search provides information of unauthenticated requests via user agent, and authentication data against Kubernetes cluster's pods</td></tr><tr><td>how_to_implement</td><td>You must install the GCP App for Splunk (version 2.0.0 or later), then configure stackdriver and set a Pub/Sub subscription to be imported to Splunk.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>search</td><td>`google_gcp_pubsub_message` category=kube-audit |spath input=properties.log |search responseStatus.code=401 |table sourceIPs{} userAgent verb requestURI responseStatus.reason properties.pod | `gcp_kubernetes_cluster_pod_scan_detection_filter`</td></tr><tr><td>known_false_positives</td><td>Not all unauthenticated requests are malicious, but frequency, User Agent, source IPs and pods  will provide context.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Scanning Activity'], 'kill_chain_phases': ['Reconnaissance'], 'mitre_attack_id': ['T1526'], 'security_domain': 'threat', 'asset_type': 'GCP Kubernetes cluster'}</td></tr></table>
<h4>kubernetes_aws_detect_most_active_service_accounts_by_pod.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-06-23</td></tr><tr><td>description</td><td>This search provides information on Kubernetes service accounts,accessing pods by IP address, verb and decision</td></tr><tr><td>how_to_implement</td><td>You must install splunk AWS add on and Splunk App for AWS. This search works with cloudwatch logs</td></tr><tr><td>id</td><td>5b30b25d-7d32-42d8-95ca-64dfcd9076e6</td></tr><tr><td>known_false_positives</td><td>Not all service accounts interactions are malicious. Analyst must consider IP, verb and decision context when trying to detect maliciousness.</td></tr><tr><td>name</td><td>Kubernetes AWS detect most active service accounts by pod</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`aws_cloudwatchlogs_eks` user.groups{}=system:serviceaccounts  objectRef.resource=pods | table  sourceIPs{} user.username userAgent verb annotations.authorization.k8s.io/decision  | top  sourceIPs{} user.username verb annotations.authorization.k8s.io/decision |`kubernetes_aws_detect_most_active_service_accounts_by_pod_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['Kubernetes Sensitive Role Activity'], 'asset_type': 'AWS EKS Kubernetes cluster', 'kill_chain_phases': ['Lateral Movement'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>
<h4>aws_detect_role_creation.yml</h4>

<table><tr><td>author</td><td>Rod Soto, Splunk</td></tr><tr><td>date</td><td>2020-07-27</td></tr><tr><td>description</td><td>This search provides detection of role creation by IAM users. Role creation is an event by itself if user is creating a new role with trust policies different than the available in AWS and it can be used for lateral movement and escalation of privileges.</td></tr><tr><td>how_to_implement</td><td>You must install splunk AWS add-on and Splunk App for AWS. This search works with cloudwatch logs</td></tr><tr><td>id</td><td>5f04081e-ddee-4353-afe4-504f288de9ad</td></tr><tr><td>known_false_positives</td><td>CreateRole is not very common in common users. This search can be adjusted to provide specific values to identify cases of abuse. In general AWS provides plenty of trust policies that fit most use cases.</td></tr><tr><td>name</td><td>aws detect role creation</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>search</td><td>`aws_cloudwatchlogs_eks` event_name=CreateRole action=created userIdentity.type=AssumedRole requestParameters.description=Allows* | table sourceIPAddress userIdentity.principalId userIdentity.arn action event_name awsRegion http_user_agent mfa_auth msg requestParameters.roleName requestParameters.description responseElements.role.arn responseElements.role.createDate | `aws_detect_role_creation_filter`</td></tr><tr><td>tags</td><td>{'analytics_story': ['AWS Cross Account Activity'], 'asset_type': 'AWS Account', 'kill_chain_phases': ['Lateral Movement'], 'mitre_attack_id': ['T1078'], 'security_domain': 'threat'}</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>version</td><td>1</td></tr></table>

<h2>application</h2>


<h4>okta_account_lockout_events.yml</h4>

<table><tr><td>name</td><td>Okta Account Lockout Events</td></tr><tr><td>id</td><td>62b70968-a0a5-4724-8ac4-67871e6f544d</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>Detect Okta user lockout events</td></tr><tr><td>how_to_implement</td><td>This search is specific to Okta and requires Okta logs are being ingested in your Splunk deployment.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>`okta` displayMessage="Max sign in attempts exceeded" | rename client.geographicalContext.country as country, client.geographicalContext.state as state, client.geographicalContext.city as city | table _time, user, country, state, city, src_ip | `okta_account_lockout_events_filter` </td></tr><tr><td>known_false_positives</td><td>None. Account lockouts should be followed up on to determine if the actual user was the one who caused the lockout, or if it was an unauthorized actor.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious Okta Activity'], 'mitre_attack_id': ['T1078.001'], 'cis20': ['CIS 16'], 'nist': ['DE.CM'], 'security_domain': 'access', 'asset_type': 'Infrastructure'}</td></tr></table>
<h4>monitor_email_for_brand_abuse.yml</h4>

<table><tr><td>name</td><td>Monitor Email For Brand Abuse</td></tr><tr><td>id</td><td>b2ea1f38-3a3e-4b8a-9cf1-82760d86a6b8</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2018-01-05</td></tr><tr><td>description</td><td>This search looks for emails claiming to be sent from a domain similar to one that you want to have monitored for abuse.</td></tr><tr><td>how_to_implement</td><td>You need to ingest email header data. Specifically the sender's address (src_user) must be populated.  You also need to have run the search "ESCU - DNSTwist Domain Names", which creates the permutations of the domain that will be checked for.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` values(All_Email.recipient) as recipients, min(_time) as firstTime, max(_time) as lastTime from datamodel=Email by All_Email.src_user, All_Email.message_id | `drop_dm_object_name("All_Email")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | eval temp=split(src_user, "@") | eval email_domain=mvindex(temp, 1) | lookup update=true brandMonitoring_lookup domain as email_domain OUTPUT domain_abuse | search domain_abuse=true | table message_id, src_user, email_domain, recipients, firstTime, lastTime | `monitor_email_for_brand_abuse_filter`</td></tr><tr><td>known_false_positives</td><td>None at this time</td></tr><tr><td>tags</td><td>{'analytics_story': ['Brand Monitoring', 'Suspicious Emails'], 'kill_chain_phases': ['Delivery'], 'cis20': ['CIS 7'], 'nist': ['PR.IP'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>multiple_okta_users_with_invalid_credentails_from_the_same_ip.yml</h4>

<table><tr><td>name</td><td>Multiple Okta Users With Invalid Credentails From The Same IP</td></tr><tr><td>id</td><td>19cba45f-cad3-4032-8911-0c09e0444552</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search detects Okta login failures due to bad credentials for multiple users originating from the same ip address.</td></tr><tr><td>how_to_implement</td><td>This search is specific to Okta and requires Okta logs are being ingested in your Splunk deployment.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>`okta` outcome.reason=INVALID_CREDENTIALS | rename client.geographicalContext.country as country, client.geographicalContext.state as state, client.geographicalContext.city as city | stats min(_time) as firstTime max(_time) as lastTime dc(user) as distinct_users values(user) as users by src_ip, displayMessage, outcome.reason, country, state, city  | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` |  search distinct_users > 5| `multiple_okta_users_with_invalid_credentails_from_the_same_ip_filter` </td></tr><tr><td>known_false_positives</td><td>A single public IP address servicing multiple legitmate users may trigger this search. In addition, the threshold of 5 distinct users may be too low for your needs. You may modify the included filter macro XXXXXXXXXXXXX to raise the threshold or except specific IP adresses from triggering this search.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious Okta Activity'], 'mitre_attack_id': ['T1078.001'], 'cis20': ['CIS 16'], 'nist': ['DE.CM'], 'security_domain': 'access', 'asset_type': 'Infrastructure'}</td></tr></table>
<h4>open_redirect_in_splunk_web.yml</h4>

<table><tr><td>name</td><td>Open Redirect in Splunk Web</td></tr><tr><td>id</td><td>d199fb99-2312-451a-9daa-e5efa6ed76a7</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-09-19</td></tr><tr><td>description</td><td>This search allows you to look for evidence of exploitation for CVE-2016-4859, the Splunk Open Redirect Vulnerability.</td></tr><tr><td>how_to_implement</td><td>No extra steps needed to implement this search.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>index=_internal sourcetype=splunk_web_access return_to="/%09/*" | `open_redirect_in_splunk_web_filter`</td></tr><tr><td>known_false_positives</td><td>None identified</td></tr><tr><td>tags</td><td>{'analytics_story': ['Splunk Enterprise Vulnerability'], 'kill_chain_phases': ['Delivery'], 'cis20': ['CIS 3', 'CIS 4', 'CIS 18'], 'nist': ['ID.RA', 'RS.MI', 'PR.PT', 'PR.AC', 'PR.IP', 'DE.CM'], 'security_domain': 'network', 'asset_type': 'Splunk Server'}</td></tr></table>
<h4>identify_new_user_accounts.yml</h4>

<table><tr><td>name</td><td>Identify New User Accounts</td></tr><tr><td>id</td><td>475b9e27-17e4-46e2-b7e2-648221be3b89</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-09-12</td></tr><tr><td>description</td><td>This detection search will help profile user accounts in your environment by identifying newly created accounts that have been added to your network in the past week.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you need to be populating the Enterprise Security Identity_Management data model in the assets and identity framework.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| from datamodel Identity_Management.All_Identities  | eval empStatus=case((now()-startDate)<604800, "Accounts created in last week") | search empStatus="Accounts created in last week"| `security_content_ctime(endDate)` | `security_content_ctime(startDate)`| table identity empStatus endDate startDate | `identify_new_user_accounts_filter`</td></tr><tr><td>known_false_positives</td><td>If the Identity_Management data model is not updated regularly, this search could give you false positive alerts. Please consider this and investigate appropriately.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Account Monitoring and Controls'], 'mitre_attack_id': ['T1078.002'], 'cis20': ['CIS 16'], 'nist': ['PR.IP'], 'security_domain': 'access', 'asset_type': 'Domain Server'}</td></tr></table>
<h4>detect_phishing_content___ssa.yml</h4>

<table><tr><td>name</td><td>Phishing Email Detection by Machine Learning Method - SSA</td></tr><tr><td>id</td><td>4b237388-dfa1-41a6-91d4-4de2d598376f</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2020-08-25</td></tr><tr><td>description</td><td>Malicious mails can conduct phishing that induces readers to open attachment, click links or trigger third party service. This detect uses Natural Language Processing (NLP) approach to analyze an email message's content (Sender, Subject and Body) and judge whether it is a phishing email. The detection adopts a deep learning (neural network) model that employs character level embeddings plus LSTM layers to perform classification. The model is pre-trained and then published as ONNX format. Current sample model is trained using the dataset published at https://github.com/splunk/attack_data/tree/master/datasets/T1566_Phishing_Email/splunk_train.json User are expected to re-train the model by combining with their own training data for better accuracy using the provided model file (SMLE notebook). DSP pipeline then processes the email message and passes it as an event to Apply ML Models function, which returns the probability of a phishing email. Current implementation assumes the email is fed to DSP in JSON format contains at least email's sender, subject and its message body, including reply content, if any.</td></tr><tr><td>how_to_implement</td><td>Events are fed to DSP contains at least email's sender, subject and its message body.</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>type</td><td>SSA</td></tr><tr><td>author</td><td>Xiao Lin, Splunk</td></tr><tr><td>search</td><td>| from read_ssa_enriched_events() | where source_type="email" | eval strJsn=cast(body, "string"), jsonMap=from_json_object(strJsn), eventLine=concat(ucast(map_get(jsonMap, "From"), "string", " "), " ", ucast(map_get(jsonMap, "Subject"), "string", " "), " ", ucast(map_get(jsonMap, "Content"), "string", " "), "                                                                                                                                "), Date=ucast(map_get(jsonMap, "Date"), "string", " NA") | where eventLine IS NOT NULL | eval mapC={" ": 32, "!": 33, "\"": 34, "#": 35, "$": 36, "%": 37, "&": 38, "`": 39, "(": 40, ")": 41, "*": 42, "+": 43, ",": 44, "-": 45, ".": 46, "/": 47, "0": 48, "1": 49, "2": 50, "3": 51, "4": 52, "5": 53, "6": 54, "7": 55, "8": 56, "9": 57, ":": 58, ";": 59, "<": 60, "=": 61, ">": 62, "?": 63, "@": 64, "A": 65, "B": 66, "C": 67, "D": 68, "E": 69, "F": 70, "G": 71, "H": 72, "I": 73, "J": 74, "K": 75, "L": 76, "M": 77, "N": 78, "O": 79, "P": 80, "Q": 81, "R": 82, "S": 83, "T": 84, "U": 85, "V": 86, "W": 87, "X": 88, "Y": 89, "Z": 90, "[": 91, "\\": 92, "]": 93, "^": 94, "_": 95, "`": 96, "a": 97, "b": 98, "c": 99, "d": 100, "e": 101, "f": 102, "g": 103, "h": 104, "i": 105, "j": 106, "k": 107, "l": 108, "m": 109, "n": 110, "o": 111, "p": 112, "q": 113, "r": 114, "s": 115, "t": 116, "u": 117, "v": 118, "w": 119, "x": 120, "y": 121, "z": 122, "{": 123, "|": 124, "}": 125, "~": 126}, `embedding_input:0` = for_each(iterator(mvrange(1,129), "i"), cast(map_get(mapC, substr(eventLine, i, 1)), "float") ) | apply_model connection_id="YOUR_S3_ONNX_CONNECTOR_ID" name="phishing_email_v7" path="s3://smle-experiments/models/phishing_email" | eval probability = mvindex(`dense/Sigmoid:0`, 0) | where probability > 0.5 | eval start_time=Date, end_time=Date, entities="TBD", body="TBD" | select probability, body, entities, start_time, end_time | into write_ssa_detected_events();</td></tr><tr><td>known_false_positives</td><td>Because of imbalance of anomaly data in training, the model will less likely report false positive. Instead, the model is more prone to false negative. Current best recall score is ~85%</td></tr><tr><td>tags</td><td>{'kill_chain_phases': ['Actions on Objectives'], 'mitre_technique_id': ['T1566'], 'cis20': ['CIS 8'], 'nist': ['PR.PT', 'DE.CM'], 'risk_severity': 'low', 'security_domain': 'mail server'}</td></tr></table>
<h4>detect_new_login_attempts_to_routers.yml</h4>

<table><tr><td>name</td><td>Detect New Login Attempts to Routers</td></tr><tr><td>id</td><td>104658f4-afdc-499e-9719-17243rr826f1</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-09-12</td></tr><tr><td>description</td><td>The search queries the authentication logs for assets that are categorized as routers in the ES Assets and Identity Framework, to identify connections that have not been seen before in the last 30 days.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must ensure the network router devices are categorized as "router" in the Assets and identity table. You must also populate the Authentication data model with logs related to users authenticating to routing infrastructure.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count earliest(_time) as earliest latest(_time) as latest from datamodel=Authentication where Authentication.dest_category=router by Authentication.dest Authentication.user| eval isOutlier=if(earliest >= relative_time(now(), "-30d@d"), 1, 0) | where isOutlier=1| `security_content_ctime(earliest)`| `security_content_ctime(latest)` | `drop_dm_object_name("Authentication")` | `detect_new_login_attempts_to_routers_filter`</td></tr><tr><td>known_false_positives</td><td>Legitimate router connections may appear as new connections</td></tr><tr><td>tags</td><td>{'analytics_story': ['Router and Infrastructure Security'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 11'], 'nist': ['PR.PT', 'PR.AC', 'PR.IP'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>email_files_written_outside_of_the_outlook_directory.yml</h4>

<table><tr><td>name</td><td>Email files written outside of the Outlook directory</td></tr><tr><td>id</td><td>ee18ed37-0802-4268-9435-b3b91aaa18xx</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>The search looks at the change-analysis data model and detects email files created outside the normal Outlook directory.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, you must be ingesting data that records the file-system activity from your hosts to populate the Endpoint.Filesystem data model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or by other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file-system reads and writes.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(Filesystem.file_path) as file_path min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Filesystem where (Filesystem.file_name=*.pst OR Filesystem.file_name=*.ost) Filesystem.file_path != "C:\\Users\\*\\My Documents\\Outlook Files\\*"  Filesystem.file_path!="C:\\Users\\*\\AppData\\Local\\Microsoft\\Outlook*" by Filesystem.action Filesystem.process_id Filesystem.file_name Filesystem.dest | `drop_dm_object_name("Filesystem")` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`| `email_files_written_outside_of_the_outlook_directory_filter` </td></tr><tr><td>known_false_positives</td><td>Administrators and users sometimes prefer backing up their email data by moving the email files into a different folder. These attempts will be detected by the search.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Collection and Staging'], 'mitre_attack_id': ['T1114.001'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 8'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>okta_failed_sso_attempts.yml</h4>

<table><tr><td>name</td><td>Okta Failed SSO Attempts</td></tr><tr><td>id</td><td>371a6545-2618-4032-ad84-93386b8698c5</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>Detect failed Okta SSO events</td></tr><tr><td>how_to_implement</td><td>This search is specific to Okta and requires Okta logs are being ingested in your Splunk deployment.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>`okta` displayMessage="User attempted unauthorized access to app" | stats  min(_time) as firstTime max(_time) as lastTime values(app) as Apps count by user, result ,displayMessage, src_ip | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `okta_failed_sso_attempts_filter` </td></tr><tr><td>known_false_positives</td><td>There may be a faulty config preventing legitmate users from accessing apps they should have access to.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious Okta Activity'], 'mitre_attack_id': ['T1078.001'], 'cis20': ['CIS 16'], 'nist': ['DE.CM'], 'security_domain': 'access', 'asset_type': 'Infrastructure'}</td></tr></table>
<h4>suspicious_email_attachment_extensions.yml</h4>

<table><tr><td>name</td><td>Suspicious Email Attachment Extensions</td></tr><tr><td>id</td><td>473bd65f-06ca-4dfe-a2b8-ba04ab4a0084</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-22</td></tr><tr><td>description</td><td>This search looks for emails that have attachments with suspicious file extensions.</td></tr><tr><td>how_to_implement</td><td>You need to ingest data from emails. Specifically, the sender's address and the file names of any attachments must be mapped to the Email data model. \
 **Splunk Phantom Playbook Integration**\
If Splunk Phantom is also configured in your environment, a Playbook called "Suspicious Email Attachment Investigate and Delete" can be configured to run when any results are found by this detection search. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/`, and add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search. The notable event will be sent to Phantom and the playbook will gather further information about the file attachment and its network behaviors. If Phantom finds malicious behavior and an analyst approves of the results, the email will be deleted from the user's inbox.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Email where All_Email.file_name="*" by All_Email.src_user, All_Email.file_name All_Email.message_id | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Email")` | `suspicious_email_attachments` | `suspicious_email_attachment_extensions_filter` </td></tr><tr><td>known_false_positives</td><td>None identified</td></tr><tr><td>tags</td><td>{'analytics_story': ['Emotet Malware  DHS Report TA18-201A ', 'Suspicious Emails'], 'mitre_attack_id': ['T1566.001'], 'kill_chain_phases': ['Delivery'], 'cis20': ['CIS 3', 'CIS 7', 'CIS 12'], 'nist': ['DE.AE', 'PR.IP'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>spectre_and_meltdown_vulnerable_systems.yml</h4>

<table><tr><td>name</td><td>Spectre and Meltdown Vulnerable Systems</td></tr><tr><td>id</td><td>354be8e0-32cd-4da0-8c47-796de13b60ea</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-01-07</td></tr><tr><td>description</td><td>The search is used to detect systems that are still vulnerable to the Spectre and Meltdown vulnerabilities.</td></tr><tr><td>how_to_implement</td><td>The search requires that you are ingesting your vulnerability-scanner data and that it reports the CVE of the vulnerability identified.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` min(_time) as firstTime max(_time) as lastTime from datamodel=Vulnerabilities where Vulnerabilities.cve ="CVE-2017-5753" OR Vulnerabilities.cve ="CVE-2017-5715" OR Vulnerabilities.cve ="CVE-2017-5754" by Vulnerabilities.dest | `drop_dm_object_name(Vulnerabilities)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `spectre_and_meltdown_vulnerable_systems_filter`</td></tr><tr><td>known_false_positives</td><td>It is possible that your vulnerability scanner is not detecting that the patches have been applied.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Spectre And Meltdown Vulnerabilities'], 'cis20': ['CIS 4'], 'nist': ['ID.RA', 'RS.MI', 'PR.IP', 'DE.CM'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>suspicious_email___uba_anomaly.yml</h4>

<table><tr><td>name</td><td>Suspicious Email - UBA Anomaly</td></tr><tr><td>id</td><td>56e877a6-1455-4479-ad16-0550dc1e33f8</td></tr><tr><td>version</td><td>3</td></tr><tr><td>date</td><td>2020-07-22</td></tr><tr><td>description</td><td>This detection looks for emails that are suspicious because of their sender, domain rareness, or behavior differences. This is an anomaly generated by Splunk User Behavior Analytics (UBA).</td></tr><tr><td>how_to_implement</td><td>You must be ingesting data from email logs and have Splunk integrated with UBA. This anomaly is raised by a UBA detection model called  "SuspiciousEmailDetectionModel." Ensure that this model is enabled on your UBA instance.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>|tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime values(All_UEBA_Events.category) as category from datamodel=UEBA where nodename=All_UEBA_Events.UEBA_Anomalies All_UEBA_Events.UEBA_Anomalies.uba_model = "SuspiciousEmailDetectionModel" by All_UEBA_Events.description All_UEBA_Events.severity All_UEBA_Events.user All_UEBA_Events.uba_event_type All_UEBA_Events.link All_UEBA_Events.signature All_UEBA_Events.url All_UEBA_Events.UEBA_Anomalies.uba_model | `drop_dm_object_name(All_UEBA_Events)` | `drop_dm_object_name(UEBA_Anomalies)`| `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `suspicious_email___uba_anomaly_filter`</td></tr><tr><td>known_false_positives</td><td>This detection model will alert on any sender domain that is seen for the first time. This could be a potential false positive. The next step is to investigate and whitelist the URL if you determine that it is a legitimate sender.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious Emails'], 'mitre_attack_id': ['T1566'], 'kill_chain_phases': ['Delivery'], 'cis20': ['CIS 7'], 'nist': ['PR.IP'], 'security_domain': 'threat', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>email_attachments_with_lots_of_spaces.yml</h4>

<table><tr><td>name</td><td>Email Attachments With Lots Of Spaces</td></tr><tr><td>id</td><td>56e877a6-1455-4479-ada6-0550dc1e22f8</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2017-09-19</td></tr><tr><td>description</td><td>Attackers often use spaces as a means to obfuscate an attachment's file extension. This search looks for messages with email attachments that have many spaces within the file names.</td></tr><tr><td>how_to_implement</td><td>You need to ingest data from emails. Specifically, the sender's address and the file names of any attachments must be mapped to the Email data model. The threshold ratio is set to 10%, but this value can be configured to suit each environment. \
 **Splunk Phantom Playbook Integration**\
If Splunk Phantom is also configured in your environment, a playbook called "Suspicious Email Attachment Investigate and Delete" can be configured to run when any results are found by this detection search. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/` and add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search. The notable event will be sent to Phantom and the playbook will gather further information about the file attachment and its network behaviors. If Phantom finds malicious behavior and an analyst approves of the results, the email will be deleted from the user's inbox.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` count values(All_Email.recipient) as recipient_address min(_time) as firstTime max(_time) as lastTime from datamodel=Email where All_Email.file_name="*" by All_Email.src_user, All_Email.file_name All_Email.message_id | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `drop_dm_object_name("All_Email")` | eval space_ratio = (mvcount(split(file_name," "))-1)/len(file_name) | search space_ratio >= 0.1 |  rex field=recipient_address "(?<recipient_user>.*)@" | `email_attachments_with_lots_of_spaces_filter`</td></tr><tr><td>known_false_positives</td><td>None at this time</td></tr><tr><td>tags</td><td>{'analytics_story': ['Emotet Malware  DHS Report TA18-201A ', 'Suspicious Emails'], 'kill_chain_phases': ['Delivery'], 'cis20': ['CIS 7'], 'nist': ['PR.IP'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>no_windows_updates_in_a_time_frame.yml</h4>

<table><tr><td>name</td><td>No Windows Updates in a time frame</td></tr><tr><td>id</td><td>1a77c08c-2f56-409c-a2d3-7d64617edd4f</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2017-09-15</td></tr><tr><td>description</td><td>This search looks for Windows endpoints that have not generated an event indicating a successful Windows update in the last 60 days. Windows updates are typically released monthly and applied shortly thereafter. An endpoint that has not successfully applied an update in this time frame indicates the endpoint is not regularly being patched for some reason.</td></tr><tr><td>how_to_implement</td><td>To successfully implement this search, it requires that the 'Update' data model is being populated. This can be accomplished by ingesting Windows events or the Windows Update log via a universal forwarder on the Windows endpoints you wish to monitor. The Windows add-on should be also be installed and configured to properly parse Windows events in Splunk. There may be other data sources which can populate this data model, including vulnerability management systems.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` max(_time) as lastTime from datamodel=Updates where Updates.status=Installed Updates.vendor_product="Microsoft Windows" by Updates.dest Updates.status Updates.vendor_product | rename Updates.dest as Host | rename Updates.status as "Update Status" | rename Updates.vendor_product as Product | eval isOutlier=if(lastTime <= relative_time(now(), "-60d@d"), 1, 0)  | `security_content_ctime(lastTime)`  | search isOutlier=1 | rename lastTime as "Last Update Time", | table Host, "Update Status", Product, "Last Update Time" | `no_windows_updates_in_a_time_frame_filter`</td></tr><tr><td>known_false_positives</td><td>None identified</td></tr><tr><td>tags</td><td>{'analytics_story': ['Monitor for Updates'], 'cis20': ['CIS 18'], 'nist': ['PR.PT', 'PR.MA'], 'security_domain': 'endpoint', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>email_servers_sending_high_volume_traffic_to_hosts.yml</h4>

<table><tr><td>name</td><td>Email servers sending high volume traffic to hosts</td></tr><tr><td>id</td><td>7f5fb3e1-4209-4914-90db-0ec21b556378</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search looks for an increase of data transfers from your email server to your clients. This could be indicative of a malicious actor collecting data using your email server.</td></tr><tr><td>how_to_implement</td><td>This search requires you to be ingesting your network traffic and populating the Network_Traffic data model.  Your email servers must be categorized as "email_server" for the search to work, as well. You may need to adjust the deviation_threshold and minimum_data_samples values based on the network traffic in your environment. The "deviation_threshold" field is a multiplying factor to control how much variation you're willing to tolerate. The "minimum_data_samples" field is the minimum number of connections of data samples required for the statistic to be valid.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>Bhavin Patel, Splunk</td></tr><tr><td>search</td><td>| tstats `security_content_summariesonly` sum(All_Traffic.bytes_out) as bytes_out from datamodel=Network_Traffic where All_Traffic.src_category=email_server by All_Traffic.dest_ip _time span=1d | `drop_dm_object_name("All_Traffic")` | eventstats avg(bytes_out) as avg_bytes_out stdev(bytes_out) as stdev_bytes_out | eventstats count as num_data_samples avg(eval(if(_time < relative_time(now(), "@d"), bytes_out, null))) as per_source_avg_bytes_out stdev(eval(if(_time < relative_time(now(), "@d"), bytes_out, null))) as per_source_stdev_bytes_out by dest_ip | eval minimum_data_samples = 4, deviation_threshold = 3 | where num_data_samples >= minimum_data_samples AND bytes_out > (avg_bytes_out + (deviation_threshold * stdev_bytes_out)) AND bytes_out > (per_source_avg_bytes_out + (deviation_threshold * per_source_stdev_bytes_out)) AND _time >= relative_time(now(), "@d") | eval num_standard_deviations_away_from_server_average = round(abs(bytes_out - avg_bytes_out) / stdev_bytes_out, 2), num_standard_deviations_away_from_client_average = round(abs(bytes_out - per_source_avg_bytes_out) / per_source_stdev_bytes_out, 2) | table dest_ip, _time, bytes_out, avg_bytes_out, per_source_avg_bytes_out, num_standard_deviations_away_from_server_average, num_standard_deviations_away_from_client_average | `email_servers_sending_high_volume_traffic_to_hosts_filter`</td></tr><tr><td>known_false_positives</td><td>The false-positive rate will vary based on how you set the deviation_threshold and data_samples values. Our recommendation is to adjust these values based on your network traffic to and from your email servers.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Collection and Staging'], 'mitre_attack_id': ['T1114.002'], 'kill_chain_phases': ['Actions on Objectives'], 'cis20': ['CIS 7'], 'nist': ['PR.PT', 'DE.CM', 'DE.AE'], 'security_domain': 'network', 'asset_type': 'Endpoint'}</td></tr></table>
<h4>okta_user_logins_from_multiple_cities.yml</h4>

<table><tr><td>name</td><td>Okta User Logins From Multiple Cities</td></tr><tr><td>id</td><td>7594fa07-9f34-4d01-81cc-d6af6a5db9e8</td></tr><tr><td>version</td><td>2</td></tr><tr><td>date</td><td>2020-07-21</td></tr><tr><td>description</td><td>This search detects logins from the same user from different states in a 24 hour period.</td></tr><tr><td>how_to_implement</td><td>This search is specific to Okta and requires Okta logs are being ingested in your Splunk deployment.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>author</td><td>Rico Valdez, Splunk</td></tr><tr><td>search</td><td>`okta` displayMessage="User login to Okta" client.geographicalContext.city!=null | stats min(_time) as firstTime max(_time) as lastTime dc(client.geographicalContext.city) as locations values(client.geographicalContext.city) as cities values(client.geographicalContext.state) as states by user | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `okta_user_logins_from_multiple_cities_filter` | search locations > 1</td></tr><tr><td>known_false_positives</td><td>Users in your enviornment may legitmately be travelling and loggin in from different locations. This search is useful for those users that should *not* be travelling for some reason, such as the COVID-19 pandemic. The search also relies on the geographical information being populated in the Okta logs. It is also possible that a connection from another region may be attributed to a login from a remote VPN endpoint.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Suspicious Okta Activity'], 'mitre_attack_id': ['T1078.001'], 'cis20': ['CIS 16'], 'nist': ['DE.CM'], 'security_domain': 'access', 'asset_type': 'Infrastructure'}</td></tr></table>
<h4>splunk_enterprise_information_disclosure.yml</h4>

<table><tr><td>name</td><td>Splunk Enterprise Information Disclosure</td></tr><tr><td>id</td><td>f6a26b7b-7e80-4963-a9a8-d836e7534ebd</td></tr><tr><td>version</td><td>1</td></tr><tr><td>date</td><td>2018-06-14</td></tr><tr><td>description</td><td>This search allows you to look for evidence of exploitation for CVE-2018-11409, a Splunk Enterprise Information Disclosure Bug.</td></tr><tr><td>how_to_implement</td><td>The REST endpoint that exposes system information is also necessary for the proper operation of Splunk clustering and instrumentation. Whitelisting your Splunk systems will reduce false positives.</td></tr><tr><td>type</td><td>ESCU</td></tr><tr><td>references</td><td>[]</td></tr><tr><td>author</td><td>David Dorsey, Splunk</td></tr><tr><td>search</td><td>index=_internal sourcetype=splunkd_ui_access server-info | search clientip!=127.0.0.1 uri_path="*raw/services/server/info/server-info" | rename clientip as src_ip, splunk_server as dest | stats earliest(_time) as firstTime, latest(_time) as lastTime, values(uri) as uri, values(useragent) as http_user_agent, values(user) as user by src_ip, dest | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `splunk_enterprise_information_disclosure_filter`</td></tr><tr><td>known_false_positives</td><td>Retrieving server information may be a legitimate API request. Verify that the attempt is a valid request for information.</td></tr><tr><td>tags</td><td>{'analytics_story': ['Splunk Enterprise Vulnerability CVE-2018-11409'], 'kill_chain_phases': ['Delivery'], 'cis20': ['CIS 3', 'CIS 4', 'CIS 18'], 'nist': ['ID.RA', 'RS.MI', 'PR.PT', 'PR.AC', 'PR.IP', 'DE.CM'], 'security_domain': 'network', 'asset_type': 'Splunk Server'}</td></tr></table>
