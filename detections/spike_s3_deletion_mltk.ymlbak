asset_type: S3 Bucket
baselines:
  - id: fc0edd96-ff2b-48b0-9f1f-63eq3783fd63
    name: Baseline of S3 Bucket deletion activity by ARN
    type: splunk
confidence: medium
creation_date: '2018-07-17'
data_metadata:
  data_source:
    - AWS CloudTrail logs
  data_sourcetypes:
    - aws:cloudtrail
  providing_technologies:
    - AWS
description: This search detects users creating spikes in API activity related to
  deletion of S3 buckets in your AWS environment. It will also update the cache file
  that factors in the latest data.
detect:
  splunk:
    correlation_rule:
      notable:
        nes_fields: user
        rule_description: A spike in the number of S3 buckets deleted by $user$ was
          detected.
        rule_title: Spike detected in S3 bucket deletion activity by $user$.
      risk:
        risk_object: user
        risk_object_type:
          - user
        risk_score: 30
      schedule:
        cron_schedule: 0 * * * *
        earliest_time: -70m@m
        latest_time: -10m@m
      search: sourcetype=aws:cloudtrail eventName=DeleteBucket [search sourcetype=aws:cloudtrail
        eventName=DeleteBucket | spath output=arn path=userIdentity.arn | stats count
        as apiCalls by arn | inputlookup s3_deletion_baseline append=t | fields -
        latestCount | stats values(*) as * by arn | rename apiCalls as latestCount
        | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls,
        2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval
        avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls,
        stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1)
        | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup
        s3_deletion_baseline | eval dataPointThreshold = 15, deviationThreshold =
        3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls)
        AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn
        as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn
        | spath output=bucketName path=requestParameters.bucketName | stats values(bucketName)
        as bucketName, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled
        by user
      suppress:
        suppress_fields: user
        suppress_period: 14400s
eli5: 'This search and its corresponding subsearch run through the following series
  of steps: \

  1. Retrieve all the AWS CloudTrail log entries that have recorded AWS API calls
  specifically for deletion of S3 buckets.\

  1. Kick off a subsearch that retrieves the same data and pulls out and converts
  the ARN into a more friendly format.\

  1. Count the number of API calls per ARN.\

  1. Load the cache file that contains the number of data points, the count from the
  latest hour, the API call average, and the standard deviation for each ARN.\

  1. Drop the count from the latest hour, since it is unnecessary, and merge the rest
  of the data with the results of the `stats` command. \

  1. Rename `apiCalls` as `latestCount`.\

  1. Calculate the new average value for each ARN with the latest count, weighting
  the past more heavily than the current hour. It does the same for the standard deviation&#151;weighting
  the past more heavily than the current.\

  1. Update the cache file with the latest results.\

  1. Set the minimum threshold for the number of data points and the number of standard
  deviations away from the mean it must be to be considered a spike.\

  1. Make a determination regarding whether or not the current count is a spike by
  checking to see if the minimum data-point threshold has been met and if the count
  is a sufficient number of standard deviations away from the average.\

  1. Filter out anything that it determines is not a spike and returns the list of
  ARNs to the main search. The main search subsequently gets the names of the deleted
  S3 buckets, the number of unique API calls, and the total number of API calls for
  each of these user ARNs.'
entities:
  - user
how_to_implement: You must install the AWS App for Splunk (version 5.1.0 or later)
  and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail
  inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit
  your environment. The `dataPointThreshold` variable is the minimum number of data
  points required to have a statistically significant amount of data to determine.
  The `deviationThreshold` variable is the number of standard deviations away from
  the mean that the value must be to be considered a spike. This search works best
  when you run the "Baseline of S3 Bucket deletion activity by ARN" support search
  once to create a baseline of previously seen S3 bucket-deletion activity.
id: ad12w478-84a8-4641-a3w1-e32372q4bd53
investigations:
  - id: bc91a8cd-35e7-4bb2-6140-e756cc46fd71
    name: AWS Investigate User Activities By ARN
    type: splunk
  - id: f3fb2q1c-5f33-4b01-b541-c2ah9534c242
    name: AWS S3 Bucket details via bucketName
    type: splunk
  - id: 3d6c3213-5fff-4a1e-b57d-b24c262171e7
    name: Get Notable History
    type: splunk
  - id: f3fb4d1b-5f33-4b01-b541-c7af9534c242
    name: Get Notable Info
    type: splunk
  - id: 446ec87a-85c6-40d4-b060-bea4498281d6
    name: Get All AWS Activity From IP Address
    type: splunk
  - id: bc91a8cf-35e7-4bb2-8140-e756cc06fd74
    name: Get User Information from Identity Table
    type: splunk
  - id: bc91a8cd-35e7-4bb2-6140-e756cc46fd11
    name: Investigate AWS activities via region name
    type: splunk
known_false_positives: Based on the values of`dataPointThreshold` and `deviationThreshold`,
  the false positive rate may vary. Please modify this according the your environment.
maintainers:
  - company: Splunk
    email: bpatel@splunk.com
    name: Bhavin Patel
mappings:
  cis20:
    - CIS 13
  kill_chain_phases:
    - Actions on Objectives
  mitre_attack:
    - Credential Access
    - Execution
  nist:
    - DE.DP
    - DE.CM
    - PR.AC
modification_date: '2018-11-27'
name: Detect Spike in S3 Bucket deletion
original_authors:
  - company: Splunk
    email: bpatel@splunk.com
    name: Bhavin Patel
references: []
security_domain: network
spec_version: 2
type: splunk
version: '1.0'
